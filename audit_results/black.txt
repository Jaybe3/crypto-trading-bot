--- /mnt/c/documents/crypto-trading-bot/src/coin_config.py	2026-01-14 18:13:35.446791+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/coin_config.py	2026-02-04 21:34:24.974748+00:00
@@ -13,44 +13,45 @@
 
 
 @dataclass
 class TierConfig:
     """Configuration for a coin tier."""
+
     name: str
-    max_position_pct: float      # Max % of balance per position
-    stop_loss_pct: float         # Stop loss percentage
-    take_profit_usd: float       # Take profit in USD (consistent $1)
-    max_concurrent: int          # Max positions in this tier
-    min_volume_24h: float        # Minimum 24h volume to trade
+    max_position_pct: float  # Max % of balance per position
+    stop_loss_pct: float  # Stop loss percentage
+    take_profit_usd: float  # Take profit in USD (consistent $1)
+    max_concurrent: int  # Max positions in this tier
+    min_volume_24h: float  # Minimum 24h volume to trade
 
 
 # Tier definitions
 TIERS: Dict[int, TierConfig] = {
     1: TierConfig(
         name="Blue Chips",
         max_position_pct=0.25,
         stop_loss_pct=0.03,
         take_profit_usd=1.00,
         max_concurrent=2,
-        min_volume_24h=100_000_000  # $100M
+        min_volume_24h=100_000_000,  # $100M
     ),
     2: TierConfig(
         name="Established Altcoins",
         max_position_pct=0.15,
         stop_loss_pct=0.05,
         take_profit_usd=1.00,
         max_concurrent=3,
-        min_volume_24h=10_000_000   # $10M
+        min_volume_24h=10_000_000,  # $10M
     ),
     3: TierConfig(
         name="High Volatility",
         max_position_pct=0.10,
         stop_loss_pct=0.07,
         take_profit_usd=1.00,
         max_concurrent=3,
-        min_volume_24h=1_000_000    # $1M
-    )
+        min_volume_24h=1_000_000,  # $1M
+    ),
 }
 
 
 # Coin to tier mapping (CoinGecko IDs)
 COINS: Dict[str, int] = {
@@ -60,11 +61,10 @@
     "bitcoin": 1,
     "ethereum": 1,
     "binancecoin": 1,
     "ripple": 1,
     "solana": 1,
-
     # ===================
     # Tier 2: Established Altcoins (15)
     # ===================
     "cardano": 2,
     "dogecoin": 2,
@@ -79,11 +79,10 @@
     "uniswap": 2,
     "bitcoin-cash": 2,
     "stellar": 2,
     "near": 2,
     "aptos": 2,
-
     # ===================
     # Tier 3: High Volatility (25)
     # ===================
     "pepe": 3,
     "floki": 3,
@@ -169,11 +168,11 @@
         tier: {
             "name": config.name,
             "coin_count": len(get_coins_by_tier(tier)),
             "max_position_pct": config.max_position_pct,
             "stop_loss_pct": config.stop_loss_pct,
-            "min_volume": config.min_volume_24h
+            "min_volume": config.min_volume_24h,
         }
         for tier, config in TIERS.items()
     }
 
 
would reformat /mnt/c/documents/crypto-trading-bot/src/coin_config.py
--- /mnt/c/documents/crypto-trading-bot/scripts/daily_checkpoint.py	2026-02-03 19:13:00.438657+00:00
+++ /mnt/c/documents/crypto-trading-bot/scripts/daily_checkpoint.py	2026-02-04 21:34:24.992097+00:00
@@ -73,17 +73,21 @@
     blacklist = fetch_api("/api/knowledge/blacklist")
 
     return {
         "total_coins": coins.get("count", 0),
         "total_patterns": patterns.get("count", 0),
-        "active_patterns": len([p for p in patterns.get("patterns", []) if p.get("is_active", True)]),
+        "active_patterns": len(
+            [p for p in patterns.get("patterns", []) if p.get("is_active", True)]
+        ),
         "total_rules": rules.get("count", 0),
         "blacklisted_coins": blacklist.get("count", 0),
     }
 
 
-def determine_decision(health: dict, stats: dict, profit: dict, effectiveness: dict) -> str:
+def determine_decision(
+    health: dict, stats: dict, profit: dict, effectiveness: dict
+) -> str:
     """Determine go/no-go decision based on metrics."""
     issues = []
 
     # Check health
     overall = health.get("overall", "unknown")
@@ -99,17 +103,19 @@
     if total_pnl < -500:
         issues.append(f"P&L concerning: ${total_pnl:.2f}")
 
     # Check effectiveness
     harmful = effectiveness.get("harmful", 0)
-    total_measured = sum([
-        effectiveness.get("highly_effective", 0),
-        effectiveness.get("effective", 0),
-        effectiveness.get("neutral", 0),
-        effectiveness.get("ineffective", 0),
-        harmful,
-    ])
+    total_measured = sum(
+        [
+            effectiveness.get("highly_effective", 0),
+            effectiveness.get("effective", 0),
+            effectiveness.get("neutral", 0),
+            effectiveness.get("ineffective", 0),
+            harmful,
+        ]
+    )
     if total_measured > 0 and (harmful / total_measured) > 0.5:
         return "PAUSE", [f">{50}% adaptations harmful"]
     if total_measured > 0 and (harmful / total_measured) > 0.2:
         issues.append(f"High harmful adaptation rate: {harmful}/{total_measured}")
 
would reformat /mnt/c/documents/crypto-trading-bot/scripts/daily_checkpoint.py
--- /mnt/c/documents/crypto-trading-bot/scripts/analyze_performance.py	2026-02-03 19:34:41.339977+00:00
+++ /mnt/c/documents/crypto-trading-bot/scripts/analyze_performance.py	2026-02-04 21:34:25.005714+00:00
@@ -65,46 +65,118 @@
     """
     checks = []
 
     # Check 1: Profitability
     if metrics.total_pnl > 0:
-        checks.append({"name": "Profitability", "passed": True, "detail": f"P&L: ${metrics.total_pnl:+.2f}"})
-    else:
-        checks.append({"name": "Profitability", "passed": False, "detail": f"P&L: ${metrics.total_pnl:+.2f} (negative)"})
+        checks.append(
+            {
+                "name": "Profitability",
+                "passed": True,
+                "detail": f"P&L: ${metrics.total_pnl:+.2f}",
+            }
+        )
+    else:
+        checks.append(
+            {
+                "name": "Profitability",
+                "passed": False,
+                "detail": f"P&L: ${metrics.total_pnl:+.2f} (negative)",
+            }
+        )
 
     # Check 2: Profit Factor
     if metrics.profit_factor > 1.0:
-        checks.append({"name": "Profit Factor", "passed": True, "detail": f"PF: {metrics.profit_factor:.2f}"})
-    else:
-        checks.append({"name": "Profit Factor", "passed": False, "detail": f"PF: {metrics.profit_factor:.2f} (<1.0)"})
+        checks.append(
+            {
+                "name": "Profit Factor",
+                "passed": True,
+                "detail": f"PF: {metrics.profit_factor:.2f}",
+            }
+        )
+    else:
+        checks.append(
+            {
+                "name": "Profit Factor",
+                "passed": False,
+                "detail": f"PF: {metrics.profit_factor:.2f} (<1.0)",
+            }
+        )
 
     # Check 3: Win Rate
     if metrics.win_rate > 45:
-        checks.append({"name": "Win Rate", "passed": True, "detail": f"WR: {metrics.win_rate:.1f}%"})
-    else:
-        checks.append({"name": "Win Rate", "passed": False, "detail": f"WR: {metrics.win_rate:.1f}% (<45%)"})
+        checks.append(
+            {
+                "name": "Win Rate",
+                "passed": True,
+                "detail": f"WR: {metrics.win_rate:.1f}%",
+            }
+        )
+    else:
+        checks.append(
+            {
+                "name": "Win Rate",
+                "passed": False,
+                "detail": f"WR: {metrics.win_rate:.1f}% (<45%)",
+            }
+        )
 
     # Check 4: Drawdown
     if metrics.max_drawdown_pct < 20:
-        checks.append({"name": "Max Drawdown", "passed": True, "detail": f"DD: {metrics.max_drawdown_pct:.1f}%"})
-    else:
-        checks.append({"name": "Max Drawdown", "passed": False, "detail": f"DD: {metrics.max_drawdown_pct:.1f}% (>20%)"})
+        checks.append(
+            {
+                "name": "Max Drawdown",
+                "passed": True,
+                "detail": f"DD: {metrics.max_drawdown_pct:.1f}%",
+            }
+        )
+    else:
+        checks.append(
+            {
+                "name": "Max Drawdown",
+                "passed": False,
+                "detail": f"DD: {metrics.max_drawdown_pct:.1f}% (>20%)",
+            }
+        )
 
     # Check 5: Learning Effectiveness
     eff_rate = adapt_effectiveness.get("effectiveness_rate", 0)
     if eff_rate > 50:
-        checks.append({"name": "Learning Effective", "passed": True, "detail": f"Eff: {eff_rate:.1f}%"})
-    else:
-        checks.append({"name": "Learning Effective", "passed": False, "detail": f"Eff: {eff_rate:.1f}% (<50%)"})
+        checks.append(
+            {
+                "name": "Learning Effective",
+                "passed": True,
+                "detail": f"Eff: {eff_rate:.1f}%",
+            }
+        )
+    else:
+        checks.append(
+            {
+                "name": "Learning Effective",
+                "passed": False,
+                "detail": f"Eff: {eff_rate:.1f}% (<50%)",
+            }
+        )
 
     # Check 6: Improvement
     improved = comparison["comparison"].get("improved", False)
     wr_change = comparison["comparison"].get("win_rate_change", 0)
     if improved:
-        checks.append({"name": "Improving", "passed": True, "detail": f"WR change: {wr_change:+.1f}%"})
-    else:
-        checks.append({"name": "Improving", "passed": False, "detail": f"WR change: {wr_change:+.1f}%"})
+        checks.append(
+            {
+                "name": "Improving",
+                "passed": True,
+                "detail": f"WR change: {wr_change:+.1f}%",
+            }
+        )
+    else:
+        checks.append(
+            {
+                "name": "Improving",
+                "passed": False,
+                "detail": f"WR change: {wr_change:+.1f}%",
+            }
+        )
 
     passed = sum(1 for c in checks if c["passed"])
     total = len(checks)
 
     if passed >= 5:
@@ -205,11 +277,13 @@
     with open(os.path.join(args.output, "improvement.txt"), "w") as f:
         f.write(improvement)
     print(f"  - {args.output}/improvement.txt")
 
     # Detailed reports
-    generate_detailed_report(db, trades, os.path.join(args.output, "detailed"), args.days)
+    generate_detailed_report(
+        db, trades, os.path.join(args.output, "detailed"), args.days
+    )
     print(f"  - {args.output}/detailed/")
 
     # Export data if requested
     if args.export:
         print()
@@ -220,31 +294,47 @@
         print(f"  - {args.output}/data_export/")
 
     print()
 
     # Final assessment
-    assessment = assess_readiness(metrics, comparison, adapt_effectiveness, learning_score)
+    assessment = assess_readiness(
+        metrics, comparison, adapt_effectiveness, learning_score
+    )
 
     print("=" * 80)
     print("                         ANALYSIS COMPLETE")
     print("=" * 80)
     print()
     print("KEY FINDINGS:")
-    print(f"  Win Rate:       {metrics.win_rate:.1f}% (Target: >45%) "
-          f"{'[OK]' if metrics.win_rate > 45 else '[LOW]'}")
-    print(f"  Profit Factor:  {metrics.profit_factor:.2f} (Target: >1.0) "
-          f"{'[OK]' if metrics.profit_factor > 1.0 else '[LOW]'}")
-    print(f"  Total P&L:      ${metrics.total_pnl:+.2f} (Target: >$0) "
-          f"{'[OK]' if metrics.total_pnl > 0 else '[NEGATIVE]'}")
-    print(f"  Max Drawdown:   {metrics.max_drawdown_pct:.1f}% (Target: <20%) "
-          f"{'[OK]' if metrics.max_drawdown_pct < 20 else '[HIGH]'}")
-    print()
-    print(f"  Learning Score: {learning_score['total_score']:.0f}/100 (Grade: {learning_score['grade']})")
-    print(f"  Adaptations:    {adapt_effectiveness.get('effectiveness_rate', 0):.1f}% effective "
-          f"{'[OK]' if adapt_effectiveness.get('effectiveness_rate', 0) > 50 else '[LOW]'}")
-    print(f"  Improving:      {'Yes' if comparison['comparison'].get('improved') else 'No'} "
-          f"(WR change: {comparison['comparison'].get('win_rate_change', 0):+.1f}%)")
+    print(
+        f"  Win Rate:       {metrics.win_rate:.1f}% (Target: >45%) "
+        f"{'[OK]' if metrics.win_rate > 45 else '[LOW]'}"
+    )
+    print(
+        f"  Profit Factor:  {metrics.profit_factor:.2f} (Target: >1.0) "
+        f"{'[OK]' if metrics.profit_factor > 1.0 else '[LOW]'}"
+    )
+    print(
+        f"  Total P&L:      ${metrics.total_pnl:+.2f} (Target: >$0) "
+        f"{'[OK]' if metrics.total_pnl > 0 else '[NEGATIVE]'}"
+    )
+    print(
+        f"  Max Drawdown:   {metrics.max_drawdown_pct:.1f}% (Target: <20%) "
+        f"{'[OK]' if metrics.max_drawdown_pct < 20 else '[HIGH]'}"
+    )
+    print()
+    print(
+        f"  Learning Score: {learning_score['total_score']:.0f}/100 (Grade: {learning_score['grade']})"
+    )
+    print(
+        f"  Adaptations:    {adapt_effectiveness.get('effectiveness_rate', 0):.1f}% effective "
+        f"{'[OK]' if adapt_effectiveness.get('effectiveness_rate', 0) > 50 else '[LOW]'}"
+    )
+    print(
+        f"  Improving:      {'Yes' if comparison['comparison'].get('improved') else 'No'} "
+        f"(WR change: {comparison['comparison'].get('win_rate_change', 0):+.1f}%)"
+    )
     print()
 
     # Checklist
     print("READINESS CHECKLIST:")
     for check in assessment["checks"]:
would reformat /mnt/c/documents/crypto-trading-bot/scripts/analyze_performance.py
--- /mnt/c/documents/crypto-trading-bot/scripts/export_trades.py	2026-02-03 19:33:06.969504+00:00
+++ /mnt/c/documents/crypto-trading-bot/scripts/export_trades.py	2026-02-04 21:34:25.007235+00:00
@@ -37,33 +37,48 @@
     cutoff = (datetime.now() - timedelta(days=days)).isoformat()
 
     with db._get_connection() as conn:
         cursor = conn.cursor()
 
-        cursor.execute("""
+        cursor.execute(
+            """
             SELECT
                 trade_id, coin, direction, entry_price, exit_price,
                 position_size_usd, pnl_usd, pnl_pct, entry_time, exit_time,
                 exit_reason, pattern_id, strategy_id, duration_seconds,
                 btc_price_at_entry, btc_trend_at_entry
             FROM trade_journal
             WHERE exit_time >= ?
             ORDER BY exit_time ASC
-        """, (cutoff,))
+        """,
+            (cutoff,),
+        )
 
         trades = cursor.fetchall()
 
     if not trades:
         print(f"No trades found in the last {days} days")
         return 0
 
     # Write CSV
     headers = [
-        "trade_id", "coin", "direction", "entry_price", "exit_price",
-        "position_size_usd", "pnl_usd", "pnl_pct", "entry_time", "exit_time",
-        "exit_reason", "pattern_id", "strategy_id", "duration_seconds",
-        "btc_price_at_entry", "btc_trend_at_entry"
+        "trade_id",
+        "coin",
+        "direction",
+        "entry_price",
+        "exit_price",
+        "position_size_usd",
+        "pnl_usd",
+        "pnl_pct",
+        "entry_time",
+        "exit_time",
+        "exit_reason",
+        "pattern_id",
+        "strategy_id",
+        "duration_seconds",
+        "btc_price_at_entry",
+        "btc_trend_at_entry",
     ]
 
     os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
 
     with open(output_path, "w", newline="") as f:
@@ -90,43 +105,48 @@
     cutoff = (datetime.now() - timedelta(days=days)).isoformat()
 
     with db._get_connection() as conn:
         cursor = conn.cursor()
 
-        cursor.execute("""
+        cursor.execute(
+            """
             SELECT
                 trade_id, coin, direction, entry_price, exit_price,
                 position_size_usd, pnl_usd, pnl_pct, entry_time, exit_time,
                 exit_reason, pattern_id, strategy_id, duration_seconds,
                 btc_price_at_entry, btc_trend_at_entry
             FROM trade_journal
             WHERE exit_time >= ?
             ORDER BY exit_time ASC
-        """, (cutoff,))
+        """,
+            (cutoff,),
+        )
 
         rows = cursor.fetchall()
 
     trades = []
     for row in rows:
-        trades.append({
-            "trade_id": row[0],
-            "coin": row[1],
-            "direction": row[2],
-            "entry_price": row[3],
-            "exit_price": row[4],
-            "position_size_usd": row[5],
-            "pnl_usd": row[6],
-            "pnl_pct": row[7],
-            "entry_time": row[8],
-            "exit_time": row[9],
-            "exit_reason": row[10],
-            "pattern_id": row[11],
-            "strategy_id": row[12],
-            "duration_seconds": row[13],
-            "btc_price_at_entry": row[14],
-            "btc_trend_at_entry": row[15],
-        })
+        trades.append(
+            {
+                "trade_id": row[0],
+                "coin": row[1],
+                "direction": row[2],
+                "entry_price": row[3],
+                "exit_price": row[4],
+                "position_size_usd": row[5],
+                "pnl_usd": row[6],
+                "pnl_pct": row[7],
+                "entry_time": row[8],
+                "exit_time": row[9],
+                "exit_reason": row[10],
+                "pattern_id": row[11],
+                "strategy_id": row[12],
+                "duration_seconds": row[13],
+                "btc_price_at_entry": row[14],
+                "btc_trend_at_entry": row[15],
+            }
+        )
 
     output = {
         "metadata": {
             "exported_at": datetime.now().isoformat(),
             "days_exported": days,
@@ -170,90 +190,129 @@
 
     with db._get_connection() as conn:
         cursor = conn.cursor()
 
         # Export trades
-        cursor.execute("""
+        cursor.execute(
+            """
             SELECT * FROM trade_journal
             WHERE exit_time >= ?
             ORDER BY exit_time ASC
-        """, (cutoff,))
+        """,
+            (cutoff,),
+        )
         trades = cursor.fetchall()
         trade_cols = [desc[0] for desc in cursor.description]
         stats["trades"] = len(trades)
 
         with open(os.path.join(output_dir, "trades.json"), "w") as f:
-            json.dump({
-                "columns": trade_cols,
-                "data": [dict(zip(trade_cols, row)) for row in trades]
-            }, f, indent=2, default=str)
+            json.dump(
+                {
+                    "columns": trade_cols,
+                    "data": [dict(zip(trade_cols, row)) for row in trades],
+                },
+                f,
+                indent=2,
+                default=str,
+            )
 
         # Export patterns
         cursor.execute("SELECT * FROM trading_patterns")
         patterns = cursor.fetchall()
         pattern_cols = [desc[0] for desc in cursor.description]
         stats["patterns"] = len(patterns)
 
         with open(os.path.join(output_dir, "patterns.json"), "w") as f:
-            json.dump({
-                "columns": pattern_cols,
-                "data": [dict(zip(pattern_cols, row)) for row in patterns]
-            }, f, indent=2, default=str)
+            json.dump(
+                {
+                    "columns": pattern_cols,
+                    "data": [dict(zip(pattern_cols, row)) for row in patterns],
+                },
+                f,
+                indent=2,
+                default=str,
+            )
 
         # Export rules
         cursor.execute("SELECT * FROM regime_rules")
         rules = cursor.fetchall()
         rule_cols = [desc[0] for desc in cursor.description]
         stats["rules"] = len(rules)
 
         with open(os.path.join(output_dir, "rules.json"), "w") as f:
-            json.dump({
-                "columns": rule_cols,
-                "data": [dict(zip(rule_cols, row)) for row in rules]
-            }, f, indent=2, default=str)
+            json.dump(
+                {
+                    "columns": rule_cols,
+                    "data": [dict(zip(rule_cols, row)) for row in rules],
+                },
+                f,
+                indent=2,
+                default=str,
+            )
 
         # Export adaptations
-        cursor.execute("""
+        cursor.execute(
+            """
             SELECT * FROM adaptations
             WHERE applied_at >= ?
-        """, (cutoff,))
+        """,
+            (cutoff,),
+        )
         adaptations = cursor.fetchall()
         adapt_cols = [desc[0] for desc in cursor.description]
         stats["adaptations"] = len(adaptations)
 
         with open(os.path.join(output_dir, "adaptations.json"), "w") as f:
-            json.dump({
-                "columns": adapt_cols,
-                "data": [dict(zip(adapt_cols, row)) for row in adaptations]
-            }, f, indent=2, default=str)
+            json.dump(
+                {
+                    "columns": adapt_cols,
+                    "data": [dict(zip(adapt_cols, row)) for row in adaptations],
+                },
+                f,
+                indent=2,
+                default=str,
+            )
 
         # Export coin scores
         cursor.execute("SELECT * FROM coin_scores")
         scores = cursor.fetchall()
         score_cols = [desc[0] for desc in cursor.description]
         stats["coin_scores"] = len(scores)
 
         with open(os.path.join(output_dir, "coin_scores.json"), "w") as f:
-            json.dump({
-                "columns": score_cols,
-                "data": [dict(zip(score_cols, row)) for row in scores]
-            }, f, indent=2, default=str)
+            json.dump(
+                {
+                    "columns": score_cols,
+                    "data": [dict(zip(score_cols, row)) for row in scores],
+                },
+                f,
+                indent=2,
+                default=str,
+            )
 
         # Export insights
-        cursor.execute("""
+        cursor.execute(
+            """
             SELECT * FROM insights
             WHERE created_at >= ?
-        """, (cutoff,))
+        """,
+            (cutoff,),
+        )
         insights = cursor.fetchall()
         insight_cols = [desc[0] for desc in cursor.description]
         stats["insights"] = len(insights)
 
         with open(os.path.join(output_dir, "insights.json"), "w") as f:
-            json.dump({
-                "columns": insight_cols,
-                "data": [dict(zip(insight_cols, row)) for row in insights]
-            }, f, indent=2, default=str)
+            json.dump(
+                {
+                    "columns": insight_cols,
+                    "data": [dict(zip(insight_cols, row)) for row in insights],
+                },
+                f,
+                indent=2,
+                default=str,
+            )
 
     # Write manifest
     manifest = {
         "exported_at": datetime.now().isoformat(),
         "days": days,
@@ -277,12 +336,13 @@
 
 def main():
     parser = argparse.ArgumentParser(description="Export Trade Data")
     parser.add_argument("--db", default="data/trading_bot.db", help="Database path")
     parser.add_argument("--output", "-o", help="Output file/directory")
-    parser.add_argument("--format", choices=["csv", "json", "full"], default="csv",
-                       help="Export format")
+    parser.add_argument(
+        "--format", choices=["csv", "json", "full"], default="csv", help="Export format"
+    )
     parser.add_argument("--days", type=int, default=7, help="Days to export")
     args = parser.parse_args()
 
     if not os.path.exists(args.db):
         print(f"ERROR: Database not found at {args.db}")
would reformat /mnt/c/documents/crypto-trading-bot/scripts/export_trades.py
--- /mnt/c/documents/crypto-trading-bot/src/coin_scorer.py	2026-02-03 16:35:51.961996+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/coin_scorer.py	2026-02-04 21:34:25.011446+00:00
@@ -17,15 +17,16 @@
 logger = logging.getLogger(__name__)
 
 
 class CoinStatus(Enum):
     """Current trading status for a coin."""
-    BLACKLISTED = "blacklisted"    # Do not trade
-    REDUCED = "reduced"            # Trade with reduced size (50%)
-    NORMAL = "normal"              # Trade normally (100%)
-    FAVORED = "favored"            # Can trade with increased size (150%)
-    UNKNOWN = "unknown"            # Not enough data yet
+
+    BLACKLISTED = "blacklisted"  # Do not trade
+    REDUCED = "reduced"  # Trade with reduced size (50%)
+    NORMAL = "normal"  # Trade normally (100%)
+    FAVORED = "favored"  # Can trade with increased size (150%)
+    UNKNOWN = "unknown"  # Not enough data yet
 
 
 # Position size multipliers for each status
 POSITION_MODIFIERS = {
     CoinStatus.BLACKLISTED: 0.0,
@@ -37,19 +38,20 @@
 
 # Minimum trades required before making adaptation decisions
 MIN_TRADES_FOR_ADAPTATION = 5
 
 # Thresholds
-BLACKLIST_WIN_RATE = 0.30      # Below this + negative P&L = blacklist
-REDUCED_WIN_RATE = 0.45        # Below this = reduced size
-FAVORED_WIN_RATE = 0.60        # Above this + positive P&L = favored
-RECOVERY_WIN_RATE = 0.50       # Above this to recover from reduced
+BLACKLIST_WIN_RATE = 0.30  # Below this + negative P&L = blacklist
+REDUCED_WIN_RATE = 0.45  # Below this = reduced size
+FAVORED_WIN_RATE = 0.60  # Above this + positive P&L = favored
+RECOVERY_WIN_RATE = 0.50  # Above this to recover from reduced
 
 
 @dataclass
 class CoinAdaptation:
     """Record of a coin status change."""
+
     coin: str
     timestamp: datetime
     old_status: CoinStatus
     new_status: CoinStatus
     reason: str
@@ -172,49 +174,63 @@
         current_status = self._status_cache.get(coin, CoinStatus.UNKNOWN)
         new_status = current_status
         reason = ""
 
         # Check BLACKLIST threshold (most severe)
-        if (score.win_rate < BLACKLIST_WIN_RATE and
-            score.total_pnl < 0 and
-            not score.is_blacklisted):
+        if (
+            score.win_rate < BLACKLIST_WIN_RATE
+            and score.total_pnl < 0
+            and not score.is_blacklisted
+        ):
 
             new_status = CoinStatus.BLACKLISTED
-            reason = (f"Win rate {score.win_rate:.0%} < {BLACKLIST_WIN_RATE:.0%} "
-                     f"with ${score.total_pnl:.2f} loss over {score.total_trades} trades")
+            reason = (
+                f"Win rate {score.win_rate:.0%} < {BLACKLIST_WIN_RATE:.0%} "
+                f"with ${score.total_pnl:.2f} loss over {score.total_trades} trades"
+            )
             self.brain.blacklist_coin(coin, reason)
 
         # Check REDUCED threshold (not blacklisted, but underperforming)
-        elif (score.win_rate < REDUCED_WIN_RATE and
-              current_status not in [CoinStatus.BLACKLISTED, CoinStatus.REDUCED]):
+        elif score.win_rate < REDUCED_WIN_RATE and current_status not in [
+            CoinStatus.BLACKLISTED,
+            CoinStatus.REDUCED,
+        ]:
 
             new_status = CoinStatus.REDUCED
-            reason = (f"Win rate {score.win_rate:.0%} < {REDUCED_WIN_RATE:.0%} "
-                     f"over {score.total_trades} trades")
+            reason = (
+                f"Win rate {score.win_rate:.0%} < {REDUCED_WIN_RATE:.0%} "
+                f"over {score.total_trades} trades"
+            )
 
         # Check FAVORED threshold (performing well)
-        elif (score.win_rate >= FAVORED_WIN_RATE and
-              score.total_pnl > 0 and
-              current_status not in [CoinStatus.BLACKLISTED, CoinStatus.FAVORED]):
+        elif (
+            score.win_rate >= FAVORED_WIN_RATE
+            and score.total_pnl > 0
+            and current_status not in [CoinStatus.BLACKLISTED, CoinStatus.FAVORED]
+        ):
 
             new_status = CoinStatus.FAVORED
-            reason = (f"Win rate {score.win_rate:.0%} >= {FAVORED_WIN_RATE:.0%} "
-                     f"with ${score.total_pnl:.2f} profit over {score.total_trades} trades")
+            reason = (
+                f"Win rate {score.win_rate:.0%} >= {FAVORED_WIN_RATE:.0%} "
+                f"with ${score.total_pnl:.2f} profit over {score.total_trades} trades"
+            )
 
         # Check if coin recovered from REDUCED status
-        elif (score.win_rate >= RECOVERY_WIN_RATE and
-              current_status == CoinStatus.REDUCED):
+        elif (
+            score.win_rate >= RECOVERY_WIN_RATE and current_status == CoinStatus.REDUCED
+        ):
 
             new_status = CoinStatus.NORMAL
             reason = f"Win rate recovered to {score.win_rate:.0%} (>= {RECOVERY_WIN_RATE:.0%})"
 
         # Check if coin dropped from FAVORED status
-        elif (score.win_rate < FAVORED_WIN_RATE and
-              current_status == CoinStatus.FAVORED):
+        elif score.win_rate < FAVORED_WIN_RATE and current_status == CoinStatus.FAVORED:
 
             new_status = CoinStatus.NORMAL
-            reason = f"Win rate dropped to {score.win_rate:.0%} (< {FAVORED_WIN_RATE:.0%})"
+            reason = (
+                f"Win rate dropped to {score.win_rate:.0%} (< {FAVORED_WIN_RATE:.0%})"
+            )
 
         # Update cache and return adaptation if changed
         if new_status != current_status:
             self._status_cache[coin] = new_status
 
@@ -229,14 +245,16 @@
                     "wins": score.wins,
                     "losses": score.losses,
                     "win_rate": score.win_rate,
                     "total_pnl": score.total_pnl,
                     "avg_pnl": score.avg_pnl,
-                }
-            )
-
-            logger.info(f"COIN ADAPTATION: {coin} {current_status.value} -> {new_status.value}")
+                },
+            )
+
+            logger.info(
+                f"COIN ADAPTATION: {coin} {current_status.value} -> {new_status.value}"
+            )
             logger.info(f"  Reason: {reason}")
 
             return adaptation
 
         return None
@@ -299,11 +317,11 @@
             coin=coin,
             timestamp=datetime.now(),
             old_status=old_status,
             new_status=CoinStatus.BLACKLISTED,
             reason=f"Manual blacklist: {reason}",
-            trigger_stats={"manual": True}
+            trigger_stats={"manual": True},
         )
 
         self._log_adaptation(adaptation)
         logger.info(f"MANUAL BLACKLIST: {coin} - {reason}")
 
@@ -335,11 +353,11 @@
             coin=coin,
             timestamp=datetime.now(),
             old_status=old_status,
             new_status=new_status,
             reason="Manual unblacklist",
-            trigger_stats={"manual": True}
+            trigger_stats={"manual": True},
         )
 
         self._log_adaptation(adaptation)
         logger.info(f"MANUAL UNBLACKLIST: {coin} -> {new_status.value}")
 
would reformat /mnt/c/documents/crypto-trading-bot/src/coin_scorer.py
--- /mnt/c/documents/crypto-trading-bot/src/llm_interface.py	2026-02-03 14:02:06.011904+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/llm_interface.py	2026-02-04 21:34:25.025528+00:00
@@ -16,12 +16,11 @@
 
 from src.database import Database
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 
 # Default configuration
@@ -62,11 +61,11 @@
     def __init__(
         self,
         api_url: str = DEFAULT_API_URL,
         model: str = DEFAULT_MODEL,
         timeout: int = DEFAULT_TIMEOUT,
-        db: Optional[Database] = None
+        db: Optional[Database] = None,
     ):
         """Initialize the LLM interface.
 
         Args:
             api_url: Ollama API endpoint (default: http://localhost:11434/api/chat).
@@ -83,37 +82,31 @@
         self.db = db or Database()
 
         logger.info(f"LLMInterface initialized: model={model}, url={api_url}")
 
     def _make_request(
-        self,
-        messages: List[Dict[str, str]],
-        retry_count: int = 0
+        self, messages: List[Dict[str, str]], retry_count: int = 0
     ) -> Optional[Dict[str, Any]]:
         """Make a request to the LLM API with retry logic.
 
         Args:
             messages: List of message dicts with 'role' and 'content'.
             retry_count: Current retry attempt (for exponential backoff).
 
         Returns:
             API response as dict, or None if all retries failed.
         """
-        payload = {
-            "model": self.model,
-            "messages": messages,
-            "stream": False
-        }
+        payload = {"model": self.model, "messages": messages, "stream": False}
 
         try:
             start_time = time.time()
 
             response = requests.post(
                 self.api_url,
                 json=payload,
                 headers={"Content-Type": "application/json"},
-                timeout=self.timeout
+                timeout=self.timeout,
             )
             response.raise_for_status()
 
             elapsed = time.time() - start_time
             logger.info(f"LLM response received in {elapsed:.2f}s")
@@ -122,46 +115,48 @@
 
         except ConnectionError as e:
             logger.error(f"Cannot connect to LLM at {self.api_url}: {e}")
             logger.error("Is Ollama running? Try: ollama serve")
             self.db.log_activity(
-                activity_type='error',
-                description='LLM connection failed',
-                details=f'Cannot connect to {self.api_url}: {str(e)}'
+                activity_type="error",
+                description="LLM connection failed",
+                details=f"Cannot connect to {self.api_url}: {str(e)}",
             )
             return None
 
         except Timeout as e:
             logger.warning(f"LLM request timed out after {self.timeout}s")
 
             if retry_count < MAX_RETRIES:
-                backoff = INITIAL_BACKOFF * (2 ** retry_count)
-                logger.info(f"Retrying in {backoff}s (attempt {retry_count + 1}/{MAX_RETRIES})")
+                backoff = INITIAL_BACKOFF * (2**retry_count)
+                logger.info(
+                    f"Retrying in {backoff}s (attempt {retry_count + 1}/{MAX_RETRIES})"
+                )
                 time.sleep(backoff)
                 return self._make_request(messages, retry_count + 1)
 
             logger.error(f"LLM request failed after {MAX_RETRIES} retries")
             self.db.log_activity(
-                activity_type='error',
-                description='LLM timeout after retries',
-                details=f'Timed out after {MAX_RETRIES} attempts'
+                activity_type="error",
+                description="LLM timeout after retries",
+                details=f"Timed out after {MAX_RETRIES} attempts",
             )
             return None
 
         except RequestException as e:
             logger.error(f"LLM request error: {e}")
 
             if retry_count < MAX_RETRIES:
-                backoff = INITIAL_BACKOFF * (2 ** retry_count)
-                logger.info(f"Retrying in {backoff}s (attempt {retry_count + 1}/{MAX_RETRIES})")
+                backoff = INITIAL_BACKOFF * (2**retry_count)
+                logger.info(
+                    f"Retrying in {backoff}s (attempt {retry_count + 1}/{MAX_RETRIES})"
+                )
                 time.sleep(backoff)
                 return self._make_request(messages, retry_count + 1)
 
             self.db.log_activity(
-                activity_type='error',
-                description='LLM request failed',
-                details=str(e)
+                activity_type="error", description="LLM request failed", details=str(e)
             )
             return None
 
     def query(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:
         """Send a prompt to the LLM and get a text response.
@@ -192,28 +187,28 @@
         try:
             content = response.get("message", {}).get("content", "")
 
             # Log successful interaction
             self.db.log_activity(
-                activity_type='llm_query',
-                description=f'Prompt: {prompt[:100]}...',
-                details=json.dumps({
-                    'prompt': prompt,
-                    'response': content,
-                    'model': self.model
-                })
+                activity_type="llm_query",
+                description=f"Prompt: {prompt[:100]}...",
+                details=json.dumps(
+                    {"prompt": prompt, "response": content, "model": self.model}
+                ),
             )
 
             logger.info(f"LLM response: {content[:100]}...")
             return content
 
         except (KeyError, TypeError) as e:
             logger.error(f"Failed to parse LLM response: {e}")
             logger.debug(f"Raw response: {response}")
             return None
 
-    def query_json(self, prompt: str, system_prompt: Optional[str] = None) -> Optional[Dict]:
+    def query_json(
+        self, prompt: str, system_prompt: Optional[str] = None
+    ) -> Optional[Dict]:
         """Send a prompt and parse the response as JSON.
 
         Args:
             prompt: The user prompt (should ask for JSON response).
             system_prompt: Optional system prompt.
@@ -249,11 +244,11 @@
         self,
         market_data: Dict[str, Any],
         account_state: Dict[str, Any],
         recent_learnings: Optional[List[str]] = None,
         active_rules: Optional[List[str]] = None,
-        coins_in_cooldown: Optional[List[str]] = None
+        coins_in_cooldown: Optional[List[str]] = None,
     ) -> Optional[Dict[str, Any]]:
         """Get a trading decision from the LLM.
 
         Args:
             market_data: Current market prices and changes.
@@ -321,22 +316,24 @@
 REMEMBER: You MUST NOT select any coin from the FORBIDDEN list above.
 Respond with JSON only."""
 
         result = self.query_json(prompt, system_prompt)
 
-        if result and 'action' in result:
-            logger.info(f"Trading decision: {result['action']} (confidence: {result.get('confidence', 'N/A')})")
+        if result and "action" in result:
+            logger.info(
+                f"Trading decision: {result['action']} (confidence: {result.get('confidence', 'N/A')})"
+            )
             return result
 
         # Return a safe default if parsing failed
         logger.warning("Failed to get valid trading decision, defaulting to HOLD")
         return {
             "action": "HOLD",
             "coin": None,
             "size_usd": None,
             "reason": "Failed to parse LLM response",
-            "confidence": 0.0
+            "confidence": 0.0,
         }
 
     def analyze_trade(self, trade_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
         """Analyze a completed trade and generate a learning.
 
@@ -373,11 +370,13 @@
 Respond with JSON only."""
 
         result = self.query_json(prompt, system_prompt)
 
         if result:
-            logger.info(f"Trade analysis complete: {result.get('lesson', 'N/A')[:50]}...")
+            logger.info(
+                f"Trade analysis complete: {result.get('lesson', 'N/A')[:50]}..."
+            )
             return result
 
         return None
 
     def test_connection(self) -> bool:
@@ -401,15 +400,11 @@
         """Get information about the configured model.
 
         Returns:
             Dict with model name and API URL.
         """
-        return {
-            "model": self.model,
-            "api_url": self.api_url,
-            "timeout": self.timeout
-        }
+        return {"model": self.model, "api_url": self.api_url, "timeout": self.timeout}
 
 
 # Allow running directly for testing
 if __name__ == "__main__":
     print("=" * 60)
would reformat /mnt/c/documents/crypto-trading-bot/src/llm_interface.py
--- /mnt/c/documents/crypto-trading-bot/src/analysis/metrics.py	2026-02-03 19:31:19.016970+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/analysis/metrics.py	2026-02-04 21:34:25.031065+00:00
@@ -96,11 +96,13 @@
             f"Sharpe Ratio: {self.sharpe_ratio:.2f}",
         ]
         return "\n".join(lines)
 
 
-def calculate_metrics(trades: List[dict], starting_balance: float = 1000.0) -> TradingMetrics:
+def calculate_metrics(
+    trades: List[dict], starting_balance: float = 1000.0
+) -> TradingMetrics:
     """
     Calculate all trading metrics from a list of trades.
 
     Args:
         trades: List of trade dictionaries with at least:
@@ -117,12 +119,11 @@
     if not trades:
         return metrics
 
     # Sort by exit time
     sorted_trades = sorted(
-        trades,
-        key=lambda t: t.get("exit_time") or t.get("timestamp") or ""
+        trades, key=lambda t: t.get("exit_time") or t.get("timestamp") or ""
     )
 
     metrics.total_trades = len(sorted_trades)
 
     # Calculate P&L metrics
@@ -237,11 +238,11 @@
 
 def calculate_sharpe_ratio(
     returns: List[float],
     risk_free_rate: float = 0.0,
     annualize: bool = True,
-    periods_per_year: int = 365
+    periods_per_year: int = 365,
 ) -> float:
     """
     Calculate Sharpe ratio.
 
     Args:
@@ -306,11 +307,13 @@
             max_dd_pct = drawdown_pct
 
     return max_dd_amount, max_dd_pct
 
 
-def build_equity_curve(pnl_values: List[float], starting_balance: float = 1000.0) -> List[float]:
+def build_equity_curve(
+    pnl_values: List[float], starting_balance: float = 1000.0
+) -> List[float]:
     """
     Build equity curve from P&L values.
 
     Args:
         pnl_values: List of trade P&L values.
would reformat /mnt/c/documents/crypto-trading-bot/src/analysis/metrics.py
--- /mnt/c/documents/crypto-trading-bot/src/analysis/performance.py	2026-02-03 19:31:47.660627+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/analysis/performance.py	2026-02-04 21:34:25.035216+00:00
@@ -36,11 +36,13 @@
                 except ValueError:
                     continue
             hour = ts.hour
             by_hour[hour].append(trade)
 
-    return {hour: calculate_metrics(hour_trades) for hour, hour_trades in by_hour.items()}
+    return {
+        hour: calculate_metrics(hour_trades) for hour, hour_trades in by_hour.items()
+    }
 
 
 def analyze_by_coin(trades: List[dict]) -> Dict[str, TradingMetrics]:
     """
     Analyze trading performance by coin.
@@ -55,11 +57,13 @@
 
     for trade in trades:
         coin = trade.get("coin") or trade.get("symbol") or "UNKNOWN"
         by_coin[coin].append(trade)
 
-    return {coin: calculate_metrics(coin_trades) for coin, coin_trades in by_coin.items()}
+    return {
+        coin: calculate_metrics(coin_trades) for coin, coin_trades in by_coin.items()
+    }
 
 
 def analyze_by_pattern(trades: List[dict]) -> Dict[str, TradingMetrics]:
     """
     Analyze trading performance by pattern.
@@ -74,11 +78,14 @@
 
     for trade in trades:
         pattern = trade.get("pattern_id") or trade.get("pattern") or "no_pattern"
         by_pattern[pattern].append(trade)
 
-    return {pattern: calculate_metrics(pattern_trades) for pattern, pattern_trades in by_pattern.items()}
+    return {
+        pattern: calculate_metrics(pattern_trades)
+        for pattern, pattern_trades in by_pattern.items()
+    }
 
 
 def analyze_by_day(trades: List[dict]) -> Dict[str, TradingMetrics]:
     """
     Analyze trading performance by day of week.
@@ -87,11 +94,19 @@
         trades: List of trade dictionaries.
 
     Returns:
         Dictionary mapping day name to TradingMetrics.
     """
-    days = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
+    days = [
+        "Monday",
+        "Tuesday",
+        "Wednesday",
+        "Thursday",
+        "Friday",
+        "Saturday",
+        "Sunday",
+    ]
     by_day = defaultdict(list)
 
     for trade in trades:
         ts = trade.get("exit_time") or trade.get("timestamp")
         if ts:
@@ -138,16 +153,18 @@
                 session = "European"
             else:
                 session = "US"
             by_session[session].append(trade)
 
-    return {session: calculate_metrics(session_trades) for session, session_trades in by_session.items()}
+    return {
+        session: calculate_metrics(session_trades)
+        for session, session_trades in by_session.items()
+    }
 
 
 def compare_periods(
-    trades: List[dict],
-    split_point: Optional[datetime] = None
+    trades: List[dict], split_point: Optional[datetime] = None
 ) -> Dict[str, dict]:
     """
     Compare early vs late trading performance.
 
     Args:
@@ -164,12 +181,11 @@
             "comparison": {},
         }
 
     # Sort by timestamp
     sorted_trades = sorted(
-        trades,
-        key=lambda t: t.get("exit_time") or t.get("timestamp") or ""
+        trades, key=lambda t: t.get("exit_time") or t.get("timestamp") or ""
     )
 
     # Determine split point
     if split_point is None:
         midpoint_idx = len(sorted_trades) // 2
@@ -196,105 +212,121 @@
 
     # Calculate improvements
     comparison = {
         "trades_change": metrics_second.total_trades - metrics_first.total_trades,
         "win_rate_change": metrics_second.win_rate - metrics_first.win_rate,
-        "profit_factor_change": metrics_second.profit_factor - metrics_first.profit_factor,
+        "profit_factor_change": metrics_second.profit_factor
+        - metrics_first.profit_factor,
         "avg_pnl_change": metrics_second.avg_pnl - metrics_first.avg_pnl,
         "total_pnl_change": metrics_second.total_pnl - metrics_first.total_pnl,
-        "drawdown_change": metrics_second.max_drawdown_pct - metrics_first.max_drawdown_pct,
+        "drawdown_change": metrics_second.max_drawdown_pct
+        - metrics_first.max_drawdown_pct,
         "sharpe_change": metrics_second.sharpe_ratio - metrics_first.sharpe_ratio,
         "improved": (
-            metrics_second.win_rate > metrics_first.win_rate and
-            metrics_second.profit_factor > metrics_first.profit_factor
+            metrics_second.win_rate > metrics_first.win_rate
+            and metrics_second.profit_factor > metrics_first.profit_factor
         ),
     }
 
     return {
         "first_half": metrics_first.to_dict(),
         "second_half": metrics_second.to_dict(),
         "comparison": comparison,
     }
 
 
-def get_best_worst_hours(hour_metrics: Dict[int, TradingMetrics], min_trades: int = 3) -> dict:
+def get_best_worst_hours(
+    hour_metrics: Dict[int, TradingMetrics], min_trades: int = 3
+) -> dict:
     """
     Identify best and worst trading hours.
 
     Args:
         hour_metrics: Dictionary from analyze_by_hour().
         min_trades: Minimum trades required for consideration.
 
     Returns:
         Dictionary with best/worst hours and their metrics.
     """
-    filtered = {
-        h: m for h, m in hour_metrics.items()
-        if m.total_trades >= min_trades
-    }
+    filtered = {h: m for h, m in hour_metrics.items() if m.total_trades >= min_trades}
 
     if not filtered:
         return {"best_hours": [], "worst_hours": [], "message": "Not enough data"}
 
     # Sort by win rate
     sorted_hours = sorted(
         filtered.items(),
         key=lambda x: (x[1].win_rate, x[1].profit_factor),
-        reverse=True
+        reverse=True,
     )
 
     best = sorted_hours[:3]
     worst = sorted_hours[-3:] if len(sorted_hours) >= 3 else []
 
     return {
         "best_hours": [
-            {"hour": h, "win_rate": m.win_rate, "pnl": m.total_pnl, "trades": m.total_trades}
+            {
+                "hour": h,
+                "win_rate": m.win_rate,
+                "pnl": m.total_pnl,
+                "trades": m.total_trades,
+            }
             for h, m in best
         ],
         "worst_hours": [
-            {"hour": h, "win_rate": m.win_rate, "pnl": m.total_pnl, "trades": m.total_trades}
+            {
+                "hour": h,
+                "win_rate": m.win_rate,
+                "pnl": m.total_pnl,
+                "trades": m.total_trades,
+            }
             for h, m in worst
         ],
     }
 
 
-def get_best_worst_coins(coin_metrics: Dict[str, TradingMetrics], min_trades: int = 3) -> dict:
+def get_best_worst_coins(
+    coin_metrics: Dict[str, TradingMetrics], min_trades: int = 3
+) -> dict:
     """
     Identify best and worst performing coins.
 
     Args:
         coin_metrics: Dictionary from analyze_by_coin().
         min_trades: Minimum trades required for consideration.
 
     Returns:
         Dictionary with best/worst coins and their metrics.
     """
-    filtered = {
-        c: m for c, m in coin_metrics.items()
-        if m.total_trades >= min_trades
-    }
+    filtered = {c: m for c, m in coin_metrics.items() if m.total_trades >= min_trades}
 
     if not filtered:
         return {"best_coins": [], "worst_coins": [], "message": "Not enough data"}
 
     # Sort by total P&L
-    sorted_coins = sorted(
-        filtered.items(),
-        key=lambda x: x[1].total_pnl,
-        reverse=True
-    )
+    sorted_coins = sorted(filtered.items(), key=lambda x: x[1].total_pnl, reverse=True)
 
     best = sorted_coins[:3]
     worst = sorted_coins[-3:] if len(sorted_coins) >= 3 else []
 
     return {
         "best_coins": [
-            {"coin": c, "pnl": m.total_pnl, "win_rate": m.win_rate, "trades": m.total_trades}
+            {
+                "coin": c,
+                "pnl": m.total_pnl,
+                "win_rate": m.win_rate,
+                "trades": m.total_trades,
+            }
             for c, m in best
         ],
         "worst_coins": [
-            {"coin": c, "pnl": m.total_pnl, "win_rate": m.win_rate, "trades": m.total_trades}
+            {
+                "coin": c,
+                "pnl": m.total_pnl,
+                "win_rate": m.win_rate,
+                "trades": m.total_trades,
+            }
             for c, m in worst
         ],
     }
 
 
would reformat /mnt/c/documents/crypto-trading-bot/src/analysis/performance.py
--- /mnt/c/documents/crypto-trading-bot/src/dashboard.py	2026-01-14 19:52:24.276214+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/dashboard.py	2026-02-04 21:34:25.035476+00:00
@@ -22,12 +22,11 @@
 from src.volatility import VolatilityCalculator
 from src.metrics import MetricsCollector
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 # Create Flask app
 app = Flask(__name__)
@@ -605,23 +604,25 @@
 
             result = {}
             for row in cursor.fetchall():
                 coin_id = row[0]
                 result[coin_id] = {
-                    'price_usd': row[1],
-                    'change_24h': row[2] or 0,
-                    'last_updated': row[3],
-                    'tier': get_tier(coin_id),
-                    'vol_score': 50  # Default, will be updated below
+                    "price_usd": row[1],
+                    "change_24h": row[2] or 0,
+                    "last_updated": row[3],
+                    "tier": get_tier(coin_id),
+                    "vol_score": 50,  # Default, will be updated below
                 }
 
         # Add volatility scores
         try:
             vc = VolatilityCalculator(db=self.db)
             for coin_id in result.keys():
                 try:
-                    result[coin_id]['vol_score'] = vc.calculate_volatility_score(coin_id)
+                    result[coin_id]["vol_score"] = vc.calculate_volatility_score(
+                        coin_id
+                    )
                 except Exception:
                     pass  # Keep default of 50
         except Exception as e:
             logger.warning(f"Failed to get volatility scores: {e}")
 
@@ -630,16 +631,16 @@
     def get_account_state(self) -> Dict[str, Any]:
         """Get current account state."""
         state = self.db.get_account_state()
         # Ensure all expected fields exist with defaults
         return {
-            'balance': state.get('balance', 0),
-            'available_balance': state.get('available_balance', 0),
-            'in_positions': state.get('in_positions', 0),
-            'total_pnl': state.get('total_pnl', 0),
-            'daily_pnl': state.get('daily_pnl', 0),
-            'trade_count_today': state.get('trade_count_today', 0)
+            "balance": state.get("balance", 0),
+            "available_balance": state.get("available_balance", 0),
+            "in_positions": state.get("in_positions", 0),
+            "total_pnl": state.get("total_pnl", 0),
+            "daily_pnl": state.get("daily_pnl", 0),
+            "trade_count_today": state.get("trade_count_today", 0),
         }
 
     def get_open_trades(self) -> List[Dict[str, Any]]:
         """Get all open trades."""
         with self.db._get_connection() as conn:
@@ -650,65 +651,94 @@
                        take_profit_price, entry_reason, opened_at
                 FROM open_trades
                 ORDER BY opened_at DESC
             """)
 
-            columns = ['id', 'coin_name', 'entry_price', 'size_usd', 'current_price',
-                      'unrealized_pnl', 'unrealized_pnl_pct', 'stop_loss_price',
-                      'take_profit_price', 'entry_reason', 'opened_at']
+            columns = [
+                "id",
+                "coin_name",
+                "entry_price",
+                "size_usd",
+                "current_price",
+                "unrealized_pnl",
+                "unrealized_pnl_pct",
+                "stop_loss_price",
+                "take_profit_price",
+                "entry_reason",
+                "opened_at",
+            ]
 
             return [dict(zip(columns, row)) for row in cursor.fetchall()]
 
     def get_closed_trades(self, limit: int = 10) -> List[Dict[str, Any]]:
         """Get recent closed trades."""
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT id, coin_name, entry_price, exit_price, size_usd,
                        pnl_usd, pnl_pct, entry_reason, exit_reason,
                        opened_at, closed_at, duration_seconds
                 FROM closed_trades
                 ORDER BY closed_at DESC
                 LIMIT ?
-            """, (limit,))
-
-            columns = ['id', 'coin_name', 'entry_price', 'exit_price', 'size_usd',
-                      'pnl_usd', 'pnl_pct', 'entry_reason', 'exit_reason',
-                      'opened_at', 'closed_at', 'duration_seconds']
+            """,
+                (limit,),
+            )
+
+            columns = [
+                "id",
+                "coin_name",
+                "entry_price",
+                "exit_price",
+                "size_usd",
+                "pnl_usd",
+                "pnl_pct",
+                "entry_reason",
+                "exit_reason",
+                "opened_at",
+                "closed_at",
+                "duration_seconds",
+            ]
 
             return [dict(zip(columns, row)) for row in cursor.fetchall()]
 
     def get_learnings(self, limit: int = 10) -> List[Dict[str, Any]]:
         """Get recent learnings for display."""
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT l.id, l.trade_id, l.learning_text, l.confidence_level,
                        l.created_at, c.coin_name, c.pnl_usd
                 FROM learnings l
                 LEFT JOIN closed_trades c ON l.trade_id = c.id
                 ORDER BY l.created_at DESC
                 LIMIT ?
-            """, (limit,))
+            """,
+                (limit,),
+            )
 
             learnings = []
             for row in cursor.fetchall():
                 try:
                     data = json.loads(row[2])
                 except (json.JSONDecodeError, TypeError):
-                    data = {'lesson': row[2] or ''}
-
-                learnings.append({
-                    'id': row[0],
-                    'trade_id': row[1],
-                    'lesson': data.get('lesson', ''),
-                    'pattern': data.get('pattern', ''),
-                    'confidence': row[3] or 0,
-                    'created_at': row[4],
-                    'coin_name': row[5] or 'unknown',
-                    'trade_pnl': row[6] or 0
-                })
+                    data = {"lesson": row[2] or ""}
+
+                learnings.append(
+                    {
+                        "id": row[0],
+                        "trade_id": row[1],
+                        "lesson": data.get("lesson", ""),
+                        "pattern": data.get("pattern", ""),
+                        "confidence": row[3] or 0,
+                        "created_at": row[4],
+                        "coin_name": row[5] or "unknown",
+                        "trade_pnl": row[6] or 0,
+                    }
+                )
             return learnings
 
     def get_trading_rules(self) -> Dict[str, List[Dict[str, Any]]]:
         """Get trading rules grouped by status."""
         with self.db._get_connection() as conn:
@@ -723,127 +753,135 @@
                         ELSE 3
                     END,
                     created_at DESC
             """)
 
-            rules = {'active': [], 'testing': [], 'rejected': []}
+            rules = {"active": [], "testing": [], "rejected": []}
             for row in cursor.fetchall():
                 total = (row[3] or 0) + (row[4] or 0)
                 success_rate = (row[3] or 0) / total if total > 0 else 0
 
                 rule = {
-                    'id': row[0],
-                    'rule_text': row[1],
-                    'status': row[2],
-                    'success_count': row[3] or 0,
-                    'failure_count': row[4] or 0,
-                    'success_rate': success_rate,
-                    'total_trades': total,
-                    'created_at': row[5]
+                    "id": row[0],
+                    "rule_text": row[1],
+                    "status": row[2],
+                    "success_count": row[3] or 0,
+                    "failure_count": row[4] or 0,
+                    "success_rate": success_rate,
+                    "total_trades": total,
+                    "created_at": row[5],
                 }
                 if row[2] in rules:
                     rules[row[2]].append(rule)
             return rules
 
 
 # Create dashboard data fetcher
 dashboard_data = DashboardData()
 
 
-@app.route('/')
+@app.route("/")
 def index():
     """Main dashboard page."""
     try:
         # Get performance metrics
         mc = MetricsCollector(db=dashboard_data.db)
         metrics = mc.get_all_metrics()
 
         data = {
-            'market_data': dashboard_data.get_market_data(),
-            'account': dashboard_data.get_account_state(),
-            'open_trades': dashboard_data.get_open_trades(),
-            'closed_trades': dashboard_data.get_closed_trades(),
-            'learnings': dashboard_data.get_learnings(),
-            'rules': dashboard_data.get_trading_rules(),
-            'metrics': metrics,
-            'last_update': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
+            "market_data": dashboard_data.get_market_data(),
+            "account": dashboard_data.get_account_state(),
+            "open_trades": dashboard_data.get_open_trades(),
+            "closed_trades": dashboard_data.get_closed_trades(),
+            "learnings": dashboard_data.get_learnings(),
+            "rules": dashboard_data.get_trading_rules(),
+            "metrics": metrics,
+            "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
         }
         return render_template_string(DASHBOARD_TEMPLATE, **data)
     except Exception as e:
         logger.error(f"Dashboard error: {e}")
         return f"<h1>Dashboard Error</h1><p>{e}</p>", 500
 
 
-@app.route('/api/status')
+@app.route("/api/status")
 def api_status():
     """JSON API endpoint for dashboard data."""
     try:
-        return jsonify({
-            'status': 'running',
-            'market_data': dashboard_data.get_market_data(),
-            'account': dashboard_data.get_account_state(),
-            'open_trades': dashboard_data.get_open_trades(),
-            'closed_trades': dashboard_data.get_closed_trades(),
-            'timestamp': datetime.now().isoformat()
-        })
+        return jsonify(
+            {
+                "status": "running",
+                "market_data": dashboard_data.get_market_data(),
+                "account": dashboard_data.get_account_state(),
+                "open_trades": dashboard_data.get_open_trades(),
+                "closed_trades": dashboard_data.get_closed_trades(),
+                "timestamp": datetime.now().isoformat(),
+            }
+        )
     except Exception as e:
         logger.error(f"API error: {e}")
-        return jsonify({'error': str(e)}), 500
-
-
-@app.route('/api/metrics')
+        return jsonify({"error": str(e)}), 500
+
+
+@app.route("/api/metrics")
 def api_metrics():
     """JSON API endpoint for performance metrics."""
     try:
         mc = MetricsCollector(db=dashboard_data.db)
         return jsonify(mc.get_all_metrics())
     except Exception as e:
         logger.error(f"Metrics API error: {e}")
-        return jsonify({'error': str(e)}), 500
-
-
-@app.route('/metrics')
+        return jsonify({"error": str(e)}), 500
+
+
+@app.route("/metrics")
 def prometheus_metrics():
     """Prometheus-compatible metrics endpoint.
 
     Returns metrics in Prometheus exposition format for external monitoring.
     Can be scraped by Prometheus or other monitoring systems.
     """
     try:
         mc = MetricsCollector(db=dashboard_data.db)
-        return mc.format_prometheus(), 200, {'Content-Type': 'text/plain; charset=utf-8'}
+        return (
+            mc.format_prometheus(),
+            200,
+            {"Content-Type": "text/plain; charset=utf-8"},
+        )
     except Exception as e:
         logger.error(f"Prometheus metrics error: {e}")
-        return f"# Error: {e}", 500, {'Content-Type': 'text/plain; charset=utf-8'}
-
-
-@app.route('/api/alerts')
+        return f"# Error: {e}", 500, {"Content-Type": "text/plain; charset=utf-8"}
+
+
+@app.route("/api/alerts")
 def api_alerts():
     """JSON API endpoint for active alerts."""
     try:
         mc = MetricsCollector(db=dashboard_data.db)
         alerts = mc.check_alerts()
-        return jsonify({
-            'alerts': [
-                {
-                    'level': a.level.value,
-                    'metric': a.metric,
-                    'message': a.message,
-                    'value': a.value,
-                    'threshold': a.threshold
-                }
-                for a in alerts
-            ],
-            'count': len(alerts),
-            'timestamp': datetime.now().isoformat()
-        })
+        return jsonify(
+            {
+                "alerts": [
+                    {
+                        "level": a.level.value,
+                        "metric": a.metric,
+                        "message": a.message,
+                        "value": a.value,
+                        "threshold": a.threshold,
+                    }
+                    for a in alerts
+                ],
+                "count": len(alerts),
+                "timestamp": datetime.now().isoformat(),
+            }
+        )
     except Exception as e:
         logger.error(f"Alerts API error: {e}")
-        return jsonify({'error': str(e)}), 500
-
-
-def run_dashboard(host: str = '0.0.0.0', port: int = 8080, debug: bool = False):
+        return jsonify({"error": str(e)}), 500
+
+
+def run_dashboard(host: str = "0.0.0.0", port: int = 8080, debug: bool = False):
     """Run the dashboard server.
 
     Args:
         host: Host to bind to (default: 0.0.0.0 for all interfaces).
         port: Port to listen on (default: 8080).
would reformat /mnt/c/documents/crypto-trading-bot/src/dashboard.py
--- /mnt/c/documents/crypto-trading-bot/src/daily_summary.py	2026-01-14 17:48:16.857463+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/daily_summary.py	2026-02-04 21:34:25.036101+00:00
@@ -20,12 +20,11 @@
 
 from src.database import Database
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 
 class DailySummary:
@@ -46,13 +45,23 @@
                 FROM closed_trades
                 WHERE date(closed_at) = date('now')
                 ORDER BY closed_at DESC
             """)
 
-            columns = ['id', 'coin_name', 'entry_price', 'exit_price', 'size_usd',
-                      'pnl_usd', 'pnl_pct', 'entry_reason', 'exit_reason',
-                      'duration_seconds', 'closed_at']
+            columns = [
+                "id",
+                "coin_name",
+                "entry_price",
+                "exit_price",
+                "size_usd",
+                "pnl_usd",
+                "pnl_pct",
+                "entry_reason",
+                "exit_reason",
+                "duration_seconds",
+                "closed_at",
+            ]
             return [dict(zip(columns, row)) for row in cursor.fetchall()]
 
     def get_today_learnings(self) -> List[Dict[str, Any]]:
         """Get learnings created today."""
         with self.db._get_connection() as conn:
@@ -69,21 +78,23 @@
             learnings = []
             for row in cursor.fetchall():
                 try:
                     data = json.loads(row[2])
                 except (json.JSONDecodeError, TypeError):
-                    data = {'lesson': row[2] or ''}
-
-                learnings.append({
-                    'id': row[0],
-                    'trade_id': row[1],
-                    'lesson': data.get('lesson', ''),
-                    'pattern': data.get('pattern', ''),
-                    'confidence': row[3] or 0,
-                    'coin': row[4] or 'unknown',
-                    'trade_pnl': row[5] or 0
-                })
+                    data = {"lesson": row[2] or ""}
+
+                learnings.append(
+                    {
+                        "id": row[0],
+                        "trade_id": row[1],
+                        "lesson": data.get("lesson", ""),
+                        "pattern": data.get("pattern", ""),
+                        "confidence": row[3] or 0,
+                        "coin": row[4] or "unknown",
+                        "trade_pnl": row[5] or 0,
+                    }
+                )
             return learnings
 
     def get_rule_changes(self) -> Dict[str, List[Dict[str, Any]]]:
         """Get rules created or status-changed today."""
         with self.db._get_connection() as conn:
@@ -93,70 +104,73 @@
             cursor.execute("""
                 SELECT id, rule_text, status, success_count, failure_count
                 FROM trading_rules
                 WHERE date(created_at) = date('now')
             """)
-            new_rules = [dict(zip(['id', 'rule_text', 'status', 'success', 'failure'], row))
-                        for row in cursor.fetchall()]
+            new_rules = [
+                dict(zip(["id", "rule_text", "status", "success", "failure"], row))
+                for row in cursor.fetchall()
+            ]
 
             # Get activity log for rule promotions/rejections today
             cursor.execute("""
                 SELECT description, details, created_at
                 FROM activity_log
                 WHERE activity_type IN ('rule_active', 'rule_rejected')
                 AND date(created_at) = date('now')
                 ORDER BY created_at DESC
             """)
-            status_changes = [dict(zip(['description', 'details', 'time'], row))
-                            for row in cursor.fetchall()]
-
-            return {
-                'new_rules': new_rules,
-                'status_changes': status_changes
-            }
+            status_changes = [
+                dict(zip(["description", "details", "time"], row))
+                for row in cursor.fetchall()
+            ]
+
+            return {"new_rules": new_rules, "status_changes": status_changes}
 
     def calculate_stats(self, trades: List[Dict]) -> Dict[str, Any]:
         """Calculate performance statistics from trades."""
         if not trades:
             return {
-                'total_trades': 0,
-                'winning_trades': 0,
-                'losing_trades': 0,
-                'win_rate': 0,
-                'total_pnl': 0,
-                'avg_pnl': 0,
-                'best_trade': None,
-                'worst_trade': None,
-                'avg_duration_mins': 0
+                "total_trades": 0,
+                "winning_trades": 0,
+                "losing_trades": 0,
+                "win_rate": 0,
+                "total_pnl": 0,
+                "avg_pnl": 0,
+                "best_trade": None,
+                "worst_trade": None,
+                "avg_duration_mins": 0,
             }
 
-        wins = [t for t in trades if t['pnl_usd'] > 0]
-        losses = [t for t in trades if t['pnl_usd'] <= 0]
-        total_pnl = sum(t['pnl_usd'] for t in trades)
-        durations = [t['duration_seconds'] or 0 for t in trades]
-
-        best = max(trades, key=lambda t: t['pnl_usd'])
-        worst = min(trades, key=lambda t: t['pnl_usd'])
+        wins = [t for t in trades if t["pnl_usd"] > 0]
+        losses = [t for t in trades if t["pnl_usd"] <= 0]
+        total_pnl = sum(t["pnl_usd"] for t in trades)
+        durations = [t["duration_seconds"] or 0 for t in trades]
+
+        best = max(trades, key=lambda t: t["pnl_usd"])
+        worst = min(trades, key=lambda t: t["pnl_usd"])
 
         return {
-            'total_trades': len(trades),
-            'winning_trades': len(wins),
-            'losing_trades': len(losses),
-            'win_rate': len(wins) / len(trades) if trades else 0,
-            'total_pnl': total_pnl,
-            'avg_pnl': total_pnl / len(trades),
-            'best_trade': {
-                'coin': best['coin_name'],
-                'pnl': best['pnl_usd'],
-                'pnl_pct': best['pnl_pct']
+            "total_trades": len(trades),
+            "winning_trades": len(wins),
+            "losing_trades": len(losses),
+            "win_rate": len(wins) / len(trades) if trades else 0,
+            "total_pnl": total_pnl,
+            "avg_pnl": total_pnl / len(trades),
+            "best_trade": {
+                "coin": best["coin_name"],
+                "pnl": best["pnl_usd"],
+                "pnl_pct": best["pnl_pct"],
             },
-            'worst_trade': {
-                'coin': worst['coin_name'],
-                'pnl': worst['pnl_usd'],
-                'pnl_pct': worst['pnl_pct']
+            "worst_trade": {
+                "coin": worst["coin_name"],
+                "pnl": worst["pnl_usd"],
+                "pnl_pct": worst["pnl_pct"],
             },
-            'avg_duration_mins': sum(durations) / len(durations) / 60 if durations else 0
+            "avg_duration_mins": (
+                sum(durations) / len(durations) / 60 if durations else 0
+            ),
         }
 
     def generate_summary(self) -> Dict[str, Any]:
         """Generate complete daily summary."""
         trades = self.get_today_trades()
@@ -164,30 +178,30 @@
         rule_changes = self.get_rule_changes()
         stats = self.calculate_stats(trades)
         account = self.db.get_account_state()
 
         return {
-            'date': date.today().isoformat(),
-            'generated_at': datetime.now().isoformat(),
-            'account': {
-                'balance': account.get('balance', 0),
-                'daily_pnl': account.get('daily_pnl', 0),
-                'total_pnl': account.get('total_pnl', 0)
+            "date": date.today().isoformat(),
+            "generated_at": datetime.now().isoformat(),
+            "account": {
+                "balance": account.get("balance", 0),
+                "daily_pnl": account.get("daily_pnl", 0),
+                "total_pnl": account.get("total_pnl", 0),
             },
-            'stats': stats,
-            'trades': trades,
-            'learnings': learnings,
-            'rules': rule_changes
+            "stats": stats,
+            "trades": trades,
+            "learnings": learnings,
+            "rules": rule_changes,
         }
 
     def format_text_report(self, summary: Dict = None) -> str:
         """Format summary as readable text report."""
         if summary is None:
             summary = self.generate_summary()
 
-        stats = summary['stats']
-        account = summary['account']
+        stats = summary["stats"]
+        account = summary["account"]
 
         lines = [
             "=" * 60,
             f"DAILY TRADING SUMMARY - {summary['date']}",
             "=" * 60,
@@ -206,46 +220,47 @@
             f"  Total P&L:   ${stats['total_pnl']:+,.2f}",
             f"  Avg P&L:     ${stats['avg_pnl']:+,.2f}",
             f"  Avg Duration: {stats['avg_duration_mins']:.1f} mins",
         ]
 
-        if stats['best_trade']:
-            lines.extend([
-                "",
-                f"  Best Trade:  {stats['best_trade']['coin'].upper()} "
-                f"${stats['best_trade']['pnl']:+,.2f} ({stats['best_trade']['pnl_pct']:+.1f}%)",
-                f"  Worst Trade: {stats['worst_trade']['coin'].upper()} "
-                f"${stats['worst_trade']['pnl']:+,.2f} ({stats['worst_trade']['pnl_pct']:+.1f}%)",
-            ])
+        if stats["best_trade"]:
+            lines.extend(
+                [
+                    "",
+                    f"  Best Trade:  {stats['best_trade']['coin'].upper()} "
+                    f"${stats['best_trade']['pnl']:+,.2f} ({stats['best_trade']['pnl_pct']:+.1f}%)",
+                    f"  Worst Trade: {stats['worst_trade']['coin'].upper()} "
+                    f"${stats['worst_trade']['pnl']:+,.2f} ({stats['worst_trade']['pnl_pct']:+.1f}%)",
+                ]
+            )
 
         # Learnings section
         lines.extend(["", "LEARNINGS GAINED", "-" * 40])
-        if summary['learnings']:
-            for i, l in enumerate(summary['learnings'][:5], 1):
+        if summary["learnings"]:
+            for i, l in enumerate(summary["learnings"][:5], 1):
                 conf = f"[{l['confidence']:.0%}]"
-                lesson_text = l['lesson'][:55] + "..." if len(l['lesson']) > 55 else l['lesson']
+                lesson_text = (
+                    l["lesson"][:55] + "..." if len(l["lesson"]) > 55 else l["lesson"]
+                )
                 lines.append(f"  {i}. {conf} {lesson_text}")
         else:
             lines.append("  No new learnings today")
 
         # Rules section
         lines.extend(["", "RULE CHANGES", "-" * 40])
-        rules = summary['rules']
-        if rules['new_rules']:
+        rules = summary["rules"]
+        if rules["new_rules"]:
             lines.append(f"  New rules created: {len(rules['new_rules'])}")
-        if rules['status_changes']:
-            for change in rules['status_changes']:
+        if rules["status_changes"]:
+            for change in rules["status_changes"]:
                 lines.append(f"  - {change['description']}")
-        if not rules['new_rules'] and not rules['status_changes']:
+        if not rules["new_rules"] and not rules["status_changes"]:
             lines.append("  No rule changes today")
 
-        lines.extend([
-            "",
-            "=" * 60,
-            f"Generated at {summary['generated_at'][:19]}",
-            "=" * 60
-        ])
+        lines.extend(
+            ["", "=" * 60, f"Generated at {summary['generated_at'][:19]}", "=" * 60]
+        )
 
         return "\n".join(lines)
 
     def save_report(self, output_dir: str = None) -> str:
         """Save daily report to file.
would reformat /mnt/c/documents/crypto-trading-bot/src/daily_summary.py
--- /mnt/c/documents/crypto-trading-bot/scripts/analyze_learning.py	2026-02-03 19:20:43.386807+00:00
+++ /mnt/c/documents/crypto-trading-bot/scripts/analyze_learning.py	2026-02-04 21:34:25.082529+00:00
@@ -39,11 +39,13 @@
         # Get all coins with scores
         with db._get_connection() as conn:
             cursor = conn.cursor()
 
             # Get coin scores
-            cursor.execute("SELECT coin, score, total_trades, win_rate, total_pnl FROM coin_scores")
+            cursor.execute(
+                "SELECT coin, score, total_trades, win_rate, total_pnl FROM coin_scores"
+            )
             coins = cursor.fetchall()
 
             if not coins:
                 results["message"] = "No coin data available"
                 return results
@@ -59,28 +61,32 @@
                     actual_good = (win_rate or 0) > 50 and (pnl or 0) > 0
 
                     if expected_good == actual_good:
                         results["correlation_positive"] += 1
 
-                    score_performance_pairs.append({
-                        "coin": coin,
-                        "score": score,
-                        "win_rate": win_rate,
-                        "pnl": pnl,
-                        "trades": trades,
-                        "expected_good": expected_good,
-                        "actual_good": actual_good,
-                        "correct": expected_good == actual_good,
-                    })
+                    score_performance_pairs.append(
+                        {
+                            "coin": coin,
+                            "score": score,
+                            "win_rate": win_rate,
+                            "pnl": pnl,
+                            "trades": trades,
+                            "expected_good": expected_good,
+                            "actual_good": actual_good,
+                            "correct": expected_good == actual_good,
+                        }
+                    )
 
             if results["coins_analyzed"] > 0:
                 results["score_accuracy"] = (
                     results["correlation_positive"] / results["coins_analyzed"] * 100
                 )
 
             # Top and bottom performers
-            sorted_by_pnl = sorted(score_performance_pairs, key=lambda x: x["pnl"] or 0, reverse=True)
+            sorted_by_pnl = sorted(
+                score_performance_pairs, key=lambda x: x["pnl"] or 0, reverse=True
+            )
             results["top_performers"] = sorted_by_pnl[:3]
             results["bottom_performers"] = sorted_by_pnl[-3:]
             results["details"] = score_performance_pairs
 
     except Exception as e:
@@ -135,19 +141,26 @@
                         high_conf_patterns.append(win_rate or 0)
                     elif conf and conf < 0.4:
                         low_conf_patterns.append(win_rate or 0)
 
             if high_conf_patterns:
-                results["high_confidence_win_rate"] = sum(high_conf_patterns) / len(high_conf_patterns)
+                results["high_confidence_win_rate"] = sum(high_conf_patterns) / len(
+                    high_conf_patterns
+                )
 
             if low_conf_patterns:
-                results["low_confidence_win_rate"] = sum(low_conf_patterns) / len(low_conf_patterns)
+                results["low_confidence_win_rate"] = sum(low_conf_patterns) / len(
+                    low_conf_patterns
+                )
 
             # Confidence accuracy: high conf should have higher win rate
             if high_conf_patterns and low_conf_patterns:
                 results["confidence_accuracy"] = (
-                    100 if results["high_confidence_win_rate"] > results["low_confidence_win_rate"] else 0
+                    100
+                    if results["high_confidence_win_rate"]
+                    > results["low_confidence_win_rate"]
+                    else 0
                 )
 
     except Exception as e:
         results["error"] = str(e)
 
@@ -182,21 +195,39 @@
 
             effective_count = 0
             harmful_count = 0
 
             for row in adaptations:
-                (adapt_id, action, target, conf, rating,
-                 wr_before, wr_after, pnl_before, pnl_after, applied_at) = row
+                (
+                    adapt_id,
+                    action,
+                    target,
+                    conf,
+                    rating,
+                    wr_before,
+                    wr_after,
+                    pnl_before,
+                    pnl_after,
+                    applied_at,
+                ) = row
 
                 adaptation_data = {
                     "id": adapt_id,
                     "action": action,
                     "target": target,
                     "confidence": conf,
                     "rating": rating,
-                    "win_rate_change": (wr_after or 0) - (wr_before or 0) if wr_after and wr_before else None,
-                    "pnl_change": (pnl_after or 0) - (pnl_before or 0) if pnl_after and pnl_before else None,
+                    "win_rate_change": (
+                        (wr_after or 0) - (wr_before or 0)
+                        if wr_after and wr_before
+                        else None
+                    ),
+                    "pnl_change": (
+                        (pnl_after or 0) - (pnl_before or 0)
+                        if pnl_after and pnl_before
+                        else None
+                    ),
                 }
                 results["details"].append(adaptation_data)
 
                 if rating and rating != "pending":
                     results["measured_adaptations"] += 1
@@ -211,12 +242,16 @@
                     elif rating == "harmful":
                         harmful_count += 1
                         results["by_type"][action_type]["harmful"] += 1
 
             if results["measured_adaptations"] > 0:
-                results["effective_rate"] = effective_count / results["measured_adaptations"] * 100
-                results["harmful_rate"] = harmful_count / results["measured_adaptations"] * 100
+                results["effective_rate"] = (
+                    effective_count / results["measured_adaptations"] * 100
+                )
+                results["harmful_rate"] = (
+                    harmful_count / results["measured_adaptations"] * 100
+                )
 
             # Convert defaultdict to regular dict
             results["by_type"] = dict(results["by_type"])
 
     except Exception as e:
@@ -242,69 +277,99 @@
             cursor = conn.cursor()
 
             # Get trade count
             cutoff = (datetime.now() - timedelta(days=days)).isoformat()
 
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM trade_journal
                 WHERE exit_time >= ?
-            """, (cutoff,))
+            """,
+                (cutoff,),
+            )
             results["total_trades"] = cursor.fetchone()[0] or 0
 
             # Get reflection count
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM reflections
                 WHERE created_at >= ?
-            """, (cutoff,))
+            """,
+                (cutoff,),
+            )
             results["total_reflections"] = cursor.fetchone()[0] or 0
 
             # Get insight count
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM insights
                 WHERE created_at >= ?
-            """, (cutoff,))
+            """,
+                (cutoff,),
+            )
             results["total_insights"] = cursor.fetchone()[0] or 0
 
             # Get adaptation count
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM adaptations
                 WHERE applied_at >= ?
-            """, (cutoff,))
+            """,
+                (cutoff,),
+            )
             results["total_adaptations"] = cursor.fetchone()[0] or 0
 
             # Calculate rates
             if results["total_trades"] > 0:
-                results["insight_rate"] = results["total_insights"] / results["total_trades"]
-                results["adaptation_rate"] = results["total_adaptations"] / results["total_trades"]
+                results["insight_rate"] = (
+                    results["total_insights"] / results["total_trades"]
+                )
+                results["adaptation_rate"] = (
+                    results["total_adaptations"] / results["total_trades"]
+                )
 
             # Daily breakdown
             for d in range(days):
-                day_start = (datetime.now() - timedelta(days=d+1)).replace(
-                    hour=0, minute=0, second=0
-                ).isoformat()
-                day_end = (datetime.now() - timedelta(days=d)).replace(
-                    hour=0, minute=0, second=0
-                ).isoformat()
-
-                cursor.execute("""
+                day_start = (
+                    (datetime.now() - timedelta(days=d + 1))
+                    .replace(hour=0, minute=0, second=0)
+                    .isoformat()
+                )
+                day_end = (
+                    (datetime.now() - timedelta(days=d))
+                    .replace(hour=0, minute=0, second=0)
+                    .isoformat()
+                )
+
+                cursor.execute(
+                    """
                     SELECT COUNT(*) FROM trade_journal
                     WHERE exit_time >= ? AND exit_time < ?
-                """, (day_start, day_end))
+                """,
+                    (day_start, day_end),
+                )
                 day_trades = cursor.fetchone()[0] or 0
 
-                cursor.execute("""
+                cursor.execute(
+                    """
                     SELECT COUNT(*) FROM adaptations
                     WHERE applied_at >= ? AND applied_at < ?
-                """, (day_start, day_end))
+                """,
+                    (day_start, day_end),
+                )
                 day_adaptations = cursor.fetchone()[0] or 0
 
-                results["daily_breakdown"].append({
-                    "day": d + 1,
-                    "date": (datetime.now() - timedelta(days=d+1)).strftime("%Y-%m-%d"),
-                    "trades": day_trades,
-                    "adaptations": day_adaptations,
-                })
+                results["daily_breakdown"].append(
+                    {
+                        "day": d + 1,
+                        "date": (datetime.now() - timedelta(days=d + 1)).strftime(
+                            "%Y-%m-%d"
+                        ),
+                        "trades": day_trades,
+                        "adaptations": day_adaptations,
+                    }
+                )
 
     except Exception as e:
         results["error"] = str(e)
 
     return results
@@ -331,28 +396,38 @@
     print(f"Score accuracy: {coin_results.get('score_accuracy', 0):.1f}%")
 
     if coin_results.get("top_performers"):
         print("\nTop Performers:")
         for p in coin_results["top_performers"][:3]:
-            print(f"  {p['coin']}: Score={p.get('score', 'N/A')}, "
-                  f"WinRate={p.get('win_rate', 0):.1f}%, P&L=${p.get('pnl', 0):.2f}")
+            print(
+                f"  {p['coin']}: Score={p.get('score', 'N/A')}, "
+                f"WinRate={p.get('win_rate', 0):.1f}%, P&L=${p.get('pnl', 0):.2f}"
+            )
 
     if coin_results.get("bottom_performers"):
         print("\nBottom Performers:")
         for p in coin_results["bottom_performers"][-3:]:
-            print(f"  {p['coin']}: Score={p.get('score', 'N/A')}, "
-                  f"WinRate={p.get('win_rate', 0):.1f}%, P&L=${p.get('pnl', 0):.2f}")
+            print(
+                f"  {p['coin']}: Score={p.get('score', 'N/A')}, "
+                f"WinRate={p.get('win_rate', 0):.1f}%, P&L=${p.get('pnl', 0):.2f}"
+            )
     print()
 
     # Pattern Learning
     print("-" * 70)
     print("PATTERN CONFIDENCE LEARNING")
     print("-" * 70)
     print(f"Patterns analyzed: {pattern_results.get('patterns_analyzed', 0)}")
-    print(f"High confidence win rate: {pattern_results.get('high_confidence_win_rate', 0):.1f}%")
-    print(f"Low confidence win rate: {pattern_results.get('low_confidence_win_rate', 0):.1f}%")
-    print(f"Confidence predicts outcomes: {'Yes' if pattern_results.get('confidence_accuracy', 0) > 50 else 'No'}")
+    print(
+        f"High confidence win rate: {pattern_results.get('high_confidence_win_rate', 0):.1f}%"
+    )
+    print(
+        f"Low confidence win rate: {pattern_results.get('low_confidence_win_rate', 0):.1f}%"
+    )
+    print(
+        f"Confidence predicts outcomes: {'Yes' if pattern_results.get('confidence_accuracy', 0) > 50 else 'No'}"
+    )
     print()
 
     # Adaptation Effectiveness
     print("-" * 70)
     print("ADAPTATION EFFECTIVENESS")
@@ -363,12 +438,14 @@
     print(f"Harmful rate: {adaptation_results.get('harmful_rate', 0):.1f}%")
 
     if adaptation_results.get("by_type"):
         print("\nBy Type:")
         for action, stats in adaptation_results["by_type"].items():
-            print(f"  {action}: {stats['count']} total, "
-                  f"{stats['effective']} effective, {stats['harmful']} harmful")
+            print(
+                f"  {action}: {stats['count']} total, "
+                f"{stats['effective']} effective, {stats['harmful']} harmful"
+            )
     print()
 
     # Learning Velocity
     print("-" * 70)
     print("LEARNING VELOCITY")
@@ -376,23 +453,29 @@
     print(f"Total trades: {velocity_results.get('total_trades', 0)}")
     print(f"Total reflections: {velocity_results.get('total_reflections', 0)}")
     print(f"Total insights: {velocity_results.get('total_insights', 0)}")
     print(f"Total adaptations: {velocity_results.get('total_adaptations', 0)}")
     print(f"Insight rate: {velocity_results.get('insight_rate', 0):.2%} per trade")
-    print(f"Adaptation rate: {velocity_results.get('adaptation_rate', 0):.2%} per trade")
+    print(
+        f"Adaptation rate: {velocity_results.get('adaptation_rate', 0):.2%} per trade"
+    )
 
     if velocity_results.get("daily_breakdown"):
         print("\nDaily Activity (last 7 days):")
         for day in velocity_results["daily_breakdown"][:7]:
-            print(f"  {day['date']}: {day['trades']} trades, {day['adaptations']} adaptations")
+            print(
+                f"  {day['date']}: {day['trades']} trades, {day['adaptations']} adaptations"
+            )
 
     print()
     print("=" * 70)
 
     # Overall Assessment
     score_ok = coin_results.get("score_accuracy", 0) >= 50
-    pattern_ok = pattern_results.get("high_confidence_win_rate", 0) >= pattern_results.get("low_confidence_win_rate", 0)
+    pattern_ok = pattern_results.get(
+        "high_confidence_win_rate", 0
+    ) >= pattern_results.get("low_confidence_win_rate", 0)
     adapt_ok = adaptation_results.get("harmful_rate", 100) < 30
     velocity_ok = velocity_results.get("total_trades", 0) > 0
 
     passed = sum([score_ok, pattern_ok, adapt_ok, velocity_ok])
     total = 4
@@ -442,10 +525,12 @@
             "learning_velocity": velocity_results,
         }
         Path(args.output).write_text(json.dumps(output, indent=2, default=str))
         print(f"Results saved to {args.output}")
     else:
-        print_analysis(coin_results, pattern_results, adaptation_results, velocity_results)
+        print_analysis(
+            coin_results, pattern_results, adaptation_results, velocity_results
+        )
 
 
 if __name__ == "__main__":
     main()
would reformat /mnt/c/documents/crypto-trading-bot/scripts/analyze_learning.py
--- /mnt/c/documents/crypto-trading-bot/scripts/validate_learning.py	2026-02-03 19:19:53.500454+00:00
+++ /mnt/c/documents/crypto-trading-bot/scripts/validate_learning.py	2026-02-04 21:34:25.091719+00:00
@@ -57,198 +57,256 @@
 
 # =============================================================================
 # Validation Functions
 # =============================================================================
 
+
 def validate_coin_scores() -> list[ValidationResult]:
     """Validate coin score updates."""
     results = []
 
     # Fetch coin data
     data = fetch_api("/api/knowledge/coins")
     if "error" in data:
-        return [ValidationResult(
-            "coin_scores_available",
-            False,
-            f"Cannot fetch coin data: {data['error']}"
-        )]
+        return [
+            ValidationResult(
+                "coin_scores_available",
+                False,
+                f"Cannot fetch coin data: {data['error']}",
+            )
+        ]
 
     coins = data.get("coins", [])
 
     # Test 1: Coins are being tracked
-    results.append(ValidationResult(
-        "coins_tracked",
-        len(coins) > 0,
-        f"Found {len(coins)} coins" if coins else "No coins tracked yet",
-        {"count": len(coins)}
-    ))
+    results.append(
+        ValidationResult(
+            "coins_tracked",
+            len(coins) > 0,
+            f"Found {len(coins)} coins" if coins else "No coins tracked yet",
+            {"count": len(coins)},
+        )
+    )
 
     # Test 2: Coins have trade data
     coins_with_trades = [c for c in coins if c.get("total_trades", 0) > 0]
-    results.append(ValidationResult(
-        "coins_have_trades",
-        len(coins_with_trades) > 0,
-        f"{len(coins_with_trades)} coins have trade data",
-        {"coins_with_trades": len(coins_with_trades)}
-    ))
+    results.append(
+        ValidationResult(
+            "coins_have_trades",
+            len(coins_with_trades) > 0,
+            f"{len(coins_with_trades)} coins have trade data",
+            {"coins_with_trades": len(coins_with_trades)},
+        )
+    )
 
     # Test 3: Scores vary (not all the same)
     if len(coins) >= 2:
         scores = [c.get("score", 50) for c in coins if c.get("total_trades", 0) > 0]
         if len(scores) >= 2:
             score_variance = max(scores) - min(scores) if scores else 0
-            results.append(ValidationResult(
-                "scores_vary",
-                score_variance > 5,
-                f"Score range: {min(scores):.1f} - {max(scores):.1f}",
-                {"min": min(scores), "max": max(scores), "variance": score_variance}
-            ))
+            results.append(
+                ValidationResult(
+                    "scores_vary",
+                    score_variance > 5,
+                    f"Score range: {min(scores):.1f} - {max(scores):.1f}",
+                    {
+                        "min": min(scores),
+                        "max": max(scores),
+                        "variance": score_variance,
+                    },
+                )
+            )
         else:
-            results.append(ValidationResult(
-                "scores_vary",
-                False,
-                "Not enough coins with trades to compare scores"
-            ))
+            results.append(
+                ValidationResult(
+                    "scores_vary",
+                    False,
+                    "Not enough coins with trades to compare scores",
+                )
+            )
 
     # Test 4: Score correlates with win rate
     coins_with_enough_trades = [c for c in coins if c.get("total_trades", 0) >= 5]
     if len(coins_with_enough_trades) >= 2:
         # Sort by win rate and check if scores follow
-        sorted_coins = sorted(coins_with_enough_trades, key=lambda c: c.get("win_rate", 0))
+        sorted_coins = sorted(
+            coins_with_enough_trades, key=lambda c: c.get("win_rate", 0)
+        )
         score_trend_correct = True
         for i in range(len(sorted_coins) - 1):
             # Higher win rate should generally mean higher score
-            if sorted_coins[i+1].get("win_rate", 0) > sorted_coins[i].get("win_rate", 0) + 20:
-                if sorted_coins[i+1].get("score", 0) < sorted_coins[i].get("score", 0):
+            if (
+                sorted_coins[i + 1].get("win_rate", 0)
+                > sorted_coins[i].get("win_rate", 0) + 20
+            ):
+                if sorted_coins[i + 1].get("score", 0) < sorted_coins[i].get(
+                    "score", 0
+                ):
                     score_trend_correct = False
                     break
 
-        results.append(ValidationResult(
-            "score_correlates_winrate",
-            score_trend_correct,
-            "Scores generally correlate with win rate" if score_trend_correct else "Score-winrate correlation weak",
-        ))
+        results.append(
+            ValidationResult(
+                "score_correlates_winrate",
+                score_trend_correct,
+                (
+                    "Scores generally correlate with win rate"
+                    if score_trend_correct
+                    else "Score-winrate correlation weak"
+                ),
+            )
+        )
 
     return results
 
 
 def validate_pattern_confidence() -> list[ValidationResult]:
     """Validate pattern confidence updates."""
     results = []
 
     data = fetch_api("/api/knowledge/patterns")
     if "error" in data:
-        return [ValidationResult(
-            "patterns_available",
-            False,
-            f"Cannot fetch pattern data: {data['error']}"
-        )]
+        return [
+            ValidationResult(
+                "patterns_available",
+                False,
+                f"Cannot fetch pattern data: {data['error']}",
+            )
+        ]
 
     patterns = data.get("patterns", [])
 
     # Test 1: Patterns exist
-    results.append(ValidationResult(
-        "patterns_exist",
-        len(patterns) > 0,
-        f"Found {len(patterns)} patterns" if patterns else "No patterns yet",
-        {"count": len(patterns)}
-    ))
+    results.append(
+        ValidationResult(
+            "patterns_exist",
+            len(patterns) > 0,
+            f"Found {len(patterns)} patterns" if patterns else "No patterns yet",
+            {"count": len(patterns)},
+        )
+    )
 
     # Test 2: Patterns have been used
     used_patterns = [p for p in patterns if p.get("usage_count", 0) > 0]
-    results.append(ValidationResult(
-        "patterns_used",
-        len(used_patterns) > 0,
-        f"{len(used_patterns)} patterns have been used",
-        {"used_count": len(used_patterns)}
-    ))
+    results.append(
+        ValidationResult(
+            "patterns_used",
+            len(used_patterns) > 0,
+            f"{len(used_patterns)} patterns have been used",
+            {"used_count": len(used_patterns)},
+        )
+    )
 
     # Test 3: Confidence varies
     if len(patterns) >= 2:
         confidences = [p.get("confidence", 0.5) for p in patterns]
         conf_variance = max(confidences) - min(confidences)
-        results.append(ValidationResult(
-            "confidence_varies",
-            conf_variance > 0.1,
-            f"Confidence range: {min(confidences):.2f} - {max(confidences):.2f}",
-            {"min": min(confidences), "max": max(confidences)}
-        ))
+        results.append(
+            ValidationResult(
+                "confidence_varies",
+                conf_variance > 0.1,
+                f"Confidence range: {min(confidences):.2f} - {max(confidences):.2f}",
+                {"min": min(confidences), "max": max(confidences)},
+            )
+        )
 
     # Test 4: Some patterns are active, some may be inactive
     active_patterns = [p for p in patterns if p.get("is_active", True)]
-    results.append(ValidationResult(
-        "active_patterns",
-        len(active_patterns) > 0,
-        f"{len(active_patterns)} active patterns",
-        {"active": len(active_patterns), "total": len(patterns)}
-    ))
+    results.append(
+        ValidationResult(
+            "active_patterns",
+            len(active_patterns) > 0,
+            f"{len(active_patterns)} active patterns",
+            {"active": len(active_patterns), "total": len(patterns)},
+        )
+    )
 
     return results
 
 
 def validate_adaptations() -> list[ValidationResult]:
     """Validate that adaptations are being triggered."""
     results = []
 
     data = fetch_api("/api/adaptations")
     if "error" in data:
-        return [ValidationResult(
-            "adaptations_available",
-            False,
-            f"Cannot fetch adaptation data: {data['error']}"
-        )]
+        return [
+            ValidationResult(
+                "adaptations_available",
+                False,
+                f"Cannot fetch adaptation data: {data['error']}",
+            )
+        ]
 
     adaptations = data.get("adaptations", [])
 
     # Test 1: Adaptations have occurred
-    results.append(ValidationResult(
-        "adaptations_occurred",
-        len(adaptations) > 0,
-        f"Found {len(adaptations)} adaptations" if adaptations else "No adaptations yet",
-        {"count": len(adaptations)}
-    ))
+    results.append(
+        ValidationResult(
+            "adaptations_occurred",
+            len(adaptations) > 0,
+            (
+                f"Found {len(adaptations)} adaptations"
+                if adaptations
+                else "No adaptations yet"
+            ),
+            {"count": len(adaptations)},
+        )
+    )
 
     # Test 2: Effectiveness is being measured
     eff_data = fetch_api("/api/adaptations/effectiveness")
     if "error" not in eff_data:
-        measured = sum([
-            eff_data.get("highly_effective", 0),
-            eff_data.get("effective", 0),
-            eff_data.get("neutral", 0),
-            eff_data.get("ineffective", 0),
-            eff_data.get("harmful", 0),
-        ])
+        measured = sum(
+            [
+                eff_data.get("highly_effective", 0),
+                eff_data.get("effective", 0),
+                eff_data.get("neutral", 0),
+                eff_data.get("ineffective", 0),
+                eff_data.get("harmful", 0),
+            ]
+        )
         pending = eff_data.get("pending", 0)
 
-        results.append(ValidationResult(
-            "effectiveness_measured",
-            measured > 0 or pending > 0,
-            f"{measured} measured, {pending} pending",
-            eff_data
-        ))
+        results.append(
+            ValidationResult(
+                "effectiveness_measured",
+                measured > 0 or pending > 0,
+                f"{measured} measured, {pending} pending",
+                eff_data,
+            )
+        )
 
         # Test 3: Not too many harmful adaptations
         total_rated = measured
         harmful = eff_data.get("harmful", 0)
         harmful_pct = (harmful / total_rated * 100) if total_rated > 0 else 0
 
-        results.append(ValidationResult(
-            "harmful_rate_acceptable",
-            harmful_pct < 30,
-            f"Harmful rate: {harmful_pct:.1f}%",
-            {"harmful": harmful, "total_rated": total_rated, "harmful_pct": harmful_pct}
-        ))
+        results.append(
+            ValidationResult(
+                "harmful_rate_acceptable",
+                harmful_pct < 30,
+                f"Harmful rate: {harmful_pct:.1f}%",
+                {
+                    "harmful": harmful,
+                    "total_rated": total_rated,
+                    "harmful_pct": harmful_pct,
+                },
+            )
+        )
 
     # Test 4: Various adaptation types
     if adaptations:
         action_types = set(a.get("action", "") for a in adaptations)
-        results.append(ValidationResult(
-            "diverse_adaptations",
-            len(action_types) >= 1,
-            f"Adaptation types: {', '.join(action_types)}",
-            {"types": list(action_types)}
-        ))
+        results.append(
+            ValidationResult(
+                "diverse_adaptations",
+                len(action_types) >= 1,
+                f"Adaptation types: {', '.join(action_types)}",
+                {"types": list(action_types)},
+            )
+        )
 
     return results
 
 
 def validate_strategist_usage() -> list[ValidationResult]:
@@ -256,53 +314,72 @@
     results = []
 
     # Get knowledge context
     context = fetch_api("/api/knowledge/context")
     if "error" in context:
-        return [ValidationResult(
-            "context_available",
-            False,
-            f"Cannot fetch context: {context['error']}"
-        )]
+        return [
+            ValidationResult(
+                "context_available", False, f"Cannot fetch context: {context['error']}"
+            )
+        ]
 
     # Test 1: Context has coin information
     has_coins = (
-        "coins" in context or
-        "coin_summaries" in context or
-        "good_coins" in context
-    )
-    results.append(ValidationResult(
-        "context_has_coins",
-        has_coins,
-        "Context includes coin information" if has_coins else "No coin info in context",
-    ))
+        "coins" in context or "coin_summaries" in context or "good_coins" in context
+    )
+    results.append(
+        ValidationResult(
+            "context_has_coins",
+            has_coins,
+            (
+                "Context includes coin information"
+                if has_coins
+                else "No coin info in context"
+            ),
+        )
+    )
 
     # Test 2: Blacklist is in context
     blacklist = fetch_api("/api/knowledge/blacklist")
     blacklist_coins = blacklist.get("coins", [])
-    results.append(ValidationResult(
-        "blacklist_in_context",
-        "blacklist" in context or len(blacklist_coins) >= 0,  # Always true if endpoint works
-        f"{len(blacklist_coins)} coins blacklisted",
-        {"blacklisted": len(blacklist_coins)}
-    ))
+    results.append(
+        ValidationResult(
+            "blacklist_in_context",
+            "blacklist" in context
+            or len(blacklist_coins) >= 0,  # Always true if endpoint works
+            f"{len(blacklist_coins)} coins blacklisted",
+            {"blacklisted": len(blacklist_coins)},
+        )
+    )
 
     # Test 3: Patterns in context
     has_patterns = "patterns" in context or "pattern_summaries" in context
-    results.append(ValidationResult(
-        "context_has_patterns",
-        has_patterns,
-        "Context includes pattern information" if has_patterns else "No pattern info",
-    ))
+    results.append(
+        ValidationResult(
+            "context_has_patterns",
+            has_patterns,
+            (
+                "Context includes pattern information"
+                if has_patterns
+                else "No pattern info"
+            ),
+        )
+    )
 
     # Test 4: Rules in context
     has_rules = "regime_rules" in context or "rules" in context
-    results.append(ValidationResult(
-        "context_has_rules",
-        has_rules or True,  # Rules are optional
-        "Context includes regime rules" if has_rules else "No regime rules yet (OK)",
-    ))
+    results.append(
+        ValidationResult(
+            "context_has_rules",
+            has_rules or True,  # Rules are optional
+            (
+                "Context includes regime rules"
+                if has_rules
+                else "No regime rules yet (OK)"
+            ),
+        )
+    )
 
     return results
 
 
 def validate_knowledge_growth() -> list[ValidationResult]:
@@ -310,62 +387,71 @@
     results = []
 
     # Get loop stats
     stats = fetch_api("/api/loop-stats")
     if "error" in stats:
-        return [ValidationResult(
-            "stats_available",
-            False,
-            f"Cannot fetch stats: {stats['error']}"
-        )]
+        return [
+            ValidationResult(
+                "stats_available", False, f"Cannot fetch stats: {stats['error']}"
+            )
+        ]
 
     # Test 1: Trades are happening
     total_trades = stats.get("total_trades", 0)
-    results.append(ValidationResult(
-        "trades_executed",
-        total_trades > 0,
-        f"{total_trades} trades executed",
-        {"total_trades": total_trades}
-    ))
+    results.append(
+        ValidationResult(
+            "trades_executed",
+            total_trades > 0,
+            f"{total_trades} trades executed",
+            {"total_trades": total_trades},
+        )
+    )
 
     # Test 2: Reflections are running
     reflections = stats.get("total_reflections", 0)
-    results.append(ValidationResult(
-        "reflections_running",
-        reflections > 0,
-        f"{reflections} reflections completed",
-        {"reflections": reflections}
-    ))
+    results.append(
+        ValidationResult(
+            "reflections_running",
+            reflections > 0,
+            f"{reflections} reflections completed",
+            {"reflections": reflections},
+        )
+    )
 
     # Test 3: Insights being generated
     insights = stats.get("total_insights", 0)
-    results.append(ValidationResult(
-        "insights_generated",
-        insights >= 0,  # Can be 0 if no insights yet
-        f"{insights} insights generated",
-        {"insights": insights}
-    ))
+    results.append(
+        ValidationResult(
+            "insights_generated",
+            insights >= 0,  # Can be 0 if no insights yet
+            f"{insights} insights generated",
+            {"insights": insights},
+        )
+    )
 
     # Test 4: Learning rate (insights per trade)
     if total_trades > 10:
         insight_rate = insights / total_trades if total_trades > 0 else 0
         adaptations = stats.get("total_adaptations", 0)
         adaptation_rate = adaptations / total_trades if total_trades > 0 else 0
 
-        results.append(ValidationResult(
-            "learning_rate",
-            adaptation_rate > 0 or total_trades < 20,  # Give time to accumulate
-            f"Adaptation rate: {adaptation_rate:.2%} per trade",
-            {"insight_rate": insight_rate, "adaptation_rate": adaptation_rate}
-        ))
+        results.append(
+            ValidationResult(
+                "learning_rate",
+                adaptation_rate > 0 or total_trades < 20,  # Give time to accumulate
+                f"Adaptation rate: {adaptation_rate:.2%} per trade",
+                {"insight_rate": insight_rate, "adaptation_rate": adaptation_rate},
+            )
+        )
 
     return results
 
 
 # =============================================================================
 # Main
 # =============================================================================
+
 
 def run_validation(verbose: bool = False) -> dict:
     """Run all learning validation checks."""
     all_results = {
         "coin_scores": validate_coin_scores(),
@@ -391,17 +477,19 @@
     for category, tests in results.items():
         passed = sum(1 for t in tests if t.passed)
         total = len(tests)
         status = "PASS" if passed == total else "PARTIAL" if passed > 0 else "FAIL"
         status_color = {
-            "PASS": "\033[92m",    # Green
-            "PARTIAL": "\033[93m", # Yellow
-            "FAIL": "\033[91m",    # Red
+            "PASS": "\033[92m",  # Green
+            "PARTIAL": "\033[93m",  # Yellow
+            "FAIL": "\033[91m",  # Red
         }.get(status, "")
         reset = "\033[0m"
 
-        print(f"\n{category.upper().replace('_', ' ')}: {status_color}{passed}/{total} {status}{reset}")
+        print(
+            f"\n{category.upper().replace('_', ' ')}: {status_color}{passed}/{total} {status}{reset}"
+        )
 
         for test in tests:
             icon = "\033[92m\033[0m" if test.passed else "\033[91m\033[0m"
             print(f"  {icon} {test.name}")
             if test.reason:
@@ -431,13 +519,12 @@
 
     if args.json:
         output = {
             "timestamp": datetime.now().isoformat(),
             "results": {
-                cat: [r.to_dict() for r in tests]
-                for cat, tests in results.items()
-            }
+                cat: [r.to_dict() for r in tests] for cat, tests in results.items()
+            },
         }
         print(json.dumps(output, indent=2))
     else:
         passed = print_results(results)
         sys.exit(0 if passed else 1)
would reformat /mnt/c/documents/crypto-trading-bot/scripts/validate_learning.py
--- /mnt/c/documents/crypto-trading-bot/src/knowledge.py	2026-02-03 18:32:11.457317+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/knowledge.py	2026-02-04 21:34:25.095653+00:00
@@ -43,12 +43,14 @@
         self.db = db
         self._coin_scores: Dict[str, CoinScore] = {}
         self._patterns: Dict[str, TradingPattern] = {}
         self._regime_rules: Dict[str, RegimeRule] = {}
         self._load_from_db()
-        logger.info(f"KnowledgeBrain initialized: {len(self._coin_scores)} coins, "
-                   f"{len(self._patterns)} patterns, {len(self._regime_rules)} rules")
+        logger.info(
+            f"KnowledgeBrain initialized: {len(self._coin_scores)} coins, "
+            f"{len(self._patterns)} patterns, {len(self._regime_rules)} rules"
+        )
 
     def _load_from_db(self) -> None:
         """Load all knowledge data from database."""
         # Load coin scores
         for row in self.db.get_all_coin_scores():
@@ -83,13 +85,11 @@
 
         Returns:
             List of CoinScore objects.
         """
         return sorted(
-            self._coin_scores.values(),
-            key=lambda s: s.total_pnl,
-            reverse=True
+            self._coin_scores.values(), key=lambda s: s.total_pnl, reverse=True
         )
 
     def update_coin_score(self, coin: str, trade_result: Dict[str, Any]) -> CoinScore:
         """Update coin score with a new trade result.
 
@@ -114,30 +114,36 @@
             score.wins += 1
             # Update running average for winners
             if score.wins == 1:
                 score.avg_winner = pnl
             else:
-                score.avg_winner = ((score.avg_winner * (score.wins - 1)) + pnl) / score.wins
+                score.avg_winner = (
+                    (score.avg_winner * (score.wins - 1)) + pnl
+                ) / score.wins
         else:
             score.losses += 1
             # Update running average for losers
             if score.losses == 1:
                 score.avg_loser = pnl
             else:
-                score.avg_loser = ((score.avg_loser * (score.losses - 1)) + pnl) / score.losses
+                score.avg_loser = (
+                    (score.avg_loser * (score.losses - 1)) + pnl
+                ) / score.losses
 
         score.recalculate_stats()
         score.last_updated = datetime.now()
 
         # Update trend based on recent performance
         score.trend = self._calculate_trend(score)
 
         # Persist to database
         self.db.save_coin_score(score.to_dict())
 
-        logger.debug(f"Updated {coin} score: {score.total_trades} trades, "
-                    f"{score.win_rate:.1%} win rate, ${score.total_pnl:.2f} total P&L")
+        logger.debug(
+            f"Updated {coin} score: {score.total_trades} trades, "
+            f"{score.win_rate:.1%} win rate, ${score.total_pnl:.2f} total P&L"
+        )
 
         return score
 
     def _calculate_trend(self, score: CoinScore) -> str:
         """Calculate trend for a coin based on recent performance.
@@ -158,39 +164,45 @@
             return "improving"
         elif score.win_rate <= 0.35:
             return "degrading"
         return "stable"
 
-    def get_good_coins(self, min_trades: int = 5, min_win_rate: float = 0.5) -> List[str]:
+    def get_good_coins(
+        self, min_trades: int = 5, min_win_rate: float = 0.5
+    ) -> List[str]:
         """Get coins with good performance.
 
         Args:
             min_trades: Minimum trades required for evaluation.
             min_win_rate: Minimum win rate to be considered "good".
 
         Returns:
             List of coin symbols meeting criteria.
         """
         return [
-            score.coin for score in self._coin_scores.values()
+            score.coin
+            for score in self._coin_scores.values()
             if score.total_trades >= min_trades
             and score.win_rate >= min_win_rate
             and not score.is_blacklisted
         ]
 
-    def get_bad_coins(self, min_trades: int = 5, max_win_rate: float = 0.35) -> List[str]:
+    def get_bad_coins(
+        self, min_trades: int = 5, max_win_rate: float = 0.35
+    ) -> List[str]:
         """Get coins with poor performance.
 
         Args:
             min_trades: Minimum trades required for evaluation.
             max_win_rate: Maximum win rate to be considered "bad".
 
         Returns:
             List of coin symbols meeting criteria.
         """
         return [
-            score.coin for score in self._coin_scores.values()
+            score.coin
+            for score in self._coin_scores.values()
             if score.total_trades >= min_trades
             and score.win_rate <= max_win_rate
             and not score.is_blacklisted  # Already blacklisted coins separate
         ]
 
@@ -255,12 +267,11 @@
 
         Returns:
             List of blacklisted coin symbols.
         """
         return [
-            score.coin for score in self._coin_scores.values()
-            if score.is_blacklisted
+            score.coin for score in self._coin_scores.values() if score.is_blacklisted
         ]
 
     def is_blacklisted(self, coin: str) -> bool:
         """Check if a coin is blacklisted.
 
@@ -328,12 +339,14 @@
         # Update confidence based on performance
         if pattern.times_used >= 5:
             pattern.confidence = min(0.9, max(0.1, pattern.win_rate))
 
         self.db.save_pattern(pattern.to_dict())
-        logger.debug(f"Updated pattern {pattern_id}: {pattern.times_used} uses, "
-                    f"{pattern.win_rate:.1%} win rate")
+        logger.debug(
+            f"Updated pattern {pattern_id}: {pattern.times_used} uses, "
+            f"{pattern.win_rate:.1%} win rate"
+        )
 
     def deactivate_pattern(self, pattern_id: str) -> None:
         """Deactivate a pattern (stop using it).
 
         Args:
@@ -368,13 +381,11 @@
                 logger.info(f"Reactivated pattern from database: {pattern_id}")
             else:
                 logger.warning(f"Pattern {pattern_id} not found for reactivation")
 
     def get_winning_patterns(
-        self,
-        min_uses: int = 5,
-        min_win_rate: float = 0.55
+        self, min_uses: int = 5, min_win_rate: float = 0.55
     ) -> List[TradingPattern]:
         """Get patterns with proven track records.
 
         Args:
             min_uses: Minimum times used for evaluation.
@@ -382,14 +393,13 @@
 
         Returns:
             List of winning patterns sorted by confidence.
         """
         winning = [
-            p for p in self._patterns.values()
-            if p.is_active
-            and p.times_used >= min_uses
-            and p.win_rate >= min_win_rate
+            p
+            for p in self._patterns.values()
+            if p.is_active and p.times_used >= min_uses and p.win_rate >= min_win_rate
         ]
         return sorted(winning, key=lambda p: p.confidence, reverse=True)
 
     # ========== Regime Rules ==========
 
@@ -410,14 +420,11 @@
         self._regime_rules[rule.rule_id] = rule
         self.db.save_rule(rule.to_dict())
         logger.info(f"Added rule: {rule.rule_id} - {rule.description}")
 
     def update_rule_stats(
-        self,
-        rule_id: str,
-        triggered: bool,
-        saved_pnl: float = 0.0
+        self, rule_id: str, triggered: bool, saved_pnl: float = 0.0
     ) -> None:
         """Update rule statistics after evaluation.
 
         Args:
             rule_id: Rule identifier.
would reformat /mnt/c/documents/crypto-trading-bot/src/knowledge.py
--- /mnt/c/documents/crypto-trading-bot/scripts/generate_report.py	2026-02-03 19:34:09.969155+00:00
+++ /mnt/c/documents/crypto-trading-bot/scripts/generate_report.py	2026-02-04 21:34:25.102839+00:00
@@ -42,19 +42,22 @@
     """Load trades from database."""
     cutoff = (datetime.now() - timedelta(days=days)).isoformat()
 
     with db._get_connection() as conn:
         cursor = conn.cursor()
-        cursor.execute("""
+        cursor.execute(
+            """
             SELECT
                 trade_id, coin, direction, entry_price, exit_price,
                 position_size_usd, pnl_usd, pnl_pct, entry_time, exit_time,
                 exit_reason, pattern_id, strategy_id, duration_seconds
             FROM trade_journal
             WHERE exit_time >= ?
             ORDER BY exit_time ASC
-        """, (cutoff,))
+        """,
+            (cutoff,),
+        )
 
         rows = cursor.fetchall()
 
     return [
         {
@@ -280,88 +283,110 @@
         "CONCLUSION",
         "-" * 40,
     ]
 
     if change.get("improved"):
-        lines.extend([
-            "The system shows clear improvement over time:",
-            f"  - Win rate improved by {change.get('win_rate_change', 0):+.1f} percentage points",
-            f"  - Profit factor changed by {change.get('profit_factor_change', 0):+.2f}",
-            f"  - Average P&L per trade changed by ${change.get('avg_pnl_change', 0):+.2f}",
-            "",
-            "STATUS: LEARNING IS WORKING",
-        ])
+        lines.extend(
+            [
+                "The system shows clear improvement over time:",
+                f"  - Win rate improved by {change.get('win_rate_change', 0):+.1f} percentage points",
+                f"  - Profit factor changed by {change.get('profit_factor_change', 0):+.2f}",
+                f"  - Average P&L per trade changed by ${change.get('avg_pnl_change', 0):+.2f}",
+                "",
+                "STATUS: LEARNING IS WORKING",
+            ]
+        )
     else:
-        lines.extend([
-            "The system does not show clear improvement:",
-            f"  - Win rate changed by {change.get('win_rate_change', 0):+.1f} percentage points",
-            f"  - Profit factor changed by {change.get('profit_factor_change', 0):+.2f}",
-            "",
-            "STATUS: LEARNING NEEDS INVESTIGATION",
-        ])
+        lines.extend(
+            [
+                "The system does not show clear improvement:",
+                f"  - Win rate changed by {change.get('win_rate_change', 0):+.1f} percentage points",
+                f"  - Profit factor changed by {change.get('profit_factor_change', 0):+.2f}",
+                "",
+                "STATUS: LEARNING NEEDS INVESTIGATION",
+            ]
+        )
 
     lines.append("=" * 80)
 
     return "\n".join(lines)
 
 
-def generate_detailed_report(db: Database, trades: list, output_dir: str, days: int) -> None:
+def generate_detailed_report(
+    db: Database, trades: list, output_dir: str, days: int
+) -> None:
     """Generate all detailed reports to a directory."""
     os.makedirs(output_dir, exist_ok=True)
 
     # Breakdown analyses
     by_hour = analyze_by_hour(trades)
     by_coin = analyze_by_coin(trades)
     by_pattern = analyze_by_pattern(trades)
 
     # Hour analysis
     hour_lines = ["PERFORMANCE BY HOUR", "=" * 60, ""]
-    hour_lines.append(f"{'Hour':>6} {'Trades':>8} {'Win Rate':>10} {'P&L':>12} {'Profit Factor':>15}")
+    hour_lines.append(
+        f"{'Hour':>6} {'Trades':>8} {'Win Rate':>10} {'P&L':>12} {'Profit Factor':>15}"
+    )
     hour_lines.append("-" * 60)
     for hour in sorted(by_hour.keys()):
         m = by_hour[hour]
         hour_lines.append(
             f"{hour:>6} {m.total_trades:>8} {m.win_rate:>9.1f}% ${m.total_pnl:>10.2f} {m.profit_factor:>15.2f}"
         )
 
     best_worst_hours = get_best_worst_hours(by_hour)
     hour_lines.extend(["", "Best Hours:"])
     for h in best_worst_hours.get("best_hours", []):
-        hour_lines.append(f"  Hour {h['hour']}: {h['win_rate']:.1f}% win rate, ${h['pnl']:.2f} P&L")
+        hour_lines.append(
+            f"  Hour {h['hour']}: {h['win_rate']:.1f}% win rate, ${h['pnl']:.2f} P&L"
+        )
     hour_lines.extend(["", "Worst Hours:"])
     for h in best_worst_hours.get("worst_hours", []):
-        hour_lines.append(f"  Hour {h['hour']}: {h['win_rate']:.1f}% win rate, ${h['pnl']:.2f} P&L")
+        hour_lines.append(
+            f"  Hour {h['hour']}: {h['win_rate']:.1f}% win rate, ${h['pnl']:.2f} P&L"
+        )
 
     with open(os.path.join(output_dir, "by_hour.txt"), "w") as f:
         f.write("\n".join(hour_lines))
 
     # Coin analysis
     coin_lines = ["PERFORMANCE BY COIN", "=" * 60, ""]
-    coin_lines.append(f"{'Coin':>10} {'Trades':>8} {'Win Rate':>10} {'P&L':>12} {'Profit Factor':>15}")
+    coin_lines.append(
+        f"{'Coin':>10} {'Trades':>8} {'Win Rate':>10} {'P&L':>12} {'Profit Factor':>15}"
+    )
     coin_lines.append("-" * 60)
-    for coin in sorted(by_coin.keys(), key=lambda c: by_coin[c].total_pnl, reverse=True):
+    for coin in sorted(
+        by_coin.keys(), key=lambda c: by_coin[c].total_pnl, reverse=True
+    ):
         m = by_coin[coin]
         coin_lines.append(
             f"{coin:>10} {m.total_trades:>8} {m.win_rate:>9.1f}% ${m.total_pnl:>10.2f} {m.profit_factor:>15.2f}"
         )
 
     best_worst_coins = get_best_worst_coins(by_coin)
     coin_lines.extend(["", "Best Coins:"])
     for c in best_worst_coins.get("best_coins", []):
-        coin_lines.append(f"  {c['coin']}: ${c['pnl']:.2f} P&L, {c['win_rate']:.1f}% win rate")
+        coin_lines.append(
+            f"  {c['coin']}: ${c['pnl']:.2f} P&L, {c['win_rate']:.1f}% win rate"
+        )
     coin_lines.extend(["", "Worst Coins:"])
     for c in best_worst_coins.get("worst_coins", []):
-        coin_lines.append(f"  {c['coin']}: ${c['pnl']:.2f} P&L, {c['win_rate']:.1f}% win rate")
+        coin_lines.append(
+            f"  {c['coin']}: ${c['pnl']:.2f} P&L, {c['win_rate']:.1f}% win rate"
+        )
 
     with open(os.path.join(output_dir, "by_coin.txt"), "w") as f:
         f.write("\n".join(coin_lines))
 
     # Pattern analysis
     pattern_lines = ["PERFORMANCE BY PATTERN", "=" * 60, ""]
     pattern_lines.append(f"{'Pattern':>25} {'Trades':>8} {'Win Rate':>10} {'P&L':>12}")
     pattern_lines.append("-" * 60)
-    for pattern in sorted(by_pattern.keys(), key=lambda p: by_pattern[p].total_pnl, reverse=True):
+    for pattern in sorted(
+        by_pattern.keys(), key=lambda p: by_pattern[p].total_pnl, reverse=True
+    ):
         m = by_pattern[pattern]
         pattern_lines.append(
             f"{pattern[:25]:>25} {m.total_trades:>8} {m.win_rate:>9.1f}% ${m.total_pnl:>10.2f}"
         )
 
@@ -374,12 +399,13 @@
 def main():
     parser = argparse.ArgumentParser(description="Generate Performance Reports")
     parser.add_argument("--db", default="data/trading_bot.db", help="Database path")
     parser.add_argument("--output", "-o", default="reports", help="Output directory")
     parser.add_argument("--days", type=int, default=7, help="Days to analyze")
-    parser.add_argument("--format", choices=["text", "json"], default="text",
-                       help="Output format")
+    parser.add_argument(
+        "--format", choices=["text", "json"], default="text", help="Output format"
+    )
     args = parser.parse_args()
 
     if not os.path.exists(args.db):
         print(f"ERROR: Database not found at {args.db}")
         sys.exit(1)
@@ -412,11 +438,13 @@
 
         with open(os.path.join(args.output, "improvement.txt"), "w") as f:
             f.write(improvement)
 
         # Generate detailed breakdowns
-        generate_detailed_report(db, trades, os.path.join(args.output, "detailed"), args.days)
+        generate_detailed_report(
+            db, trades, os.path.join(args.output, "detailed"), args.days
+        )
 
         # Print summary to console
         print(summary)
 
     elif args.format == "json":
would reformat /mnt/c/documents/crypto-trading-bot/scripts/generate_report.py
--- /mnt/c/documents/crypto-trading-bot/src/sentiment/__init__.py	2026-02-04 15:44:26.256737+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/sentiment/__init__.py	2026-02-04 21:34:25.113552+00:00
@@ -1,6 +1,7 @@
 """Sentiment analysis module for market context."""
+
 from .fear_greed import FearGreedFetcher, FearGreedData
 from .btc_correlation import BTCCorrelationTracker, BTCCorrelation
 from .news_feed import NewsFeedFetcher, NewsItem, NewsFeed
 from .social_sentiment import SocialSentimentFetcher, SocialMetrics
 from .context_manager import ContextManager, MarketContext, CoinContext
would reformat /mnt/c/documents/crypto-trading-bot/src/sentiment/__init__.py
--- /mnt/c/documents/crypto-trading-bot/src/analysis/learning.py	2026-02-03 19:32:36.119776+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/analysis/learning.py	2026-02-04 21:34:25.119883+00:00
@@ -28,25 +28,28 @@
     """
     results = {
         "total_coins": 0,
         "coins_with_enough_data": 0,
         "high_score_coins": [],  # Score > 60
-        "low_score_coins": [],   # Score < 40
+        "low_score_coins": [],  # Score < 40
         "correlation": 0.0,
         "accuracy_assessment": "",
     }
 
     try:
         with db._get_connection() as conn:
             cursor = conn.cursor()
 
             # Get coin scores with trade data
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT coin, score, total_trades, win_rate, total_pnl
                 FROM coin_scores
                 WHERE total_trades >= ?
-            """, (min_trades,))
+            """,
+                (min_trades,),
+            )
 
             coins = cursor.fetchall()
             results["total_coins"] = len(coins)
 
             if not coins:
@@ -80,42 +83,62 @@
                     low_score_wins.append(win_rate or 0)
                     low_score_pnl.append(pnl or 0)
 
             # Calculate averages
             if high_score_wins:
-                results["high_score_avg_win_rate"] = sum(high_score_wins) / len(high_score_wins)
-                results["high_score_avg_pnl"] = sum(high_score_pnl) / len(high_score_pnl)
+                results["high_score_avg_win_rate"] = sum(high_score_wins) / len(
+                    high_score_wins
+                )
+                results["high_score_avg_pnl"] = sum(high_score_pnl) / len(
+                    high_score_pnl
+                )
             else:
                 results["high_score_avg_win_rate"] = 0
                 results["high_score_avg_pnl"] = 0
 
             if low_score_wins:
-                results["low_score_avg_win_rate"] = sum(low_score_wins) / len(low_score_wins)
+                results["low_score_avg_win_rate"] = sum(low_score_wins) / len(
+                    low_score_wins
+                )
                 results["low_score_avg_pnl"] = sum(low_score_pnl) / len(low_score_pnl)
             else:
                 results["low_score_avg_win_rate"] = 0
                 results["low_score_avg_pnl"] = 0
 
             # Simple correlation check
             if high_score_wins and low_score_wins:
                 # If high score coins have better win rate, scores are accurate
-                if results["high_score_avg_win_rate"] > results["low_score_avg_win_rate"]:
-                    diff = results["high_score_avg_win_rate"] - results["low_score_avg_win_rate"]
+                if (
+                    results["high_score_avg_win_rate"]
+                    > results["low_score_avg_win_rate"]
+                ):
+                    diff = (
+                        results["high_score_avg_win_rate"]
+                        - results["low_score_avg_win_rate"]
+                    )
                     if diff > 20:
                         results["correlation"] = 0.8
-                        results["accuracy_assessment"] = "STRONG - Scores accurately predict performance"
+                        results["accuracy_assessment"] = (
+                            "STRONG - Scores accurately predict performance"
+                        )
                     elif diff > 10:
                         results["correlation"] = 0.6
-                        results["accuracy_assessment"] = "MODERATE - Scores somewhat predict performance"
+                        results["accuracy_assessment"] = (
+                            "MODERATE - Scores somewhat predict performance"
+                        )
                     else:
                         results["correlation"] = 0.4
-                        results["accuracy_assessment"] = "WEAK - Scores slightly predict performance"
+                        results["accuracy_assessment"] = (
+                            "WEAK - Scores slightly predict performance"
+                        )
                 else:
                     results["correlation"] = -0.2
                     results["accuracy_assessment"] = "INVERTED - Scores may be wrong"
             else:
-                results["accuracy_assessment"] = "INSUFFICIENT DATA - Need more varied scores"
+                results["accuracy_assessment"] = (
+                    "INSUFFICIENT DATA - Need more varied scores"
+                )
 
     except Exception as e:
         results["error"] = str(e)
 
     return results
@@ -162,12 +185,22 @@
             results["total_adaptations"] = len(adaptations)
 
             by_type = defaultdict(lambda: {"count": 0, "effective": 0, "harmful": 0})
 
             for row in adaptations:
-                (adapt_id, action, target, conf, rating,
-                 wr_before, wr_after, pnl_before, pnl_after, applied_at) = row
+                (
+                    adapt_id,
+                    action,
+                    target,
+                    conf,
+                    rating,
+                    wr_before,
+                    wr_after,
+                    pnl_before,
+                    pnl_after,
+                    applied_at,
+                ) = row
 
                 action = action or "unknown"
                 rating = rating or "pending"
 
                 # Count by rating
@@ -194,24 +227,38 @@
 
                 by_type[action]["count"] += 1
 
                 # Track recent adaptations
                 if len(results["recent_adaptations"]) < 10:
-                    results["recent_adaptations"].append({
-                        "id": adapt_id,
-                        "action": action,
-                        "target": target,
-                        "rating": rating,
-                        "win_rate_change": (wr_after or 0) - (wr_before or 0) if wr_after and wr_before else None,
-                        "pnl_change": (pnl_after or 0) - (pnl_before or 0) if pnl_after and pnl_before else None,
-                    })
+                    results["recent_adaptations"].append(
+                        {
+                            "id": adapt_id,
+                            "action": action,
+                            "target": target,
+                            "rating": rating,
+                            "win_rate_change": (
+                                (wr_after or 0) - (wr_before or 0)
+                                if wr_after and wr_before
+                                else None
+                            ),
+                            "pnl_change": (
+                                (pnl_after or 0) - (pnl_before or 0)
+                                if pnl_after and pnl_before
+                                else None
+                            ),
+                        }
+                    )
 
             # Calculate rates
             if results["measured_adaptations"] > 0:
                 effective_count = results["highly_effective"] + results["effective"]
-                results["effectiveness_rate"] = effective_count / results["measured_adaptations"] * 100
-                results["harmful_rate"] = results["harmful"] / results["measured_adaptations"] * 100
+                results["effectiveness_rate"] = (
+                    effective_count / results["measured_adaptations"] * 100
+                )
+                results["harmful_rate"] = (
+                    results["harmful"] / results["measured_adaptations"] * 100
+                )
 
             results["by_type"] = dict(by_type)
 
     except Exception as e:
         results["error"] = str(e)
@@ -232,24 +279,27 @@
     """
     results = {
         "total_patterns": 0,
         "patterns_with_data": 0,
         "high_confidence_patterns": [],  # Confidence > 0.6
-        "low_confidence_patterns": [],   # Confidence < 0.4
+        "low_confidence_patterns": [],  # Confidence < 0.4
         "confidence_predicts_outcomes": False,
         "assessment": "",
     }
 
     try:
         with db._get_connection() as conn:
             cursor = conn.cursor()
 
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT pattern_id, name, confidence, usage_count, win_rate, total_pnl, is_active
                 FROM trading_patterns
                 WHERE usage_count >= ?
-            """, (min_usage,))
+            """,
+                (min_usage,),
+            )
 
             patterns = cursor.fetchall()
             results["total_patterns"] = len(patterns)
 
             high_conf_wins = []
@@ -276,29 +326,37 @@
                     results["low_confidence_patterns"].append(pattern_data)
                     low_conf_wins.append(win_rate or 0)
 
             # Calculate averages
             if high_conf_wins:
-                results["high_conf_avg_win_rate"] = sum(high_conf_wins) / len(high_conf_wins)
+                results["high_conf_avg_win_rate"] = sum(high_conf_wins) / len(
+                    high_conf_wins
+                )
             else:
                 results["high_conf_avg_win_rate"] = 0
 
             if low_conf_wins:
-                results["low_conf_avg_win_rate"] = sum(low_conf_wins) / len(low_conf_wins)
+                results["low_conf_avg_win_rate"] = sum(low_conf_wins) / len(
+                    low_conf_wins
+                )
             else:
                 results["low_conf_avg_win_rate"] = 0
 
             # Check if confidence predicts outcomes
             if high_conf_wins and low_conf_wins:
                 if results["high_conf_avg_win_rate"] > results["low_conf_avg_win_rate"]:
                     results["confidence_predicts_outcomes"] = True
-                    results["assessment"] = "YES - High confidence patterns win more often"
+                    results["assessment"] = (
+                        "YES - High confidence patterns win more often"
+                    )
                 else:
                     results["confidence_predicts_outcomes"] = False
                     results["assessment"] = "NO - Confidence does not predict outcomes"
             else:
-                results["assessment"] = "INSUFFICIENT DATA - Need patterns at both confidence levels"
+                results["assessment"] = (
+                    "INSUFFICIENT DATA - Need patterns at both confidence levels"
+                )
 
     except Exception as e:
         results["error"] = str(e)
 
     return results
@@ -338,14 +396,17 @@
 
             # Pattern counts
             cursor.execute("SELECT COUNT(*) FROM trading_patterns")
             results["total_patterns"] = cursor.fetchone()[0] or 0
 
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM trading_patterns
                 WHERE created_at >= ?
-            """, (cutoff,))
+            """,
+                (cutoff,),
+            )
             results["new_patterns"] = cursor.fetchone()[0] or 0
 
             cursor.execute("""
                 SELECT COUNT(*) FROM trading_patterns
                 WHERE is_active = 0
@@ -354,14 +415,17 @@
 
             # Rule counts
             cursor.execute("SELECT COUNT(*) FROM regime_rules")
             results["total_rules"] = cursor.fetchone()[0] or 0
 
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM regime_rules
                 WHERE created_at >= ?
-            """, (cutoff,))
+            """,
+                (cutoff,),
+            )
             results["new_rules"] = cursor.fetchone()[0] or 0
 
             # Coin counts
             cursor.execute("SELECT COUNT(*) FROM coin_scores")
             results["coins_tracked"] = cursor.fetchone()[0] or 0
@@ -371,56 +435,79 @@
                 WHERE is_blacklisted = 1
             """)
             results["coins_blacklisted"] = cursor.fetchone()[0] or 0
 
             # Insight and adaptation counts
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM insights
                 WHERE created_at >= ?
-            """, (cutoff,))
+            """,
+                (cutoff,),
+            )
             results["total_insights"] = cursor.fetchone()[0] or 0
 
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM adaptations
                 WHERE applied_at >= ?
-            """, (cutoff,))
+            """,
+                (cutoff,),
+            )
             results["total_adaptations"] = cursor.fetchone()[0] or 0
 
             # Daily breakdown
             for d in range(days):
-                day_start = (datetime.now() - timedelta(days=d+1)).replace(
-                    hour=0, minute=0, second=0
-                ).isoformat()
-                day_end = (datetime.now() - timedelta(days=d)).replace(
-                    hour=0, minute=0, second=0
-                ).isoformat()
-
-                cursor.execute("""
+                day_start = (
+                    (datetime.now() - timedelta(days=d + 1))
+                    .replace(hour=0, minute=0, second=0)
+                    .isoformat()
+                )
+                day_end = (
+                    (datetime.now() - timedelta(days=d))
+                    .replace(hour=0, minute=0, second=0)
+                    .isoformat()
+                )
+
+                cursor.execute(
+                    """
                     SELECT COUNT(*) FROM insights
                     WHERE created_at >= ? AND created_at < ?
-                """, (day_start, day_end))
+                """,
+                    (day_start, day_end),
+                )
                 day_insights = cursor.fetchone()[0] or 0
 
-                cursor.execute("""
+                cursor.execute(
+                    """
                     SELECT COUNT(*) FROM adaptations
                     WHERE applied_at >= ? AND applied_at < ?
-                """, (day_start, day_end))
+                """,
+                    (day_start, day_end),
+                )
                 day_adaptations = cursor.fetchone()[0] or 0
 
-                cursor.execute("""
+                cursor.execute(
+                    """
                     SELECT COUNT(*) FROM trading_patterns
                     WHERE created_at >= ? AND created_at < ?
-                """, (day_start, day_end))
+                """,
+                    (day_start, day_end),
+                )
                 day_patterns = cursor.fetchone()[0] or 0
 
-                results["daily_breakdown"].append({
-                    "day": d + 1,
-                    "date": (datetime.now() - timedelta(days=d+1)).strftime("%Y-%m-%d"),
-                    "insights": day_insights,
-                    "adaptations": day_adaptations,
-                    "new_patterns": day_patterns,
-                })
+                results["daily_breakdown"].append(
+                    {
+                        "day": d + 1,
+                        "date": (datetime.now() - timedelta(days=d + 1)).strftime(
+                            "%Y-%m-%d"
+                        ),
+                        "insights": day_insights,
+                        "adaptations": day_adaptations,
+                        "new_patterns": day_patterns,
+                    }
+                )
 
     except Exception as e:
         results["error"] = str(e)
 
     return results
@@ -428,11 +515,11 @@
 
 def calculate_learning_score(
     coin_accuracy: dict,
     adaptation_effectiveness: dict,
     pattern_accuracy: dict,
-    knowledge_growth: dict
+    knowledge_growth: dict,
 ) -> dict:
     """
     Calculate an overall learning effectiveness score.
 
     Args:
@@ -480,13 +567,13 @@
     else:
         scores["pattern_accuracy"] = 40
 
     # Knowledge growth score (0-100)
     total_items = (
-        knowledge_growth.get("new_patterns", 0) +
-        knowledge_growth.get("new_rules", 0) +
-        knowledge_growth.get("total_adaptations", 0)
+        knowledge_growth.get("new_patterns", 0)
+        + knowledge_growth.get("new_rules", 0)
+        + knowledge_growth.get("total_adaptations", 0)
     )
     if total_items >= 10:
         scores["knowledge_growth"] = 90
     elif total_items >= 5:
         scores["knowledge_growth"] = 70
@@ -494,14 +581,11 @@
         scores["knowledge_growth"] = 50
     else:
         scores["knowledge_growth"] = 30
 
     # Calculate weighted total
-    total_score = sum(
-        scores[key] * weights[key]
-        for key in weights
-    )
+    total_score = sum(scores[key] * weights[key] for key in weights)
 
     # Determine grade
     if total_score >= 80:
         grade = "A"
         assessment = "EXCELLENT - Learning system is highly effective"
would reformat /mnt/c/documents/crypto-trading-bot/src/analysis/learning.py
--- /mnt/c/documents/crypto-trading-bot/src/models/knowledge.py	2026-02-03 16:27:51.781120+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/models/knowledge.py	2026-02-04 21:34:25.129211+00:00
@@ -11,23 +11,24 @@
     """Performance metrics for a specific coin.
 
     Tracks win/loss statistics, P&L, and trend to help the Strategist
     make informed decisions about which coins to trade.
     """
-    coin: str                           # "SOL", "ETH", etc.
+
+    coin: str  # "SOL", "ETH", etc.
     total_trades: int = 0
     wins: int = 0
     losses: int = 0
     total_pnl: float = 0.0
     avg_pnl: float = 0.0
     win_rate: float = 0.0
-    avg_winner: float = 0.0             # Average profit on winning trades
-    avg_loser: float = 0.0              # Average loss on losing trades
+    avg_winner: float = 0.0  # Average profit on winning trades
+    avg_loser: float = 0.0  # Average loss on losing trades
     is_blacklisted: bool = False
     blacklist_reason: str = ""
     last_updated: Optional[datetime] = None
-    trend: str = "stable"               # "improving", "degrading", "stable"
+    trend: str = "stable"  # "improving", "degrading", "stable"
 
     def __post_init__(self):
         if self.last_updated is None:
             self.last_updated = datetime.now()
 
@@ -57,19 +58,20 @@
     """A reusable trading pattern with effectiveness tracking.
 
     Patterns describe entry/exit conditions that can be identified
     and tracked across multiple trades.
     """
+
     pattern_id: str
-    description: str                    # "Long on pullback to support in uptrend"
-    entry_conditions: Dict[str, Any]    # JSON-serializable conditions
-    exit_conditions: Dict[str, Any]     # JSON-serializable conditions
+    description: str  # "Long on pullback to support in uptrend"
+    entry_conditions: Dict[str, Any]  # JSON-serializable conditions
+    exit_conditions: Dict[str, Any]  # JSON-serializable conditions
     times_used: int = 0
     wins: int = 0
     losses: int = 0
     total_pnl: float = 0.0
-    confidence: float = 0.5             # 0-1, how much we trust this pattern
+    confidence: float = 0.5  # 0-1, how much we trust this pattern
     is_active: bool = True
     created_at: Optional[datetime] = None
     last_used: Optional[datetime] = None
 
     def __post_init__(self):
@@ -128,27 +130,30 @@
     """A rule about when to trade or sit out.
 
     Regime rules capture learned market conditions that affect
     trading decisions (e.g., "Don't trade when BTC volatility < 1%").
     """
+
     rule_id: str
-    description: str                    # "Don't trade when BTC volatility < 1%"
-    condition: Dict[str, Any]           # JSON-serializable condition
-    action: str                         # "NO_TRADE", "REDUCE_SIZE", "INCREASE_SIZE"
+    description: str  # "Don't trade when BTC volatility < 1%"
+    condition: Dict[str, Any]  # JSON-serializable condition
+    action: str  # "NO_TRADE", "REDUCE_SIZE", "INCREASE_SIZE"
     times_triggered: int = 0
-    estimated_saves: float = 0.0        # P&L saved by following this rule
+    estimated_saves: float = 0.0  # P&L saved by following this rule
     is_active: bool = True
     created_at: Optional[datetime] = None
 
     # Valid actions
     VALID_ACTIONS = ["NO_TRADE", "REDUCE_SIZE", "INCREASE_SIZE", "CAUTION"]
 
     def __post_init__(self):
         if self.created_at is None:
             self.created_at = datetime.now()
         if self.action not in self.VALID_ACTIONS:
-            raise ValueError(f"Invalid action: {self.action}. Must be one of {self.VALID_ACTIONS}")
+            raise ValueError(
+                f"Invalid action: {self.action}. Must be one of {self.VALID_ACTIONS}"
+            )
 
     def to_dict(self) -> Dict[str, Any]:
         """Convert to dictionary for database storage."""
         return {
             "rule_id": self.rule_id,
would reformat /mnt/c/documents/crypto-trading-bot/src/models/knowledge.py
--- /mnt/c/documents/crypto-trading-bot/src/effectiveness.py	2026-02-03 18:31:29.150286+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/effectiveness.py	2026-02-04 21:34:25.129693+00:00
@@ -24,36 +24,38 @@
 logger = logging.getLogger(__name__)
 
 
 class EffectivenessRating(Enum):
     """Rating for adaptation effectiveness."""
+
     HIGHLY_EFFECTIVE = "highly_effective"  # Significantly improved metrics
-    EFFECTIVE = "effective"                 # Moderately improved metrics
-    NEUTRAL = "neutral"                     # No significant change
-    INEFFECTIVE = "ineffective"             # Made things worse
-    HARMFUL = "harmful"                     # Significantly worse, consider rollback
-    PENDING = "pending"                     # Not enough data yet
+    EFFECTIVE = "effective"  # Moderately improved metrics
+    NEUTRAL = "neutral"  # No significant change
+    INEFFECTIVE = "ineffective"  # Made things worse
+    HARMFUL = "harmful"  # Significantly worse, consider rollback
+    PENDING = "pending"  # Not enough data yet
 
 
 @dataclass
 class EffectivenessResult:
     """Result of effectiveness measurement."""
+
     adaptation_id: str
     rating: EffectivenessRating
 
     # Pre/post comparison
     pre_metrics: Dict[str, Any]
     post_metrics: Dict[str, Any]
 
     # Key changes
-    win_rate_change: float = 0.0       # Percentage points (+5 means 50% -> 55%)
-    pnl_change: float = 0.0            # Dollar change
+    win_rate_change: float = 0.0  # Percentage points (+5 means 50% -> 55%)
+    pnl_change: float = 0.0  # Dollar change
     profit_factor_change: float = 0.0  # Change in profit factor
 
     # Context
-    trades_measured: int = 0           # Trades since adaptation
-    hours_elapsed: float = 0.0         # Hours since adaptation
+    trades_measured: int = 0  # Trades since adaptation
+    hours_elapsed: float = 0.0  # Hours since adaptation
 
     # Recommendation
     should_rollback: bool = False
     rollback_reason: Optional[str] = None
 
@@ -95,23 +97,23 @@
         >>> for r in results:
         ...     print(f"{r.adaptation_id}: {r.rating.value}")
     """
 
     # Measurement thresholds
-    MIN_TRADES_FOR_MEASUREMENT = 10     # At least 10 trades after adaptation
-    MIN_HOURS_FOR_MEASUREMENT = 24      # At least 24 hours after adaptation
-    MAX_HOURS_FOR_MEASUREMENT = 168     # Measure within 7 days
+    MIN_TRADES_FOR_MEASUREMENT = 10  # At least 10 trades after adaptation
+    MIN_HOURS_FOR_MEASUREMENT = 24  # At least 24 hours after adaptation
+    MAX_HOURS_FOR_MEASUREMENT = 168  # Measure within 7 days
 
     # Effectiveness thresholds (percentage points for win rate)
-    HIGHLY_EFFECTIVE_THRESHOLD = 10.0   # +10% win rate
-    EFFECTIVE_THRESHOLD = 3.0           # +3% win rate
-    INEFFECTIVE_THRESHOLD = -3.0        # -3% win rate
-    HARMFUL_THRESHOLD = -10.0           # -10% win rate
+    HIGHLY_EFFECTIVE_THRESHOLD = 10.0  # +10% win rate
+    EFFECTIVE_THRESHOLD = 3.0  # +3% win rate
+    INEFFECTIVE_THRESHOLD = -3.0  # -3% win rate
+    HARMFUL_THRESHOLD = -10.0  # -10% win rate
 
     # Rollback thresholds
-    ROLLBACK_MIN_PNL_LOSS = 20.0        # Must lose at least $20 to rollback
-    ROLLBACK_MIN_TRADES = 10            # Must have at least 10 trades
+    ROLLBACK_MIN_PNL_LOSS = 20.0  # Must lose at least $20 to rollback
+    ROLLBACK_MIN_TRADES = 10  # Must have at least 10 trades
 
     def __init__(
         self,
         db: "Database",
         journal: "TradeJournal",
@@ -190,12 +192,16 @@
 
         Returns:
             EffectivenessResult or None if not ready.
         """
         # Get adaptation from database
-        adaptations = self.db.get_adaptations(hours=self.MAX_HOURS_FOR_MEASUREMENT, limit=1000)
-        adaptation = next((a for a in adaptations if a["adaptation_id"] == adaptation_id), None)
+        adaptations = self.db.get_adaptations(
+            hours=self.MAX_HOURS_FOR_MEASUREMENT, limit=1000
+        )
+        adaptation = next(
+            (a for a in adaptations if a["adaptation_id"] == adaptation_id), None
+        )
 
         if not adaptation:
             logger.debug(f"Adaptation {adaptation_id} not found")
             return None
 
@@ -276,14 +282,11 @@
             status="closed",
             limit=10000,
         )
 
         # Filter to only trades after adaptation
-        trades_after = [
-            t for t in trades
-            if t.exit_time and t.exit_time > since
-        ]
+        trades_after = [t for t in trades if t.exit_time and t.exit_time > since]
 
         # Calculate metrics
         if trades_after:
             metrics = self.profitability.calculate_metrics(trades_after)
         else:
@@ -303,11 +306,11 @@
                 "total_trades": metrics.get("total_trades", 0),
                 "winning_trades": metrics.get("winning_trades", 0),
                 "win_rate": metrics.get("win_rate", 0.0),
                 "total_pnl": metrics.get("total_pnl", 0.0),
                 "profit_factor": metrics.get("profit_factor", 0.0),
-            }
+            },
         }
 
     def _calculate_effectiveness(
         self,
         adaptation_id: str,
@@ -358,13 +361,13 @@
         else:
             rating = EffectivenessRating.HARMFUL
 
         # Determine if rollback needed
         should_rollback = (
-            rating == EffectivenessRating.HARMFUL and
-            pnl_change < -self.ROLLBACK_MIN_PNL_LOSS and
-            trades_measured >= self.ROLLBACK_MIN_TRADES
+            rating == EffectivenessRating.HARMFUL
+            and pnl_change < -self.ROLLBACK_MIN_PNL_LOSS
+            and trades_measured >= self.ROLLBACK_MIN_TRADES
         )
 
         rollback_reason = None
         if should_rollback:
             rollback_reason = (
@@ -385,11 +388,13 @@
             should_rollback=should_rollback,
             rollback_reason=rollback_reason,
             measured_at=datetime.now(),
         )
 
-    def _save_effectiveness(self, adaptation_id: str, result: EffectivenessResult) -> None:
+    def _save_effectiveness(
+        self, adaptation_id: str, result: EffectivenessResult
+    ) -> None:
         """Save effectiveness measurement to database.
 
         Args:
             adaptation_id: ID of adaptation.
             result: Effectiveness result.
@@ -399,11 +404,13 @@
                 adaptation_id=adaptation_id,
                 post_metrics=json.dumps(result.post_metrics),
                 effectiveness=result.rating.value,
                 effectiveness_measured_at=result.measured_at,
             )
-            logger.debug(f"Saved effectiveness for {adaptation_id}: {result.rating.value}")
+            logger.debug(
+                f"Saved effectiveness for {adaptation_id}: {result.rating.value}"
+            )
         except Exception as e:
             logger.error(f"Failed to save effectiveness: {e}")
 
     def _parse_timestamp(self, ts: Any) -> Optional[datetime]:
         """Parse timestamp from various formats."""
@@ -470,11 +477,13 @@
         """Get summary of adaptation effectiveness.
 
         Returns:
             Summary dict with counts by rating.
         """
-        adaptations = self.db.get_adaptations(hours=self.MAX_HOURS_FOR_MEASUREMENT, limit=1000)
+        adaptations = self.db.get_adaptations(
+            hours=self.MAX_HOURS_FOR_MEASUREMENT, limit=1000
+        )
 
         summary = {
             "total": len(adaptations),
             "total_measured": 0,
             "highly_effective": 0,
@@ -509,12 +518,16 @@
             adaptation_id: ID of adaptation.
 
         Returns:
             Dict with rollback suggestion.
         """
-        adaptations = self.db.get_adaptations(hours=self.MAX_HOURS_FOR_MEASUREMENT, limit=1000)
-        adaptation = next((a for a in adaptations if a["adaptation_id"] == adaptation_id), None)
+        adaptations = self.db.get_adaptations(
+            hours=self.MAX_HOURS_FOR_MEASUREMENT, limit=1000
+        )
+        adaptation = next(
+            (a for a in adaptations if a["adaptation_id"] == adaptation_id), None
+        )
 
         if not adaptation:
             return {"error": "Adaptation not found"}
 
         action = adaptation.get("action", "")
@@ -550,12 +563,16 @@
             adaptation_id: ID of adaptation to rollback.
 
         Returns:
             True if rollback successful.
         """
-        adaptations = self.db.get_adaptations(hours=self.MAX_HOURS_FOR_MEASUREMENT, limit=1000)
-        adaptation = next((a for a in adaptations if a["adaptation_id"] == adaptation_id), None)
+        adaptations = self.db.get_adaptations(
+            hours=self.MAX_HOURS_FOR_MEASUREMENT, limit=1000
+        )
+        adaptation = next(
+            (a for a in adaptations if a["adaptation_id"] == adaptation_id), None
+        )
 
         if not adaptation:
             logger.error(f"Adaptation {adaptation_id} not found for rollback")
             return False
 
@@ -603,15 +620,17 @@
                 self._rollbacks_executed += 1
                 # Log the rollback
                 self.db.log_activity(
                     activity_type="rollback",
                     description=f"Rolled back adaptation {adaptation_id}",
-                    details=json.dumps({
-                        "adaptation_id": adaptation_id,
-                        "action": action,
-                        "target": target,
-                    }),
+                    details=json.dumps(
+                        {
+                            "adaptation_id": adaptation_id,
+                            "action": action,
+                            "target": target,
+                        }
+                    ),
                 )
 
         except Exception as e:
             logger.error(f"Rollback failed for {adaptation_id}: {e}")
             success = False
@@ -642,11 +661,11 @@
                 "measurements_completed": self._measurements_completed,
                 "rollbacks_flagged": self._rollbacks_flagged,
                 "rollbacks_executed": self._rollbacks_executed,
                 "has_journal": self.journal is not None,
                 "has_profitability": self.profitability is not None,
-            }
+            },
         }
 
     def get_stats(self) -> Dict[str, Any]:
         """Get monitor statistics.
 
would reformat /mnt/c/documents/crypto-trading-bot/src/effectiveness.py
--- /mnt/c/documents/crypto-trading-bot/src/adaptation.py	2026-02-03 18:12:59.748264+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/adaptation.py	2026-02-04 21:34:25.132994+00:00
@@ -102,11 +102,13 @@
                 logger.info(f"Adaptation applied: {record}")
             else:
                 self.adaptations_skipped += 1
 
         if adaptations:
-            logger.info(f"Applied {len(adaptations)} adaptations from {len(insights)} insights")
+            logger.info(
+                f"Applied {len(adaptations)} adaptations from {len(insights)} insights"
+            )
         else:
             logger.debug(f"No adaptations applied from {len(insights)} insights")
 
         return adaptations
 
@@ -197,11 +199,13 @@
 
         if not target:
             return False
 
         # Check recent adaptations for this target
-        recent = self.db.get_adaptations_for_target(target, hours=ADAPTATION_COOLDOWN_HOURS)
+        recent = self.db.get_adaptations_for_target(
+            target, hours=ADAPTATION_COOLDOWN_HOURS
+        )
         return len(recent) > 0
 
     def _extract_coin(self, text: str) -> Optional[str]:
         """Extract coin symbol from text.
 
@@ -210,19 +214,30 @@
 
         Returns:
             Coin symbol or None.
         """
         # Common coin patterns
-        coins = ["BTC", "ETH", "SOL", "DOGE", "SHIB", "XRP", "ADA", "AVAX", "MATIC", "LINK"]
+        coins = [
+            "BTC",
+            "ETH",
+            "SOL",
+            "DOGE",
+            "SHIB",
+            "XRP",
+            "ADA",
+            "AVAX",
+            "MATIC",
+            "LINK",
+        ]
         text_upper = text.upper()
 
         for coin in coins:
             if coin in text_upper:
                 return coin
 
         # Try to find any uppercase 3-5 letter word that might be a coin
-        match = re.search(r'\b([A-Z]{3,5})\b', text.upper())
+        match = re.search(r"\b([A-Z]{3,5})\b", text.upper())
         if match:
             return match.group(1)
 
         return None
 
@@ -566,22 +581,22 @@
                 "adaptations_applied": self.adaptations_applied,
                 "adaptations_skipped": self.adaptations_skipped,
                 "has_knowledge_brain": self.knowledge is not None,
                 "has_coin_scorer": self.coin_scorer is not None,
                 "has_pattern_library": self.pattern_library is not None,
-            }
+            },
         }
 
 
 # Allow running directly for testing
 if __name__ == "__main__":
     import tempfile
     import os
 
     logging.basicConfig(
         level=logging.INFO,
-        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
     )
 
     print("=" * 60)
     print("AdaptationEngine Test")
     print("=" * 60)
would reformat /mnt/c/documents/crypto-trading-bot/src/adaptation.py
--- /mnt/c/documents/crypto-trading-bot/src/main_legacy.py	2026-01-14 23:35:06.148711+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/main_legacy.py	2026-02-04 21:34:25.140420+00:00
@@ -24,42 +24,46 @@
 sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
 
 from src.database import Database
 from src.market_data import MarketDataFetcher, format_price
 from src.trading_engine import TradingEngine
-from src.learning_system import LearningSystem, RuleManager, get_learnings_as_text, get_rules_as_text
+from src.learning_system import (
+    LearningSystem,
+    RuleManager,
+    get_learnings_as_text,
+    get_rules_as_text,
+)
 from src.llm_interface import LLMInterface
 from src.risk_manager import RiskManager
 from src.coin_config import get_coin_ids, get_tier, get_tier_config
 
 # =============================================================================
 # CONFIGURATION - All configurable parameters in one place
 # =============================================================================
 
 LOOP_INTERVAL = int(os.environ.get("LOOP_INTERVAL", 30))  # seconds
-MIN_CONFIDENCE = float(os.environ.get("MIN_CONFIDENCE", 0.3))  # 30% minimum for aggressive learning
+MIN_CONFIDENCE = float(
+    os.environ.get("MIN_CONFIDENCE", 0.3)
+)  # 30% minimum for aggressive learning
 MAX_TRADES_PER_CYCLE = 5  # Allow multiple trades per cycle for faster learning
 # Coins are now loaded from coin_config (45 coins across 3 tiers)
 
 # Configure logging - summary to console, details to file
 logging.basicConfig(
     level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
-    handlers=[
-        logging.FileHandler('logs/bot.log'),
-        logging.StreamHandler(sys.stdout)
-    ]
+    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
+    handlers=[logging.FileHandler("logs/bot.log"), logging.StreamHandler(sys.stdout)],
 )
 logger = logging.getLogger(__name__)
 
 # Suppress verbose logging from other modules in console
-logging.getLogger('src.database').setLevel(logging.WARNING)
-logging.getLogger('src.market_data').setLevel(logging.WARNING)
-logging.getLogger('src.trading_engine').setLevel(logging.WARNING)
-logging.getLogger('src.learning_system').setLevel(logging.WARNING)
-logging.getLogger('src.llm_interface').setLevel(logging.WARNING)
-logging.getLogger('src.risk_manager').setLevel(logging.WARNING)
+logging.getLogger("src.database").setLevel(logging.WARNING)
+logging.getLogger("src.market_data").setLevel(logging.WARNING)
+logging.getLogger("src.trading_engine").setLevel(logging.WARNING)
+logging.getLogger("src.learning_system").setLevel(logging.WARNING)
+logging.getLogger("src.llm_interface").setLevel(logging.WARNING)
+logging.getLogger("src.risk_manager").setLevel(logging.WARNING)
 
 
 class TradingBot:
     """Main trading bot that runs the 24/7 autonomous loop.
 
@@ -109,17 +113,19 @@
 
         print("\n  Configuration:")
         print(f"    Loop interval: {LOOP_INTERVAL}s")
         print(f"    Min confidence: {MIN_CONFIDENCE:.0%}")
         print(f"    Max trades/cycle: {MAX_TRADES_PER_CYCLE}")
-        print(f"    Coins: {len(all_coins)} total (T1:{tier_counts[1]} T2:{tier_counts[2]} T3:{tier_counts[3]})")
+        print(
+            f"    Coins: {len(all_coins)} total (T1:{tier_counts[1]} T2:{tier_counts[2]} T3:{tier_counts[3]})"
+        )
 
         # Log initialization
         self.db.log_activity(
             "bot_initialized",
             "Trading bot initialized",
-            f"interval={LOOP_INTERVAL}s, min_confidence={MIN_CONFIDENCE}"
+            f"interval={LOOP_INTERVAL}s, min_confidence={MIN_CONFIDENCE}",
         )
 
     def run(self):
         """Main loop - runs until stopped."""
         self.running = True
@@ -127,15 +133,19 @@
 
         # Get initial account state
         account = self.db.get_account_state()
 
         print("\n" + "=" * 64)
-        print(f"  TRADING BOT STARTED - {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
+        print(
+            f"  TRADING BOT STARTED - {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}"
+        )
         print(f"  Balance: ${account['balance']:.2f} | Model: {self.llm.model}")
         print("=" * 64 + "\n")
 
-        self.db.log_activity("bot_started", f"Bot started with balance ${account['balance']:.2f}")
+        self.db.log_activity(
+            "bot_started", f"Bot started with balance ${account['balance']:.2f}"
+        )
 
         try:
             while self.running:
                 self.run_cycle()
 
@@ -152,17 +162,21 @@
     def run_cycle(self):
         """Execute a single trading cycle."""
         self.cycle_count += 1
         cycle_start = datetime.now()
 
-        print(f"[{cycle_start.strftime('%H:%M:%S')}] Cycle #{self.cycle_count} starting...")
+        print(
+            f"[{cycle_start.strftime('%H:%M:%S')}] Cycle #{self.cycle_count} starting..."
+        )
 
         try:
             # Step 1: Fetch market data
             prices = self._fetch_market_data()
             if not prices:
-                print(f"[{cycle_start.strftime('%H:%M:%S')}]  Market data fetch failed, skipping cycle")
+                print(
+                    f"[{cycle_start.strftime('%H:%M:%S')}]  Market data fetch failed, skipping cycle"
+                )
                 return
 
             # Step 2: Update positions (may close trades)
             closed_trades = self._update_positions()
 
@@ -180,30 +194,38 @@
             # Step 6: Log cycle completion
             elapsed = (datetime.now() - cycle_start).total_seconds()
             account = self.db.get_account_state()
 
             # Summary line for console
-            action_str = decision.get('action', 'HOLD') if decision else 'HOLD'
-            confidence_str = f"{decision.get('confidence', 0):.0%}" if decision else "N/A"
-
-            print(f"[{cycle_start.strftime('%H:%M:%S')}]  Cycle #{self.cycle_count} complete "
-                  f"| {action_str} ({confidence_str}) "
-                  f"| Balance: ${account['balance']:.2f} "
-                  f"| {elapsed:.1f}s")
+            action_str = decision.get("action", "HOLD") if decision else "HOLD"
+            confidence_str = (
+                f"{decision.get('confidence', 0):.0%}" if decision else "N/A"
+            )
+
+            print(
+                f"[{cycle_start.strftime('%H:%M:%S')}]  Cycle #{self.cycle_count} complete "
+                f"| {action_str} ({confidence_str}) "
+                f"| Balance: ${account['balance']:.2f} "
+                f"| {elapsed:.1f}s"
+            )
 
         except Exception as e:
             logger.error(f"Error in cycle #{self.cycle_count}: {e}")
-            self.db.log_activity("cycle_error", f"Cycle #{self.cycle_count} error: {str(e)}")
-            print(f"[{cycle_start.strftime('%H:%M:%S')}]  Cycle #{self.cycle_count} error: {e}")
+            self.db.log_activity(
+                "cycle_error", f"Cycle #{self.cycle_count} error: {str(e)}"
+            )
+            print(
+                f"[{cycle_start.strftime('%H:%M:%S')}]  Cycle #{self.cycle_count} error: {e}"
+            )
 
     def _fetch_market_data(self) -> Optional[Dict[str, float]]:
         """Fetch latest market data from CoinGecko using batch API."""
         try:
             # Batch fetch all coins with volume filtering
             stats = self.market_data.update_all_prices()
 
-            if stats['updated'] == 0:
+            if stats["updated"] == 0:
                 logger.warning("No coins updated")
                 return None
 
             # Get tradeable coins (those that passed volume filter)
             tradeable = self.market_data.get_tradeable_coins()
@@ -223,11 +245,13 @@
                         SELECT coin, change_24h FROM market_data
                         ORDER BY ABS(change_24h) DESC LIMIT 3
                     """)
                     top_movers = cursor.fetchall()
 
-                mover_str = " | ".join([f"{c[:4].upper()}: {ch:+.1f}%" for c, ch in top_movers])
+                mover_str = " | ".join(
+                    [f"{c[:4].upper()}: {ch:+.1f}%" for c, ch in top_movers]
+                )
                 logger.info(f"Updated {len(prices)} coins | Top movers: {mover_str}")
                 return prices
 
             return None
 
@@ -242,34 +266,42 @@
         open_trades = self.trading_engine.get_open_trades()
 
         if closed:
             self.trades_closed += len(closed)
             for trade in closed:
-                pnl_sign = "+" if trade['pnl_usd'] >= 0 else ""
-                print(f"          Trade closed: {trade['coin']} {pnl_sign}${trade['pnl_usd']:.2f} ({trade['reason']})")
-
-        logger.info(f"Positions: {len(open_trades)} open, {len(closed)} closed this cycle")
+                pnl_sign = "+" if trade["pnl_usd"] >= 0 else ""
+                print(
+                    f"          Trade closed: {trade['coin']} {pnl_sign}${trade['pnl_usd']:.2f} ({trade['reason']})"
+                )
+
+        logger.info(
+            f"Positions: {len(open_trades)} open, {len(closed)} closed this cycle"
+        )
         return closed
 
     def _analyze_closed_trades(self, closed_trades: List[Dict[str, Any]]):
         """Analyze closed trades to create learnings and rules."""
         for trade in closed_trades:
-            trade_id = trade['trade_id']
+            trade_id = trade["trade_id"]
 
             # Analyze trade with LLM
             learning = self.learning_system.analyze_trade(trade_id)
 
             if learning:
-                print(f"          Learning created: {learning.lesson[:50]}... ({learning.confidence:.0%})")
+                print(
+                    f"          Learning created: {learning.lesson[:50]}... ({learning.confidence:.0%})"
+                )
 
                 # Try to create rule from high-confidence learning
                 if learning.confidence >= 0.7:
                     rule = self.rule_manager.create_rule_from_learning(learning)
                     if rule:
                         print(f"          Rule created: {rule.rule_text[:50]}...")
 
-    def _get_trading_decision(self, prices: Dict[str, float]) -> Optional[Dict[str, Any]]:
+    def _get_trading_decision(
+        self, prices: Dict[str, float]
+    ) -> Optional[Dict[str, Any]]:
         """Query LLM for a trading decision."""
         # Build context for LLM
         account = self.db.get_account_state()
         open_trades = self.trading_engine.get_open_trades()
         learnings = get_learnings_as_text(db=self.db, limit=5)
@@ -287,21 +319,21 @@
             for row in cursor.fetchall():
                 coin, price, change = row
                 market_data[coin] = {
                     "price_usd": price,
                     "change_24h": change or 0,
-                    "tier": get_tier(coin)
+                    "tier": get_tier(coin),
                 }
 
         # Build account state dict
         account_state = {
-            "balance": account['balance'],
-            "available_balance": account['available_balance'],
-            "in_positions": account['in_positions'],
-            "daily_pnl": account['daily_pnl'],
+            "balance": account["balance"],
+            "available_balance": account["available_balance"],
+            "in_positions": account["in_positions"],
+            "daily_pnl": account["daily_pnl"],
             "open_trades": len(open_trades),
-            "trade_count_today": account['trade_count_today']
+            "trade_count_today": account["trade_count_today"],
         }
 
         # Get coins in cooldown for diversity enforcement
         coins_in_cooldown = self.risk_manager.get_coins_in_cooldown()
 
@@ -309,42 +341,44 @@
         decision = self.llm.get_trading_decision(
             market_data=market_data,
             account_state=account_state,
             recent_learnings=learnings,
             active_rules=active_rules,
-            coins_in_cooldown=coins_in_cooldown
+            coins_in_cooldown=coins_in_cooldown,
         )
 
         if decision is None:
             logger.warning("LLM returned no decision, defaulting to HOLD")
             return {"action": "HOLD", "confidence": 0, "reason": "LLM unavailable"}
 
         # Log the decision details to activity_log (detailed logging)
         self.db.log_activity(
             "llm_decision",
             f"{decision.get('action', 'HOLD')} (confidence: {decision.get('confidence', 0):.2f})",
-            json.dumps(decision)
+            json.dumps(decision),
         )
 
         return decision
 
     def _execute_decision(self, decision: Dict[str, Any]):
         """Execute a trading decision if valid."""
-        action = decision.get('action', 'HOLD')
-        confidence = decision.get('confidence', 0)
-        coin = decision.get('coin')
-        size_usd = decision.get('size_usd')
-        reason = decision.get('reason', 'No reason provided')
-        rules_applied = decision.get('rules_applied', [])
+        action = decision.get("action", "HOLD")
+        confidence = decision.get("confidence", 0)
+        coin = decision.get("coin")
+        size_usd = decision.get("size_usd")
+        reason = decision.get("reason", "No reason provided")
+        rules_applied = decision.get("rules_applied", [])
 
         # Check confidence threshold
         if confidence < MIN_CONFIDENCE:
-            logger.info(f"Decision {action} rejected: confidence {confidence:.0%} < {MIN_CONFIDENCE:.0%}")
+            logger.info(
+                f"Decision {action} rejected: confidence {confidence:.0%} < {MIN_CONFIDENCE:.0%}"
+            )
             self.db.log_activity(
                 "decision_rejected",
                 f"{action} rejected: low confidence ({confidence:.0%})",
-                reason
+                reason,
             )
             return
 
         # Only execute BUY orders for now (no shorting in Phase 1)
         if action == "BUY" and coin and size_usd:
@@ -360,34 +394,37 @@
                         logger.info(f"Trade applying rules: {rule_ids}")
                 except (ValueError, TypeError):
                     rule_ids = None
 
             result = self.trading_engine.execute_buy(
-                coin=coin,
-                size_usd=size_usd,
-                reason=reason,
-                rule_ids=rule_ids
+                coin=coin, size_usd=size_usd, reason=reason, rule_ids=rule_ids
             )
 
             if result.success:
                 self.trades_opened += 1
                 self.risk_manager.record_trade(coin)  # Start cooldown for diversity
-                print(f"          Trade opened: {coin.upper()} ${size_usd:.2f} ({reason[:30]}...)")
+                print(
+                    f"          Trade opened: {coin.upper()} ${size_usd:.2f} ({reason[:30]}...)"
+                )
             else:
                 print(f"          Trade rejected: {result.message}")
 
         elif action == "SELL":
             # For Phase 1, SELL means close an existing position
             open_trades = self.trading_engine.get_open_trades()
             if coin:
                 # Find trade for this coin
                 for trade in open_trades:
-                    if trade['coin_name'] == coin:
-                        result = self.trading_engine.close_trade(trade['id'], f"llm_sell: {reason}")
+                    if trade["coin_name"] == coin:
+                        result = self.trading_engine.close_trade(
+                            trade["id"], f"llm_sell: {reason}"
+                        )
                         if result.success:
                             self.trades_closed += 1
-                            print(f"          Trade closed: {coin.upper()} ({reason[:30]}...)")
+                            print(
+                                f"          Trade closed: {coin.upper()} ({reason[:30]}...)"
+                            )
                         break
 
         # HOLD - do nothing
         elif action == "HOLD":
             logger.info(f"HOLD decision: {reason}")
@@ -418,11 +455,11 @@
         print("=" * 64 + "\n")
 
         self.db.log_activity(
             "bot_stopped",
             f"Bot stopped after {self.cycle_count} cycles",
-            f"runtime={runtime}, trades_opened={self.trades_opened}, trades_closed={self.trades_closed}"
+            f"runtime={runtime}, trades_opened={self.trades_opened}, trades_closed={self.trades_closed}",
         )
 
 
 def main():
     """Main entry point."""
would reformat /mnt/c/documents/crypto-trading-bot/src/main_legacy.py
--- /mnt/c/documents/crypto-trading-bot/scripts/autonomous_monitor.py	2026-01-15 00:31:55.586458+00:00
+++ /mnt/c/documents/crypto-trading-bot/scripts/autonomous_monitor.py	2026-02-04 21:34:25.143730+00:00
@@ -26,12 +26,11 @@
 from src.llm_interface import LLMInterface
 from src.coin_config import get_tier
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 
 # =============================================================================
@@ -102,10 +101,11 @@
 
 # =============================================================================
 # AUTONOMOUS MONITOR CLASS
 # =============================================================================
 
+
 class AutonomousMonitor:
     """Self-monitoring agent that uses LLM to detect issues."""
 
     def __init__(self, db: Database = None, llm: LLMInterface = None):
         """Initialize the monitor.
@@ -161,122 +161,143 @@
 
         Returns:
             Comprehensive data report.
         """
         return {
-            'timestamp': datetime.now().isoformat(),
-            'hours': hours,
-            'trade_patterns': self.collect_trade_patterns(hours),
-            'rule_stats': self.collect_rule_stats(),
-            'winloss_patterns': self.collect_winloss_patterns(hours),
-            'account_health': self.collect_account_health(),
-            'system_metrics': self.collect_system_metrics(hours),
-            'learning_quality': self.collect_learning_quality(hours)
+            "timestamp": datetime.now().isoformat(),
+            "hours": hours,
+            "trade_patterns": self.collect_trade_patterns(hours),
+            "rule_stats": self.collect_rule_stats(),
+            "winloss_patterns": self.collect_winloss_patterns(hours),
+            "account_health": self.collect_account_health(),
+            "system_metrics": self.collect_system_metrics(hours),
+            "learning_quality": self.collect_learning_quality(hours),
         }
 
     def collect_trade_patterns(self, hours: int) -> Dict[str, Any]:
         """Collect trade distribution and patterns."""
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
 
             # Total trades in period
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             total_trades = cursor.fetchone()[0]
 
             # Trades by coin
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT coin_name, COUNT(*) as cnt FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
                 GROUP BY coin_name ORDER BY cnt DESC
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             trades_by_coin = {row[0]: row[1] for row in cursor.fetchall()}
 
             # Trades by tier
             trades_by_tier = {1: 0, 2: 0, 3: 0}
             for coin, count in trades_by_coin.items():
                 tier = get_tier(coin)
                 trades_by_tier[tier] += count
 
             # Trades by hour of day
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT strftime('%H', closed_at) as hour, COUNT(*) FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
                 GROUP BY hour ORDER BY hour
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             trades_by_hour = {int(row[0]): row[1] for row in cursor.fetchall()}
 
             # Trade sizes
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT AVG(size_usd), MIN(size_usd), MAX(size_usd) FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             row = cursor.fetchone()
             avg_size = row[0] or 0
             min_size = row[1] or 0
             max_size = row[2] or 0
 
             # Duration stats
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT AVG(duration_seconds), MIN(duration_seconds), MAX(duration_seconds)
                 FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             row = cursor.fetchone()
             avg_duration = row[0] or 0
             min_duration = row[1] or 0
             max_duration = row[2] or 0
 
             # Win rate
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT
                     COUNT(CASE WHEN pnl_usd > 0 THEN 1 END) as wins,
                     COUNT(CASE WHEN pnl_usd <= 0 THEN 1 END) as losses
                 FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             row = cursor.fetchone()
             wins = row[0] or 0
             losses = row[1] or 0
             win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0
 
             # Average P&L
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT
                     AVG(CASE WHEN pnl_usd > 0 THEN pnl_usd END) as avg_win,
                     AVG(CASE WHEN pnl_usd <= 0 THEN pnl_usd END) as avg_loss,
                     SUM(pnl_usd) as total_pnl
                 FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             row = cursor.fetchone()
             avg_win = row[0] or 0
             avg_loss = row[1] or 0
             total_pnl = row[2] or 0
 
             # Open trades
             cursor.execute("SELECT COUNT(*) FROM open_trades")
             open_trades = cursor.fetchone()[0]
 
         return {
-            'total_trades': total_trades,
-            'open_trades': open_trades,
-            'trades_by_coin': trades_by_coin,
-            'trades_by_tier': trades_by_tier,
-            'trades_by_hour': trades_by_hour,
-            'avg_trade_size': round(avg_size, 2),
-            'size_range': {'min': round(min_size, 2), 'max': round(max_size, 2)},
-            'avg_duration_seconds': round(avg_duration, 1),
-            'duration_range': {'min': min_duration, 'max': max_duration},
-            'wins': wins,
-            'losses': losses,
-            'win_rate': round(win_rate, 3),
-            'avg_win_pnl': round(avg_win, 2),
-            'avg_loss_pnl': round(avg_loss, 2),
-            'total_pnl': round(total_pnl, 2)
+            "total_trades": total_trades,
+            "open_trades": open_trades,
+            "trades_by_coin": trades_by_coin,
+            "trades_by_tier": trades_by_tier,
+            "trades_by_hour": trades_by_hour,
+            "avg_trade_size": round(avg_size, 2),
+            "size_range": {"min": round(min_size, 2), "max": round(max_size, 2)},
+            "avg_duration_seconds": round(avg_duration, 1),
+            "duration_range": {"min": min_duration, "max": max_duration},
+            "wins": wins,
+            "losses": losses,
+            "win_rate": round(win_rate, 3),
+            "avg_win_pnl": round(avg_win, 2),
+            "avg_loss_pnl": round(avg_loss, 2),
+            "total_pnl": round(total_pnl, 2),
         }
 
     def collect_rule_stats(self) -> Dict[str, Any]:
         """Collect rule usage and effectiveness."""
         with self.db._get_connection() as conn:
@@ -292,99 +313,117 @@
             for row in cursor.fetchall():
                 success = row[4] or 0
                 failure = row[5] or 0
                 total = success + failure
                 rate = success / total if total > 0 else 0
-                rules.append({
-                    'id': row[0],
-                    'text': row[1][:100] + '...' if len(row[1]) > 100 else row[1],
-                    'type': row[2],
-                    'status': row[3],
-                    'success_count': success,
-                    'failure_count': failure,
-                    'total_uses': total,
-                    'success_rate': round(rate, 3),
-                    'last_used': row[6]
-                })
+                rules.append(
+                    {
+                        "id": row[0],
+                        "text": row[1][:100] + "..." if len(row[1]) > 100 else row[1],
+                        "type": row[2],
+                        "status": row[3],
+                        "success_count": success,
+                        "failure_count": failure,
+                        "total_uses": total,
+                        "success_rate": round(rate, 3),
+                        "last_used": row[6],
+                    }
+                )
 
             # Rules by status
             rules_by_status = {}
             for r in rules:
-                status = r['status']
+                status = r["status"]
                 rules_by_status[status] = rules_by_status.get(status, 0) + 1
 
             # Unused rules (never applied)
-            unused = [r for r in rules if r['total_uses'] == 0]
+            unused = [r for r in rules if r["total_uses"] == 0]
 
             # Rules that never succeeded
-            never_succeeded = [r for r in rules if r['total_uses'] > 0 and r['success_count'] == 0]
+            never_succeeded = [
+                r for r in rules if r["total_uses"] > 0 and r["success_count"] == 0
+            ]
 
             # Rules with very low success rate (< 30% with 5+ uses)
-            low_success = [r for r in rules if r['total_uses'] >= 5 and r['success_rate'] < 0.3]
+            low_success = [
+                r for r in rules if r["total_uses"] >= 5 and r["success_rate"] < 0.3
+            ]
 
         return {
-            'total_rules': len(rules),
-            'rules_by_status': rules_by_status,
-            'rule_details': rules,
-            'unused_rules': [r['id'] for r in unused],
-            'rules_never_succeeded': [r['id'] for r in never_succeeded],
-            'low_success_rules': [{'id': r['id'], 'rate': r['success_rate'], 'uses': r['total_uses']} for r in low_success]
+            "total_rules": len(rules),
+            "rules_by_status": rules_by_status,
+            "rule_details": rules,
+            "unused_rules": [r["id"] for r in unused],
+            "rules_never_succeeded": [r["id"] for r in never_succeeded],
+            "low_success_rules": [
+                {"id": r["id"], "rate": r["success_rate"], "uses": r["total_uses"]}
+                for r in low_success
+            ],
         }
 
     def collect_winloss_patterns(self, hours: int) -> Dict[str, Any]:
         """Analyze win/loss patterns."""
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
 
             # Win rate by coin
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT coin_name,
                     COUNT(CASE WHEN pnl_usd > 0 THEN 1 END) as wins,
                     COUNT(*) as total
                 FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
                 GROUP BY coin_name
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             win_rate_by_coin = {}
             for row in cursor.fetchall():
                 if row[2] > 0:
                     win_rate_by_coin[row[0]] = {
-                        'wins': row[1],
-                        'total': row[2],
-                        'rate': round(row[1] / row[2], 3)
+                        "wins": row[1],
+                        "total": row[2],
+                        "rate": round(row[1] / row[2], 3),
                     }
 
             # Win rate by hour
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT strftime('%H', closed_at) as hour,
                     COUNT(CASE WHEN pnl_usd > 0 THEN 1 END) as wins,
                     COUNT(*) as total
                 FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
                 GROUP BY hour
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             win_rate_by_hour = {}
             for row in cursor.fetchall():
                 if row[2] > 0:
                     win_rate_by_hour[int(row[0])] = round(row[1] / row[2], 3)
 
             # Win rate by exit reason
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT exit_reason,
                     COUNT(*) as cnt,
                     SUM(pnl_usd) as total_pnl,
                     AVG(pnl_usd) as avg_pnl
                 FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
                 GROUP BY exit_reason
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             by_exit_reason = {}
             for row in cursor.fetchall():
                 by_exit_reason[row[0]] = {
-                    'count': row[1],
-                    'total_pnl': round(row[2] or 0, 2),
-                    'avg_pnl': round(row[3] or 0, 2)
+                    "count": row[1],
+                    "total_pnl": round(row[2] or 0, 2),
+                    "avg_pnl": round(row[3] or 0, 2),
                 }
 
             # Streak analysis - get last 20 trades
             cursor.execute("""
                 SELECT pnl_usd FROM closed_trades
@@ -418,30 +457,34 @@
                     current_loss += 1
                     current_win = 0
                     max_loss_streak = max(max_loss_streak, current_loss)
 
         # Win rate by tier
-        win_rate_by_tier = {1: {'wins': 0, 'total': 0}, 2: {'wins': 0, 'total': 0}, 3: {'wins': 0, 'total': 0}}
+        win_rate_by_tier = {
+            1: {"wins": 0, "total": 0},
+            2: {"wins": 0, "total": 0},
+            3: {"wins": 0, "total": 0},
+        }
         for coin, stats in win_rate_by_coin.items():
             tier = get_tier(coin)
-            win_rate_by_tier[tier]['wins'] += stats['wins']
-            win_rate_by_tier[tier]['total'] += stats['total']
+            win_rate_by_tier[tier]["wins"] += stats["wins"]
+            win_rate_by_tier[tier]["total"] += stats["total"]
 
         for tier in win_rate_by_tier:
             t = win_rate_by_tier[tier]
-            t['rate'] = round(t['wins'] / t['total'], 3) if t['total'] > 0 else 0
+            t["rate"] = round(t["wins"] / t["total"], 3) if t["total"] > 0 else 0
 
         return {
-            'win_rate_by_coin': win_rate_by_coin,
-            'win_rate_by_tier': win_rate_by_tier,
-            'win_rate_by_hour': win_rate_by_hour,
-            'by_exit_reason': by_exit_reason,
-            'streak_analysis': {
-                'current_streak': current_streak,
-                'max_win_streak': max_win_streak,
-                'max_loss_streak': max_loss_streak
-            }
+            "win_rate_by_coin": win_rate_by_coin,
+            "win_rate_by_tier": win_rate_by_tier,
+            "win_rate_by_hour": win_rate_by_hour,
+            "by_exit_reason": by_exit_reason,
+            "streak_analysis": {
+                "current_streak": current_streak,
+                "max_win_streak": max_win_streak,
+                "max_loss_streak": max_loss_streak,
+            },
         }
 
     def collect_account_health(self) -> Dict[str, Any]:
         """Track account state."""
         with self.db._get_connection() as conn:
@@ -462,11 +505,13 @@
                 SELECT date(closed_at) as day, SUM(pnl_usd) as daily_pnl
                 FROM closed_trades
                 WHERE closed_at > datetime('now', '-7 days')
                 GROUP BY day ORDER BY day
             """)
-            daily_pnl = [{'date': row[0], 'pnl': round(row[1], 2)} for row in cursor.fetchall()]
+            daily_pnl = [
+                {"date": row[0], "pnl": round(row[1], 2)} for row in cursor.fetchall()
+            ]
 
             # Trades rejected (from activity log)
             cursor.execute("""
                 SELECT COUNT(*) FROM activity_log
                 WHERE activity_type IN ('risk_check_failed', 'decision_rejected')
@@ -474,74 +519,88 @@
             """)
             rejected_trades = cursor.fetchone()[0]
 
             # Determine trend
             if len(daily_pnl) >= 2:
-                recent_avg = sum(d['pnl'] for d in daily_pnl[-3:]) / min(3, len(daily_pnl))
+                recent_avg = sum(d["pnl"] for d in daily_pnl[-3:]) / min(
+                    3, len(daily_pnl)
+                )
                 if recent_avg > 1:
-                    trend = 'improving'
+                    trend = "improving"
                 elif recent_avg < -1:
-                    trend = 'declining'
+                    trend = "declining"
                 else:
-                    trend = 'stable'
+                    trend = "stable"
             else:
-                trend = 'insufficient_data'
+                trend = "insufficient_data"
 
             # Exposure utilization
             max_exposure = current_balance * 0.10
             exposure_util = in_positions / max_exposure if max_exposure > 0 else 0
 
         return {
-            'current_balance': round(current_balance, 2),
-            'starting_balance': starting_balance,
-            'total_pnl': round(total_pnl, 2),
-            'pnl_percent': round((total_pnl / starting_balance) * 100, 2),
-            'in_positions': round(in_positions, 2),
-            'exposure_utilization': round(exposure_util, 2),
-            'pnl_trend': trend,
-            'daily_pnl_history': daily_pnl,
-            'trades_rejected_24h': rejected_trades
+            "current_balance": round(current_balance, 2),
+            "starting_balance": starting_balance,
+            "total_pnl": round(total_pnl, 2),
+            "pnl_percent": round((total_pnl / starting_balance) * 100, 2),
+            "in_positions": round(in_positions, 2),
+            "exposure_utilization": round(exposure_util, 2),
+            "pnl_trend": trend,
+            "daily_pnl_history": daily_pnl,
+            "trades_rejected_24h": rejected_trades,
         }
 
     def collect_system_metrics(self, hours: int) -> Dict[str, Any]:
         """Collect system health data."""
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
 
             # Activity counts by type
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT activity_type, COUNT(*) FROM activity_log
                 WHERE created_at > datetime('now', ? || ' hours')
                 GROUP BY activity_type
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             activity_counts = {row[0]: row[1] for row in cursor.fetchall()}
 
             # Error counts
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM activity_log
                 WHERE activity_type IN ('error', 'cycle_error', 'bot_error')
                 AND created_at > datetime('now', ? || ' hours')
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             error_count = cursor.fetchone()[0]
 
             # Cycle count (approximate from bot_started to now)
-            cycles = activity_counts.get('llm_decision', 0)
+            cycles = activity_counts.get("llm_decision", 0)
 
             # Cooldown rejections
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM activity_log
                 WHERE activity_type = 'risk_check_failed'
                 AND description LIKE '%cooldown%'
                 AND created_at > datetime('now', ? || ' hours')
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             cooldown_rejections = cursor.fetchone()[0]
 
             # Unique coins traded
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(DISTINCT coin_name) FROM closed_trades
                 WHERE closed_at > datetime('now', ? || ' hours')
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             unique_coins = cursor.fetchone()[0]
 
             # Current cooldowns
             cursor.execute("""
                 SELECT COUNT(*) FROM coin_cooldowns
@@ -554,20 +613,20 @@
                 SELECT MAX(last_updated) FROM market_data
             """)
             last_market_update = cursor.fetchone()[0]
 
         return {
-            'cycles_estimated': cycles,
-            'error_count': error_count,
-            'error_rate': round(error_count / cycles, 4) if cycles > 0 else 0,
-            'activity_counts': activity_counts,
-            'cooldown_stats': {
-                'rejections': cooldown_rejections,
-                'unique_coins_traded': unique_coins,
-                'active_cooldowns': active_cooldowns
+            "cycles_estimated": cycles,
+            "error_count": error_count,
+            "error_rate": round(error_count / cycles, 4) if cycles > 0 else 0,
+            "activity_counts": activity_counts,
+            "cooldown_stats": {
+                "rejections": cooldown_rejections,
+                "unique_coins_traded": unique_coins,
+                "active_cooldowns": active_cooldowns,
             },
-            'last_market_update': last_market_update
+            "last_market_update": last_market_update,
         }
 
     def collect_learning_quality(self, hours: int) -> Dict[str, Any]:
         """Analyze quality of learnings."""
         with self.db._get_connection() as conn:
@@ -576,14 +635,17 @@
             # Total learnings
             cursor.execute("SELECT COUNT(*) FROM learnings")
             total_learnings = cursor.fetchone()[0]
 
             # Recent learnings
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT COUNT(*) FROM learnings
                 WHERE created_at > datetime('now', ? || ' hours')
-            """, (f'-{hours}',))
+            """,
+                (f"-{hours}",),
+            )
             recent_learnings = cursor.fetchone()[0]
 
             # Average confidence
             cursor.execute("SELECT AVG(confidence_level) FROM learnings")
             avg_confidence = cursor.fetchone()[0] or 0
@@ -621,24 +683,26 @@
                 if start in seen_starts:
                     duplicates += 1
                 seen_starts.add(start)
 
         return {
-            'total_learnings': total_learnings,
-            'learnings_last_period': recent_learnings,
-            'avg_confidence': round(avg_confidence, 3),
-            'by_outcome': by_outcome,
-            'rules_created': rules_from_learnings,
-            'potential_duplicates': duplicates,
-            'sample_learnings': recent_texts[:5]
+            "total_learnings": total_learnings,
+            "learnings_last_period": recent_learnings,
+            "avg_confidence": round(avg_confidence, 3),
+            "by_outcome": by_outcome,
+            "rules_created": rules_from_learnings,
+            "potential_duplicates": duplicates,
+            "sample_learnings": recent_texts[:5],
         }
 
     # =========================================================================
     # LLM ANALYSIS
     # =========================================================================
 
-    def analyze_with_llm(self, report: Dict[str, Any], hours: int) -> List[Dict[str, Any]]:
+    def analyze_with_llm(
+        self, report: Dict[str, Any], hours: int
+    ) -> List[Dict[str, Any]]:
         """Send report to LLM for critical analysis.
 
         Args:
             report: Collected data report.
             hours: Analysis period in hours.
@@ -680,36 +744,38 @@
         # Query LLM
         response = self.llm.query_json(user_prompt, MONITOR_SYSTEM_PROMPT)
 
         if response is None:
             logger.error("LLM returned no response")
-            return [{
-                'type': 'performance',
-                'severity': 'high',
-                'title': 'LLM analysis failed',
-                'description': 'The monitoring LLM query returned no response',
-                'evidence': 'query_json returned None',
-                'recommendation': 'Check LLM connectivity and try again'
-            }]
+            return [
+                {
+                    "type": "performance",
+                    "severity": "high",
+                    "title": "LLM analysis failed",
+                    "description": "The monitoring LLM query returned no response",
+                    "evidence": "query_json returned None",
+                    "recommendation": "Check LLM connectivity and try again",
+                }
+            ]
 
         # Handle both list and dict responses
         if isinstance(response, list):
             findings = response
-        elif isinstance(response, dict) and 'findings' in response:
-            findings = response['findings']
+        elif isinstance(response, dict) and "findings" in response:
+            findings = response["findings"]
         else:
             logger.warning(f"Unexpected LLM response format: {type(response)}")
             findings = [response] if isinstance(response, dict) else []
 
         # Validate findings
         valid_findings = []
         for f in findings:
-            if isinstance(f, dict) and 'type' in f and 'severity' in f and 'title' in f:
+            if isinstance(f, dict) and "type" in f and "severity" in f and "title" in f:
                 # Ensure all required fields exist
-                f.setdefault('description', f.get('title', 'No description'))
-                f.setdefault('evidence', '')
-                f.setdefault('recommendation', '')
+                f.setdefault("description", f.get("title", "No description"))
+                f.setdefault("evidence", "")
+                f.setdefault("recommendation", "")
                 valid_findings.append(f)
 
         logger.info(f"LLM returned {len(valid_findings)} valid findings")
         return valid_findings
 
@@ -726,31 +792,37 @@
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
 
             for finding in findings:
                 # Check for duplicate (same title in last hour)
-                cursor.execute("""
+                cursor.execute(
+                    """
                     SELECT id FROM monitoring_alerts
                     WHERE title = ? AND created_at > datetime('now', '-1 hour')
-                """, (finding['title'],))
+                """,
+                    (finding["title"],),
+                )
 
                 if cursor.fetchone():
                     logger.debug(f"Skipping duplicate alert: {finding['title']}")
                     continue
 
-                cursor.execute("""
+                cursor.execute(
+                    """
                     INSERT INTO monitoring_alerts
                     (alert_type, severity, title, description, evidence, recommendation)
                     VALUES (?, ?, ?, ?, ?, ?)
-                """, (
-                    finding.get('type', 'unknown'),
-                    finding.get('severity', 'info'),
-                    finding.get('title', 'Untitled'),
-                    finding.get('description', ''),
-                    finding.get('evidence', ''),
-                    finding.get('recommendation', '')
-                ))
+                """,
+                    (
+                        finding.get("type", "unknown"),
+                        finding.get("severity", "info"),
+                        finding.get("title", "Untitled"),
+                        finding.get("description", ""),
+                        finding.get("evidence", ""),
+                        finding.get("recommendation", ""),
+                    ),
+                )
 
             conn.commit()
 
     def log_summary(self, findings: List[Dict[str, Any]]) -> None:
         """Log summary of findings.
@@ -759,59 +831,57 @@
             findings: List of findings.
         """
         # Count by severity
         by_severity = {}
         for f in findings:
-            sev = f.get('severity', 'unknown')
+            sev = f.get("severity", "unknown")
             by_severity[sev] = by_severity.get(sev, 0) + 1
 
         print("\n" + "=" * 50)
         print("MONITORING COMPLETE")
         print("=" * 50)
         print(f"Total findings: {len(findings)}")
 
-        for sev in ['critical', 'high', 'medium', 'low', 'info']:
+        for sev in ["critical", "high", "medium", "low", "info"]:
             if sev in by_severity:
                 print(f"  {sev}: {by_severity[sev]}")
 
         # Show high+ severity details
-        high_plus = [f for f in findings if f.get('severity') in ['critical', 'high']]
+        high_plus = [f for f in findings if f.get("severity") in ["critical", "high"]]
         if high_plus:
             print(f"\n{'='*50}")
             print("HIGH+ SEVERITY FINDINGS:")
             print("=" * 50)
             for f in high_plus:
-                print(f"\n[{f.get('severity', '?').upper()}] {f.get('type', '?')}: {f.get('title', '?')}")
+                print(
+                    f"\n[{f.get('severity', '?').upper()}] {f.get('type', '?')}: {f.get('title', '?')}"
+                )
                 print(f"  {f.get('description', '')[:200]}")
-                if f.get('evidence'):
+                if f.get("evidence"):
                     print(f"  Evidence: {f.get('evidence')[:150]}")
-                if f.get('recommendation'):
+                if f.get("recommendation"):
                     print(f"  Fix: {f.get('recommendation')[:150]}")
 
         print("=" * 50 + "\n")
 
 
 # =============================================================================
 # MAIN
 # =============================================================================
 
+
 def main():
     """Main entry point."""
     parser = argparse.ArgumentParser(
-        description='Autonomous monitoring agent for the trading bot'
+        description="Autonomous monitoring agent for the trading bot"
     )
     parser.add_argument(
-        '--hours', type=int, default=24,
-        help='Hours of data to analyze (default: 24)'
+        "--hours", type=int, default=24, help="Hours of data to analyze (default: 24)"
     )
+    parser.add_argument("--verbose", action="store_true", help="Enable verbose output")
     parser.add_argument(
-        '--verbose', action='store_true',
-        help='Enable verbose output'
-    )
-    parser.add_argument(
-        '--dry-run', action='store_true',
-        help='Run analysis but do not store findings'
+        "--dry-run", action="store_true", help="Run analysis but do not store findings"
     )
     args = parser.parse_args()
 
     if args.verbose:
         logging.getLogger().setLevel(logging.DEBUG)
@@ -819,15 +889,15 @@
     # Run monitor
     monitor = AutonomousMonitor()
     findings = monitor.run(hours=args.hours, dry_run=args.dry_run)
 
     # Exit with code based on severity
-    if any(f.get('severity') == 'critical' for f in findings):
+    if any(f.get("severity") == "critical" for f in findings):
         sys.exit(2)
-    elif any(f.get('severity') == 'high' for f in findings):
+    elif any(f.get("severity") == "high" for f in findings):
         sys.exit(1)
     else:
         sys.exit(0)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     main()
would reformat /mnt/c/documents/crypto-trading-bot/scripts/autonomous_monitor.py
--- /mnt/c/documents/crypto-trading-bot/src/technical/__init__.py	2026-02-04 15:44:31.533780+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/__init__.py	2026-02-04 21:34:25.157872+00:00
@@ -1,6 +1,7 @@
 """Technical analysis module for indicators."""
+
 from .candle_fetcher import CandleFetcher, Candle, CandleData
 from .rsi import RSICalculator, RSIData
 from .atr import ATRCalculator, ATRData
 from .funding import FundingRateFetcher, FundingData
 from .vwap import VWAPCalculator, VWAPData
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/__init__.py
--- /mnt/c/documents/crypto-trading-bot/src/dashboard_v2.py	2026-02-03 19:05:46.887989+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/dashboard_v2.py	2026-02-04 21:34:25.159750+00:00
@@ -32,10 +32,11 @@
 
 # =============================================================================
 # Pydantic Models for API
 # =============================================================================
 
+
 class BlacklistRequest(BaseModel):
     coin: str
     reason: str = "Manual override"
 
 
@@ -60,10 +61,11 @@
 
 
 # =============================================================================
 # Dashboard Server
 # =============================================================================
+
 
 class DashboardServer:
     """
     FastAPI server for the trading dashboard.
 
@@ -101,13 +103,11 @@
 
     def _setup_static(self) -> None:
         """Mount static files directory."""
         if self.static_dir.exists():
             self.app.mount(
-                "/static",
-                StaticFiles(directory=str(self.static_dir)),
-                name="static"
+                "/static", StaticFiles(directory=str(self.static_dir)), name="static"
             )
 
     def _setup_routes(self) -> None:
         """Set up all API and page routes."""
 
@@ -117,44 +117,39 @@
 
         @self.app.get("/", response_class=HTMLResponse)
         async def index(request: Request):
             """Real-time view - home page."""
             return self.templates.TemplateResponse(
-                "index.html",
-                {"request": request, "page": "realtime"}
+                "index.html", {"request": request, "page": "realtime"}
             )
 
         @self.app.get("/knowledge", response_class=HTMLResponse)
         async def knowledge_page(request: Request):
             """Knowledge brain browser."""
             return self.templates.TemplateResponse(
-                "knowledge.html",
-                {"request": request, "page": "knowledge"}
+                "knowledge.html", {"request": request, "page": "knowledge"}
             )
 
         @self.app.get("/adaptations", response_class=HTMLResponse)
         async def adaptations_page(request: Request):
             """Adaptations log."""
             return self.templates.TemplateResponse(
-                "adaptations.html",
-                {"request": request, "page": "adaptations"}
+                "adaptations.html", {"request": request, "page": "adaptations"}
             )
 
         @self.app.get("/profitability", response_class=HTMLResponse)
         async def profitability_page(request: Request):
             """Profitability stats."""
             return self.templates.TemplateResponse(
-                "profitability.html",
-                {"request": request, "page": "profitability"}
+                "profitability.html", {"request": request, "page": "profitability"}
             )
 
         @self.app.get("/overrides", response_class=HTMLResponse)
         async def overrides_page(request: Request):
             """Manual overrides (paper trading)."""
             return self.templates.TemplateResponse(
-                "overrides.html",
-                {"request": request, "page": "overrides"}
+                "overrides.html", {"request": request, "page": "overrides"}
             )
 
         # =====================================================================
         # Real-Time API
         # =====================================================================
@@ -190,11 +185,13 @@
             # Add current prices for unrealized P&L
             formatted = []
             for pos in positions:
                 current_price = None
                 if self.system.health:
-                    current_price = self.system.health.get_last_price(pos.get("coin", ""))
+                    current_price = self.system.health.get_last_price(
+                        pos.get("coin", "")
+                    )
 
                 pos_data = {
                     **pos,
                     "current_price": current_price,
                 }
@@ -210,11 +207,12 @@
                     else:
                         pos_data["unrealized_pnl"] = (entry - current_price) * size
 
                     pos_data["unrealized_pnl_pct"] = (
                         (pos_data["unrealized_pnl"] / (entry * size)) * 100
-                        if entry * size > 0 else 0
+                        if entry * size > 0
+                        else 0
                     )
 
                 formatted.append(pos_data)
 
             return {"count": len(formatted), "positions": formatted}
@@ -232,10 +230,11 @@
             return {"prices": prices, "count": len(prices)}
 
         @self.app.get("/api/feed")
         async def event_stream():
             """SSE endpoint for real-time updates."""
+
             async def generate():
                 while True:
                     try:
                         data = self._get_feed_data()
                         yield f"data: {json.dumps(data)}\n\n"
@@ -376,12 +375,17 @@
 
         @self.app.get("/api/profitability/by/{dimension}")
         async def get_performance_by_dimension(dimension: str):
             """Get performance by coin/hour/day/pattern."""
             valid_dimensions = [
-                "coin", "pattern", "hour_of_day", "day_of_week",
-                "exit_reason", "position_size", "hold_duration"
+                "coin",
+                "pattern",
+                "hour_of_day",
+                "day_of_week",
+                "exit_reason",
+                "position_size",
+                "hold_duration",
             ]
             if dimension not in valid_dimensions:
                 raise HTTPException(400, f"Invalid dimension. Use: {valid_dimensions}")
 
             result = self.system.get_performance_by_dimension(dimension)
@@ -599,11 +603,13 @@
                 try:
                     applied = datetime.fromisoformat(adaptation["applied_at"])
                     delta = datetime.now() - applied
                     hours = delta.total_seconds() / 3600
                     if hours < 1:
-                        adaptation["relative_time"] = f"{int(delta.total_seconds() / 60)}m ago"
+                        adaptation["relative_time"] = (
+                            f"{int(delta.total_seconds() / 60)}m ago"
+                        )
                     elif hours < 24:
                         adaptation["relative_time"] = f"{int(hours)}h ago"
                     else:
                         adaptation["relative_time"] = f"{int(hours / 24)}d ago"
                 except (ValueError, TypeError):
--- /mnt/c/documents/crypto-trading-bot/src/models/reflection.py	2026-02-03 18:05:52.863555+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/models/reflection.py	2026-02-04 21:34:25.159563+00:00
@@ -264,13 +264,19 @@
             "win_rate": self.win_rate,
             "wins": self.wins,
             "losses": self.losses,
             "coin_analyses": [c.to_dict() for c in self.coin_analyses],
             "pattern_analyses": [p.to_dict() for p in self.pattern_analyses],
-            "time_analysis": self.time_analysis.to_dict() if self.time_analysis else None,
-            "regime_analysis": self.regime_analysis.to_dict() if self.regime_analysis else None,
-            "exit_analysis": self.exit_analysis.to_dict() if self.exit_analysis else None,
+            "time_analysis": (
+                self.time_analysis.to_dict() if self.time_analysis else None
+            ),
+            "regime_analysis": (
+                self.regime_analysis.to_dict() if self.regime_analysis else None
+            ),
+            "exit_analysis": (
+                self.exit_analysis.to_dict() if self.exit_analysis else None
+            ),
             "insights": [i.to_dict() for i in self.insights],
             "summary": self.summary,
             "analysis_time_ms": self.analysis_time_ms,
             "llm_time_ms": self.llm_time_ms,
             "total_time_ms": self.total_time_ms,
would reformat /mnt/c/documents/crypto-trading-bot/src/dashboard_v2.py
would reformat /mnt/c/documents/crypto-trading-bot/src/models/reflection.py
--- /mnt/c/documents/crypto-trading-bot/src/sentiment/fear_greed.py	2026-02-04 01:05:41.545465+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/sentiment/fear_greed.py	2026-02-04 21:34:25.167200+00:00
@@ -1,6 +1,7 @@
 """Fear & Greed Index fetcher from Alternative.me API."""
+
 import logging
 from dataclasses import dataclass
 from datetime import datetime, timedelta
 from typing import Optional, List
 import requests
@@ -9,12 +10,13 @@
 
 
 @dataclass
 class FearGreedData:
     """Fear & Greed Index data point."""
-    value: int                    # 0-100
-    classification: str           # "Extreme Fear", "Fear", "Neutral", "Greed", "Extreme Greed"
+
+    value: int  # 0-100
+    classification: str  # "Extreme Fear", "Fear", "Neutral", "Greed", "Extreme Greed"
     timestamp: datetime
 
     @property
     def is_extreme_fear(self) -> bool:
         """Market in extreme fear (potential buying opportunity)."""
@@ -76,10 +78,11 @@
                     return data
             except Exception as e:
                 logger.warning(f"Fear & Greed API attempt {attempt + 1} failed: {e}")
                 if attempt < self._retry_count - 1:
                     import time
+
                     time.sleep(self._retry_delay * (attempt + 1))
 
         # All retries failed - return cached if available
         if self._cached_data:
             logger.warning("Using stale Fear & Greed data after API failure")
@@ -96,24 +99,23 @@
 
         Returns:
             List of FearGreedData, newest first
         """
         try:
-            response = requests.get(
-                f"{self.API_URL}?limit={days}",
-                timeout=10
-            )
+            response = requests.get(f"{self.API_URL}?limit={days}", timeout=10)
             response.raise_for_status()
             data = response.json()
 
             results = []
             for item in data.get("data", []):
-                results.append(FearGreedData(
-                    value=int(item["value"]),
-                    classification=item["value_classification"],
-                    timestamp=datetime.fromtimestamp(int(item["timestamp"]))
-                ))
+                results.append(
+                    FearGreedData(
+                        value=int(item["value"]),
+                        classification=item["value_classification"],
+                        timestamp=datetime.fromtimestamp(int(item["timestamp"])),
+                    )
+                )
             return results
 
         except Exception as e:
             logger.error(f"Failed to fetch historical Fear & Greed: {e}")
             return []
@@ -130,11 +132,11 @@
         current = data["data"][0]
 
         return FearGreedData(
             value=int(current["value"]),
             classification=current["value_classification"],
-            timestamp=datetime.fromtimestamp(int(current["timestamp"]))
+            timestamp=datetime.fromtimestamp(int(current["timestamp"])),
         )
 
     def _is_cache_valid(self) -> bool:
         """Check if cached data is still fresh."""
         if self._cached_data is None or self._cache_time is None:
@@ -145,8 +147,10 @@
             return False
 
         # Warn if data is >24 hours old (stale)
         data_age = datetime.now() - self._cached_data.timestamp
         if data_age > timedelta(hours=24):
-            logger.warning(f"Fear & Greed data is {data_age.total_seconds()/3600:.1f}h old")
+            logger.warning(
+                f"Fear & Greed data is {data_age.total_seconds()/3600:.1f}h old"
+            )
 
         return True
would reformat /mnt/c/documents/crypto-trading-bot/src/sentiment/fear_greed.py
--- /mnt/c/documents/crypto-trading-bot/src/learning_system.py	2026-01-14 23:39:37.072617+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/learning_system.py	2026-02-04 21:34:25.168364+00:00
@@ -19,19 +19,19 @@
 from src.database import Database
 from src.llm_interface import LLMInterface
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 
 @dataclass
 class Learning:
     """A learning extracted from a trade analysis."""
+
     id: Optional[int]
     trade_id: int
     what_happened: str
     why_outcome: str
     pattern: str
@@ -40,18 +40,18 @@
     created_at: Optional[str] = None
 
     def to_dict(self) -> Dict[str, Any]:
         """Convert to dictionary."""
         return {
-            'id': self.id,
-            'trade_id': self.trade_id,
-            'what_happened': self.what_happened,
-            'why_outcome': self.why_outcome,
-            'pattern': self.pattern,
-            'lesson': self.lesson,
-            'confidence': self.confidence,
-            'created_at': self.created_at
+            "id": self.id,
+            "trade_id": self.trade_id,
+            "what_happened": self.what_happened,
+            "why_outcome": self.why_outcome,
+            "pattern": self.pattern,
+            "lesson": self.lesson,
+            "confidence": self.confidence,
+            "created_at": self.created_at,
         }
 
     def to_text(self) -> str:
         """Convert to readable text for LLM context."""
         return f"[Confidence: {self.confidence:.0%}] {self.lesson}"
@@ -90,25 +90,39 @@
         Returns:
             Trade dictionary or None if not found.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT id, coin_name, entry_price, exit_price, size_usd,
                        pnl_usd, pnl_pct, entry_reason, exit_reason,
                        opened_at, closed_at, duration_seconds
                 FROM closed_trades
                 WHERE id = ?
-            """, (trade_id,))
+            """,
+                (trade_id,),
+            )
 
             row = cursor.fetchone()
             if row is None:
                 return None
 
-            columns = ['id', 'coin_name', 'entry_price', 'exit_price', 'size_usd',
-                      'pnl_usd', 'pnl_pct', 'entry_reason', 'exit_reason',
-                      'opened_at', 'closed_at', 'duration_seconds']
+            columns = [
+                "id",
+                "coin_name",
+                "entry_price",
+                "exit_price",
+                "size_usd",
+                "pnl_usd",
+                "pnl_pct",
+                "entry_reason",
+                "exit_reason",
+                "opened_at",
+                "closed_at",
+                "duration_seconds",
+            ]
 
             return dict(zip(columns, row))
 
     def get_market_context(self, coin: str) -> Dict[str, Any]:
         """Get current market context for a coin.
@@ -119,22 +133,25 @@
         Returns:
             Dict with market data context.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT price_usd, change_24h, last_updated
                 FROM market_data
                 WHERE coin = ?
-            """, (coin,))
+            """,
+                (coin,),
+            )
 
             row = cursor.fetchone()
             if row:
                 return {
-                    'current_price': row[0],
-                    'change_24h': row[1] or 0,
-                    'last_updated': row[2]
+                    "current_price": row[0],
+                    "change_24h": row[1] or 0,
+                    "last_updated": row[2],
                 }
             return {}
 
     def build_analysis_prompt(self, trade: Dict[str, Any]) -> str:
         """Build the prompt for trade analysis.
@@ -144,14 +161,14 @@
 
         Returns:
             Formatted prompt string.
         """
         # Get market context
-        market = self.get_market_context(trade['coin_name'])
-
-        pnl_status = "PROFIT" if trade['pnl_usd'] >= 0 else "LOSS"
-        duration_mins = trade.get('duration_seconds', 0) / 60
+        market = self.get_market_context(trade["coin_name"])
+
+        pnl_status = "PROFIT" if trade["pnl_usd"] >= 0 else "LOSS"
+        duration_mins = trade.get("duration_seconds", 0) / 60
 
         prompt = f"""You are analyzing a completed cryptocurrency trade to learn from the outcome.
 
 === TRADE DETAILS ===
 Coin: {trade['coin_name'].upper()}
@@ -201,12 +218,11 @@
 
         # Check if LLM is available
         if self.llm is None:
             logger.warning("LLM not available - cannot analyze trade")
             self.db.log_activity(
-                "learning_skipped",
-                f"Trade #{trade_id} not analyzed - LLM unavailable"
+                "learning_skipped", f"Trade #{trade_id} not analyzed - LLM unavailable"
             )
             return None
 
         # Get trade details
         trade = self.get_closed_trade(trade_id)
@@ -231,55 +247,63 @@
         result = self.llm.query_json(prompt, system_prompt)
 
         if result is None:
             logger.error(f"Failed to get LLM analysis for trade #{trade_id}")
             self.db.log_activity(
-                "learning_failed",
-                f"LLM analysis failed for trade #{trade_id}"
+                "learning_failed", f"LLM analysis failed for trade #{trade_id}"
             )
             return None
 
         # Validate response
-        required_fields = ['what_happened', 'why_outcome', 'pattern', 'lesson', 'confidence']
+        required_fields = [
+            "what_happened",
+            "why_outcome",
+            "pattern",
+            "lesson",
+            "confidence",
+        ]
         for field in required_fields:
             if field not in result:
                 logger.error(f"LLM response missing field: {field}")
                 return None
 
         # Store learning in database
         learning_text = json.dumps(result)
-        confidence = float(result.get('confidence', 0.5))
-
-        with self.db._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+        confidence = float(result.get("confidence", 0.5))
+
+        with self.db._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 INSERT INTO learnings (
                     trade_id, learning_text, pattern_observed, confidence_level, created_at
                 ) VALUES (?, ?, ?, ?, datetime('now'))
-            """, (trade_id, learning_text, result.get('pattern', ''), confidence))
+            """,
+                (trade_id, learning_text, result.get("pattern", ""), confidence),
+            )
 
             learning_id = cursor.lastrowid
             conn.commit()
 
         # Log the learning creation
         self.db.log_activity(
             "learning_created",
             f"Trade #{trade_id}: {result['lesson'][:100]}...",
-            f"confidence={confidence:.2f}, pattern={result.get('pattern', '')[:50]}"
+            f"confidence={confidence:.2f}, pattern={result.get('pattern', '')[:50]}",
         )
 
         logger.info(f"Learning #{learning_id} created for trade #{trade_id}")
         logger.info(f"Lesson: {result['lesson']}")
 
         return Learning(
             id=learning_id,
             trade_id=trade_id,
-            what_happened=result['what_happened'],
-            why_outcome=result['why_outcome'],
-            pattern=result['pattern'],
-            lesson=result['lesson'],
-            confidence=confidence
+            what_happened=result["what_happened"],
+            why_outcome=result["why_outcome"],
+            pattern=result["pattern"],
+            lesson=result["lesson"],
+            confidence=confidence,
         )
 
     def get_learning_for_trade(self, trade_id: int) -> Optional[Learning]:
         """Get existing learning for a trade.
 
@@ -289,35 +313,38 @@
         Returns:
             Learning object or None if not found.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT id, trade_id, learning_text, confidence_level, created_at
                 FROM learnings
                 WHERE trade_id = ?
-            """, (trade_id,))
+            """,
+                (trade_id,),
+            )
 
             row = cursor.fetchone()
             if row is None:
                 return None
 
             # Parse learning text
             try:
                 data = json.loads(row[2])
             except json.JSONDecodeError:
-                data = {'lesson': row[2]}
+                data = {"lesson": row[2]}
 
             return Learning(
                 id=row[0],
                 trade_id=row[1],
-                what_happened=data.get('what_happened', ''),
-                why_outcome=data.get('why_outcome', ''),
-                pattern=data.get('pattern', ''),
-                lesson=data.get('lesson', ''),
+                what_happened=data.get("what_happened", ""),
+                why_outcome=data.get("why_outcome", ""),
+                pattern=data.get("pattern", ""),
+                lesson=data.get("lesson", ""),
                 confidence=row[3],
-                created_at=row[4]
+                created_at=row[4],
             )
 
     def get_learnings_for_decision(self, limit: int = 10) -> List[Learning]:
         """Get recent high-confidence learnings to inform decisions.
 
@@ -329,35 +356,40 @@
         Returns:
             List of Learning objects.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT id, trade_id, learning_text, confidence_level, created_at
                 FROM learnings
                 WHERE confidence_level >= 0.5
                 ORDER BY confidence_level DESC, created_at DESC
                 LIMIT ?
-            """, (limit,))
+            """,
+                (limit,),
+            )
 
             learnings = []
             for row in cursor.fetchall():
                 try:
                     data = json.loads(row[2])
                 except json.JSONDecodeError:
-                    data = {'lesson': row[2]}
-
-                learnings.append(Learning(
-                    id=row[0],
-                    trade_id=row[1],
-                    what_happened=data.get('what_happened', ''),
-                    why_outcome=data.get('why_outcome', ''),
-                    pattern=data.get('pattern', ''),
-                    lesson=data.get('lesson', ''),
-                    confidence=row[3],
-                    created_at=row[4]
-                ))
+                    data = {"lesson": row[2]}
+
+                learnings.append(
+                    Learning(
+                        id=row[0],
+                        trade_id=row[1],
+                        what_happened=data.get("what_happened", ""),
+                        why_outcome=data.get("why_outcome", ""),
+                        pattern=data.get("pattern", ""),
+                        lesson=data.get("lesson", ""),
+                        confidence=row[3],
+                        created_at=row[4],
+                    )
+                )
 
             return learnings
 
     def get_learnings_by_coin(self, coin: str) -> List[Learning]:
         """Get learnings related to a specific coin.
@@ -368,35 +400,40 @@
         Returns:
             List of Learning objects for that coin.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT l.id, l.trade_id, l.learning_text, l.confidence_level, l.created_at
                 FROM learnings l
                 JOIN closed_trades c ON l.trade_id = c.id
                 WHERE c.coin_name = ?
                 ORDER BY l.confidence_level DESC
-            """, (coin,))
+            """,
+                (coin,),
+            )
 
             learnings = []
             for row in cursor.fetchall():
                 try:
                     data = json.loads(row[2])
                 except json.JSONDecodeError:
-                    data = {'lesson': row[2]}
-
-                learnings.append(Learning(
-                    id=row[0],
-                    trade_id=row[1],
-                    what_happened=data.get('what_happened', ''),
-                    why_outcome=data.get('why_outcome', ''),
-                    pattern=data.get('pattern', ''),
-                    lesson=data.get('lesson', ''),
-                    confidence=row[3],
-                    created_at=row[4]
-                ))
+                    data = {"lesson": row[2]}
+
+                learnings.append(
+                    Learning(
+                        id=row[0],
+                        trade_id=row[1],
+                        what_happened=data.get("what_happened", ""),
+                        why_outcome=data.get("why_outcome", ""),
+                        pattern=data.get("pattern", ""),
+                        lesson=data.get("lesson", ""),
+                        confidence=row[3],
+                        created_at=row[4],
+                    )
+                )
 
             return learnings
 
     def get_all_learnings(self, limit: int = 50) -> List[Learning]:
         """Get all learnings for review.
@@ -407,34 +444,39 @@
         Returns:
             List of Learning objects.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT id, trade_id, learning_text, confidence_level, created_at
                 FROM learnings
                 ORDER BY created_at DESC
                 LIMIT ?
-            """, (limit,))
+            """,
+                (limit,),
+            )
 
             learnings = []
             for row in cursor.fetchall():
                 try:
                     data = json.loads(row[2])
                 except json.JSONDecodeError:
-                    data = {'lesson': row[2]}
-
-                learnings.append(Learning(
-                    id=row[0],
-                    trade_id=row[1],
-                    what_happened=data.get('what_happened', ''),
-                    why_outcome=data.get('why_outcome', ''),
-                    pattern=data.get('pattern', ''),
-                    lesson=data.get('lesson', ''),
-                    confidence=row[3],
-                    created_at=row[4]
-                ))
+                    data = {"lesson": row[2]}
+
+                learnings.append(
+                    Learning(
+                        id=row[0],
+                        trade_id=row[1],
+                        what_happened=data.get("what_happened", ""),
+                        why_outcome=data.get("why_outcome", ""),
+                        pattern=data.get("pattern", ""),
+                        lesson=data.get("lesson", ""),
+                        confidence=row[3],
+                        created_at=row[4],
+                    )
+                )
 
             return learnings
 
     def get_unanalyzed_trades(self) -> List[int]:
         """Get trade IDs that haven't been analyzed yet.
@@ -487,21 +529,23 @@
             # Average confidence
             cursor.execute("SELECT AVG(confidence_level) FROM learnings")
             avg_confidence = cursor.fetchone()[0] or 0
 
             # High confidence learnings
-            cursor.execute("SELECT COUNT(*) FROM learnings WHERE confidence_level >= 0.7")
+            cursor.execute(
+                "SELECT COUNT(*) FROM learnings WHERE confidence_level >= 0.7"
+            )
             high_confidence = cursor.fetchone()[0]
 
             # Unanalyzed trades
             unanalyzed = len(self.get_unanalyzed_trades())
 
             return {
-                'total_learnings': total,
-                'average_confidence': avg_confidence,
-                'high_confidence_count': high_confidence,
-                'unanalyzed_trades': unanalyzed
+                "total_learnings": total,
+                "average_confidence": avg_confidence,
+                "high_confidence_count": high_confidence,
+                "unanalyzed_trades": unanalyzed,
             }
 
 
 def get_learnings_as_text(db: Database = None, limit: int = 10) -> List[str]:
     """Get learnings formatted as text for LLM context.
@@ -524,42 +568,43 @@
 # RULE CREATION FROM PATTERNS
 # =============================================================================
 
 # Rule creation configuration - adjustable thresholds
 MIN_CONFIDENCE_FOR_RULE = 0.7  # Minimum learning confidence to create a rule
-RULE_TEST_TRADES = 10          # Number of trades before evaluating rule
-RULE_PROMOTE_THRESHOLD = 0.6   # Success rate to promote to active
-RULE_REJECT_THRESHOLD = 0.4    # Success rate to reject rule
+RULE_TEST_TRADES = 10  # Number of trades before evaluating rule
+RULE_PROMOTE_THRESHOLD = 0.6  # Success rate to promote to active
+RULE_REJECT_THRESHOLD = 0.4  # Success rate to reject rule
 
 
 @dataclass
 class TradingRule:
     """A trading rule created from a high-confidence learning."""
+
     id: Optional[int]
-    rule_text: str              # The actionable rule
-    source_learning_id: int     # Which learning created this (traceability)
-    source_pattern: str         # The pattern it's based on
-    trigger_condition: str      # When the rule applies
-    expected_action: str        # BUY/SELL/HOLD/WAIT
-    status: str                 # "testing", "active", "rejected"
+    rule_text: str  # The actionable rule
+    source_learning_id: int  # Which learning created this (traceability)
+    source_pattern: str  # The pattern it's based on
+    trigger_condition: str  # When the rule applies
+    expected_action: str  # BUY/SELL/HOLD/WAIT
+    status: str  # "testing", "active", "rejected"
     success_count: int
     failure_count: int
     created_at: Optional[str] = None
 
     def to_dict(self) -> Dict[str, Any]:
         """Convert to dictionary."""
         return {
-            'id': self.id,
-            'rule_text': self.rule_text,
-            'source_learning_id': self.source_learning_id,
-            'source_pattern': self.source_pattern,
-            'trigger_condition': self.trigger_condition,
-            'expected_action': self.expected_action,
-            'status': self.status,
-            'success_count': self.success_count,
-            'failure_count': self.failure_count,
-            'created_at': self.created_at
+            "id": self.id,
+            "rule_text": self.rule_text,
+            "source_learning_id": self.source_learning_id,
+            "source_pattern": self.source_pattern,
+            "trigger_condition": self.trigger_condition,
+            "expected_action": self.expected_action,
+            "status": self.status,
+            "success_count": self.success_count,
+            "failure_count": self.failure_count,
+            "created_at": self.created_at,
         }
 
     def success_rate(self) -> float:
         """Calculate current success rate."""
         total = self.success_count + self.failure_count
@@ -614,11 +659,13 @@
         Returns:
             TradingRule if created, None if skipped or failed.
         """
         # Check confidence threshold
         if learning.confidence < self.min_confidence:
-            logger.info(f"Learning #{learning.id} confidence {learning.confidence:.0%} below threshold {self.min_confidence:.0%}")
+            logger.info(
+                f"Learning #{learning.id} confidence {learning.confidence:.0%} below threshold {self.min_confidence:.0%}"
+            )
             return None
 
         # Check if similar rule already exists
         if self._rule_exists_for_learning(learning.id):
             logger.info(f"Rule already exists for learning #{learning.id}")
@@ -627,50 +674,55 @@
         # Check if LLM available
         if self.llm is None:
             logger.warning("LLM not available - cannot create rule")
             return None
 
-        logger.info(f"Creating rule from learning #{learning.id} (confidence: {learning.confidence:.0%})")
+        logger.info(
+            f"Creating rule from learning #{learning.id} (confidence: {learning.confidence:.0%})"
+        )
 
         # Ask LLM to formulate actionable rule
         rule_data = self._formulate_rule(learning)
         if rule_data is None:
             logger.error("Failed to formulate rule from learning")
             return None
 
         # Store in database
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT INTO trading_rules (
                     rule_text, rule_type, status,
                     success_count, failure_count, created_at
                 ) VALUES (?, ?, 'testing', 0, 0, datetime('now'))
-            """, (rule_data['rule_text'], learning.pattern or 'learned'))
+            """,
+                (rule_data["rule_text"], learning.pattern or "learned"),
+            )
 
             rule_id = cursor.lastrowid
             conn.commit()
 
         # Log creation
         self.db.log_activity(
             "rule_created",
             f"Rule #{rule_id} from learning #{learning.id}: {rule_data['rule_text'][:80]}...",
-            f"trigger={rule_data.get('trigger_condition', '')[:50]}"
+            f"trigger={rule_data.get('trigger_condition', '')[:50]}",
         )
 
         logger.info(f"Rule #{rule_id} created: {rule_data['rule_text'][:60]}...")
 
         return TradingRule(
             id=rule_id,
-            rule_text=rule_data['rule_text'],
+            rule_text=rule_data["rule_text"],
             source_learning_id=learning.id,
             source_pattern=learning.pattern,
-            trigger_condition=rule_data.get('trigger_condition', ''),
-            expected_action=rule_data.get('expected_action', 'HOLD'),
-            status='testing',
+            trigger_condition=rule_data.get("trigger_condition", ""),
+            expected_action=rule_data.get("expected_action", "HOLD"),
+            status="testing",
             success_count=0,
-            failure_count=0
+            failure_count=0,
         )
 
     def _formulate_rule(self, learning: Learning) -> Optional[Dict[str, Any]]:
         """Ask LLM to formulate an actionable rule from a learning.
 
@@ -711,11 +763,11 @@
 Rules must be specific, measurable, and automatable.
 Always respond with valid JSON."""
 
         result = self.llm.query_json(prompt, system_prompt)
 
-        if result and 'rule_text' in result:
+        if result and "rule_text" in result:
             return result
         return None
 
     def _rule_exists_for_learning(self, learning_id: int) -> bool:
         """Check if a rule was already created from this learning.
@@ -731,19 +783,19 @@
         """Get all active rules for trading decisions.
 
         Returns:
             List of active TradingRule objects.
         """
-        return self._get_rules_by_status('active')
+        return self._get_rules_by_status("active")
 
     def get_testing_rules(self) -> List[TradingRule]:
         """Get rules currently being tested.
 
         Returns:
             List of testing TradingRule objects.
         """
-        return self._get_rules_by_status('testing')
+        return self._get_rules_by_status("testing")
 
     def get_all_rules(self) -> List[TradingRule]:
         """Get all rules regardless of status.
 
         Returns:
@@ -758,22 +810,24 @@
                 ORDER BY created_at DESC
             """)
 
             rules = []
             for row in cursor.fetchall():
-                rules.append(TradingRule(
-                    id=row[0],
-                    rule_text=row[1],
-                    source_learning_id=0,  # Not stored in current schema
-                    source_pattern=row[2] or '',
-                    trigger_condition='',
-                    expected_action='',
-                    status=row[3],
-                    success_count=row[4] or 0,
-                    failure_count=row[5] or 0,
-                    created_at=row[6]
-                ))
+                rules.append(
+                    TradingRule(
+                        id=row[0],
+                        rule_text=row[1],
+                        source_learning_id=0,  # Not stored in current schema
+                        source_pattern=row[2] or "",
+                        trigger_condition="",
+                        expected_action="",
+                        status=row[3],
+                        success_count=row[4] or 0,
+                        failure_count=row[5] or 0,
+                        created_at=row[6],
+                    )
+                )
 
             return rules
 
     def _get_rules_by_status(self, status: str) -> List[TradingRule]:
         """Get rules filtered by status.
@@ -784,32 +838,37 @@
         Returns:
             List of TradingRule objects.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT id, rule_text, rule_type, status,
                        success_count, failure_count, created_at
                 FROM trading_rules
                 WHERE status = ?
                 ORDER BY success_count DESC
-            """, (status,))
+            """,
+                (status,),
+            )
 
             rules = []
             for row in cursor.fetchall():
-                rules.append(TradingRule(
-                    id=row[0],
-                    rule_text=row[1],
-                    source_learning_id=0,
-                    source_pattern=row[2] or '',
-                    trigger_condition='',
-                    expected_action='',
-                    status=row[3],
-                    success_count=row[4] or 0,
-                    failure_count=row[5] or 0,
-                    created_at=row[6]
-                ))
+                rules.append(
+                    TradingRule(
+                        id=row[0],
+                        rule_text=row[1],
+                        source_learning_id=0,
+                        source_pattern=row[2] or "",
+                        trigger_condition="",
+                        expected_action="",
+                        status=row[3],
+                        success_count=row[4] or 0,
+                        failure_count=row[5] or 0,
+                        created_at=row[6],
+                    )
+                )
 
             return rules
 
     def record_rule_outcome(self, rule_id: int, success: bool) -> None:
         """Record whether a trade using this rule succeeded or failed.
@@ -818,19 +877,22 @@
 
         Args:
             rule_id: The rule that was used.
             success: True if trade was profitable, False otherwise.
         """
-        column = 'success_count' if success else 'failure_count'
-
-        with self.db._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute(f"""
+        column = "success_count" if success else "failure_count"
+
+        with self.db._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                f"""
                 UPDATE trading_rules
                 SET {column} = {column} + 1
                 WHERE id = ?
-            """, (rule_id,))
+            """,
+                (rule_id,),
+            )
             conn.commit()
 
         outcome = "SUCCESS" if success else "FAILURE"
         logger.info(f"Rule #{rule_id} outcome recorded: {outcome}")
 
@@ -848,53 +910,61 @@
         Returns:
             New status if changed, None if unchanged.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT status, success_count, failure_count
                 FROM trading_rules
                 WHERE id = ?
-            """, (rule_id,))
+            """,
+                (rule_id,),
+            )
 
             row = cursor.fetchone()
             if row is None:
                 return None
 
             status, success, failure = row
             total = success + failure
 
             # Only evaluate rules in testing status with enough data
-            if status != 'testing' or total < RULE_TEST_TRADES:
+            if status != "testing" or total < RULE_TEST_TRADES:
                 return None
 
             success_rate = success / total
 
             # Determine new status
             if success_rate >= RULE_PROMOTE_THRESHOLD:
-                new_status = 'active'
+                new_status = "active"
             elif success_rate < RULE_REJECT_THRESHOLD:
-                new_status = 'rejected'
+                new_status = "rejected"
             else:
                 return None  # Continue testing
 
             # Update status
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE trading_rules
                 SET status = ?
                 WHERE id = ?
-            """, (new_status, rule_id))
+            """,
+                (new_status, rule_id),
+            )
             conn.commit()
 
             # Log the promotion/rejection
             self.db.log_activity(
                 f"rule_{new_status}",
                 f"Rule #{rule_id} {new_status.upper()} (success rate: {success_rate:.0%})",
-                f"wins={success}, losses={failure}"
-            )
-
-            logger.info(f"Rule #{rule_id} status changed to {new_status} ({success_rate:.0%})")
+                f"wins={success}, losses={failure}",
+            )
+
+            logger.info(
+                f"Rule #{rule_id} status changed to {new_status} ({success_rate:.0%})"
+            )
             return new_status
 
     def evaluate_all_rules(self) -> List[Dict[str, Any]]:
         """Evaluate all testing rules.
 
@@ -905,16 +975,18 @@
         changes = []
 
         for rule in testing_rules:
             new_status = self.evaluate_rule(rule.id)
             if new_status:
-                changes.append({
-                    'rule_id': rule.id,
-                    'old_status': 'testing',
-                    'new_status': new_status,
-                    'success_rate': rule.success_rate()
-                })
+                changes.append(
+                    {
+                        "rule_id": rule.id,
+                        "old_status": "testing",
+                        "new_status": new_status,
+                        "success_rate": rule.success_rate(),
+                    }
+                )
 
         return changes
 
     def get_rule_summary(self) -> Dict[str, Any]:
         """Get summary statistics about rules.
@@ -944,15 +1016,15 @@
                 WHERE status = 'active'
             """)
             avg_success = cursor.fetchone()[0] or 0
 
             return {
-                'total_rules': total,
-                'active_rules': status_counts.get('active', 0),
-                'testing_rules': status_counts.get('testing', 0),
-                'rejected_rules': status_counts.get('rejected', 0),
-                'avg_active_success_rate': avg_success
+                "total_rules": total,
+                "active_rules": status_counts.get("active", 0),
+                "testing_rules": status_counts.get("testing", 0),
+                "rejected_rules": status_counts.get("rejected", 0),
+                "avg_active_success_rate": avg_success,
             }
 
 
 def get_rules_as_text(db: Database = None) -> List[str]:
     """Get active and testing rules formatted as text for LLM context.
would reformat /mnt/c/documents/crypto-trading-bot/src/learning_system.py
--- /mnt/c/documents/crypto-trading-bot/src/sentiment/btc_correlation.py	2026-02-04 15:19:07.179485+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/sentiment/btc_correlation.py	2026-02-04 21:34:25.177015+00:00
@@ -1,6 +1,7 @@
 """BTC Correlation Tracker for detecting market-wide vs coin-specific moves."""
+
 import logging
 from dataclasses import dataclass
 from datetime import datetime
 from typing import Optional, List
 import statistics
@@ -11,15 +12,16 @@
 
 
 @dataclass
 class BTCCorrelation:
     """BTC correlation data for a coin."""
+
     coin: str
-    btc_change_1h: float          # BTC % change in last hour
-    coin_change_1h: float         # Coin % change in last hour
-    correlation_24h: float        # Rolling 24h correlation coefficient (-1 to 1)
-    is_btc_driven: bool           # True if move appears BTC-correlated
+    btc_change_1h: float  # BTC % change in last hour
+    coin_change_1h: float  # Coin % change in last hour
+    correlation_24h: float  # Rolling 24h correlation coefficient (-1 to 1)
+    is_btc_driven: bool  # True if move appears BTC-correlated
     timestamp: datetime
 
     @property
     def move_type(self) -> str:
         """Classify the type of move."""
@@ -99,18 +101,15 @@
             coin=coin,
             btc_change_1h=btc_change_1h,
             coin_change_1h=coin_change_1h,
             correlation_24h=correlation_24h,
             is_btc_driven=is_btc_driven,
-            timestamp=datetime.now()
+            timestamp=datetime.now(),
         )
 
     def is_btc_driven_move(
-        self,
-        coin: str,
-        btc_threshold: float = 1.0,
-        correlation_threshold: float = 0.5
+        self, coin: str, btc_threshold: float = 1.0, correlation_threshold: float = 0.5
     ) -> tuple[bool, str]:
         """Check if a coin's current move is BTC-driven.
 
         Args:
             coin: Coin symbol
@@ -131,11 +130,14 @@
         # Check same direction
         same_direction = (corr.btc_change_1h > 0) == (corr.coin_change_1h > 0)
         if not same_direction:
             return False, "Opposite direction"
 
-        return True, f"BTC {corr.btc_change_1h:+.1f}%, correlation {corr.correlation_24h:.2f}"
+        return (
+            True,
+            f"BTC {corr.btc_change_1h:+.1f}%, correlation {corr.correlation_24h:.2f}",
+        )
 
     def get_all_correlations(self, coins: List[str]) -> dict[str, BTCCorrelation]:
         """Get correlations for multiple coins.
 
         Args:
@@ -165,13 +167,11 @@
             return 0.0
 
         return ((new_price - old_price) / old_price) * 100
 
     def _calculate_correlation(
-        self,
-        btc_closes: List[float],
-        coin_closes: List[float]
+        self, btc_closes: List[float], coin_closes: List[float]
     ) -> float:
         """Calculate Pearson correlation coefficient.
 
         Uses price returns (% changes) rather than absolute prices.
         """
@@ -225,14 +225,11 @@
             return 0.0
 
         return covariance / (std_x * std_y)
 
     def _is_btc_driven_move(
-        self,
-        btc_change: float,
-        coin_change: float,
-        correlation: float
+        self, btc_change: float, coin_change: float, correlation: float
     ) -> bool:
         """Determine if a move is BTC-driven.
 
         A move is BTC-driven if:
         1. BTC moved significantly (>1%)
would reformat /mnt/c/documents/crypto-trading-bot/src/sentiment/btc_correlation.py
--- /mnt/c/documents/crypto-trading-bot/src/metrics.py	2026-01-14 19:04:09.575297+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/metrics.py	2026-02-04 21:34:25.175957+00:00
@@ -12,26 +12,27 @@
 
 from src.database import Database
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 
 class AlertLevel(Enum):
     """Alert severity levels."""
+
     INFO = "info"
     WARNING = "warning"
     CRITICAL = "critical"
 
 
 @dataclass
 class Alert:
     """Represents a monitoring alert."""
+
     level: AlertLevel
     metric: str
     message: str
     value: Any
     threshold: Any
@@ -45,16 +46,16 @@
     activity monitoring, learning system health, and alerts.
     """
 
     # Alert thresholds
     THRESHOLDS = {
-        'min_balance': 950.0,           # Alert if balance drops below
-        'max_daily_loss': -20.0,        # Alert if daily P&L below
-        'max_trade_gap_hours': 6,       # Alert if no trades for X hours
-        'max_price_age_minutes': 5,     # Alert if prices stale
-        'max_api_errors_hourly': 10,    # Alert if too many API errors
-        'min_win_rate': 40.0,           # Warning if win rate below
+        "min_balance": 950.0,  # Alert if balance drops below
+        "max_daily_loss": -20.0,  # Alert if daily P&L below
+        "max_trade_gap_hours": 6,  # Alert if no trades for X hours
+        "max_price_age_minutes": 5,  # Alert if prices stale
+        "max_api_errors_hourly": 10,  # Alert if too many API errors
+        "min_win_rate": 40.0,  # Warning if win rate below
     }
 
     def __init__(self, db: Database = None):
         """Initialize with database connection.
 
@@ -101,21 +102,21 @@
 
             win_rate = (wins / total * 100) if total > 0 else 0
             profit_factor = (gross_profit / gross_loss) if gross_loss > 0 else 0
 
             return {
-                'total_trades': total,
-                'wins': wins,
-                'losses': losses,
-                'win_rate': round(win_rate, 1),
-                'total_pnl': round(total_pnl, 2),
-                'avg_pnl_per_trade': round(avg_pnl, 2),
-                'best_trade': round(best_trade, 2),
-                'worst_trade': round(worst_trade, 2),
-                'profit_factor': round(profit_factor, 2),
-                'gross_profit': round(gross_profit, 2),
-                'gross_loss': round(gross_loss, 2)
+                "total_trades": total,
+                "wins": wins,
+                "losses": losses,
+                "win_rate": round(win_rate, 1),
+                "total_pnl": round(total_pnl, 2),
+                "avg_pnl_per_trade": round(avg_pnl, 2),
+                "best_trade": round(best_trade, 2),
+                "worst_trade": round(worst_trade, 2),
+                "profit_factor": round(profit_factor, 2),
+                "gross_profit": round(gross_profit, 2),
+                "gross_loss": round(gross_loss, 2),
             }
 
     def get_activity_metrics(self) -> Dict[str, Any]:
         """Calculate activity and exposure metrics.
 
@@ -155,32 +156,36 @@
             """)
             last_price = cursor.fetchone()[0]
 
         # Get account state
         state = self.db.get_account_state()
-        balance = state.get('balance', 0)
-        in_positions = state.get('in_positions', 0)
+        balance = state.get("balance", 0)
+        in_positions = state.get("in_positions", 0)
         exposure_pct = (in_positions / balance * 100) if balance > 0 else 0
 
         # Calculate hours since last trade
         hours_since_trade = None
         if last_trade:
             try:
-                last_dt = datetime.fromisoformat(last_trade.replace('Z', '+00:00'))
-                hours_since_trade = (datetime.now() - last_dt.replace(tzinfo=None)).total_seconds() / 3600
+                last_dt = datetime.fromisoformat(last_trade.replace("Z", "+00:00"))
+                hours_since_trade = (
+                    datetime.now() - last_dt.replace(tzinfo=None)
+                ).total_seconds() / 3600
             except Exception:
                 pass
 
         return {
-            'trades_today': trades_today,
-            'trades_24h': trades_24h,
-            'trades_per_hour': round(trades_24h / 24, 2) if trades_24h else 0,
-            'open_positions': open_positions,
-            'exposure_pct': round(exposure_pct, 1),
-            'last_trade_time': last_trade,
-            'hours_since_trade': round(hours_since_trade, 1) if hours_since_trade else None,
-            'last_price_update': last_price
+            "trades_today": trades_today,
+            "trades_24h": trades_24h,
+            "trades_per_hour": round(trades_24h / 24, 2) if trades_24h else 0,
+            "open_positions": open_positions,
+            "exposure_pct": round(exposure_pct, 1),
+            "last_trade_time": last_trade,
+            "hours_since_trade": (
+                round(hours_since_trade, 1) if hours_since_trade else None
+            ),
+            "last_price_update": last_price,
         }
 
     def get_learning_metrics(self) -> Dict[str, Any]:
         """Calculate learning system metrics.
 
@@ -217,16 +222,16 @@
                 WHERE status = 'active'
             """)
             avg_success = cursor.fetchone()[0]
 
         return {
-            'total_learnings': total_learnings,
-            'learnings_today': learnings_today,
-            'active_rules': rules_by_status.get('active', 0),
-            'testing_rules': rules_by_status.get('testing', 0),
-            'rejected_rules': rules_by_status.get('rejected', 0),
-            'rule_success_rate': round((avg_success or 0) * 100, 1)
+            "total_learnings": total_learnings,
+            "learnings_today": learnings_today,
+            "active_rules": rules_by_status.get("active", 0),
+            "testing_rules": rules_by_status.get("testing", 0),
+            "rejected_rules": rules_by_status.get("rejected", 0),
+            "rule_success_rate": round((avg_success or 0) * 100, 1),
         }
 
     def get_system_health(self) -> Dict[str, Any]:
         """Check system health metrics.
 
@@ -253,15 +258,15 @@
             price_age_minutes = cursor.fetchone()[0] or 999
 
         state = self.db.get_account_state()
 
         return {
-            'balance': state.get('balance', 0),
-            'daily_pnl': state.get('daily_pnl', 0),
-            'api_errors_1h': api_errors_1h,
-            'price_age_minutes': round(price_age_minutes, 1),
-            'database_ok': True  # If we got here, DB is working
+            "balance": state.get("balance", 0),
+            "daily_pnl": state.get("daily_pnl", 0),
+            "api_errors_1h": api_errors_1h,
+            "price_age_minutes": round(price_age_minutes, 1),
+            "database_ok": True,  # If we got here, DB is working
         }
 
     def check_alerts(self) -> List[Alert]:
         """Check all metrics against thresholds and generate alerts.
 
@@ -273,98 +278,109 @@
         health = self.get_system_health()
         activity = self.get_activity_metrics()
         trading = self.get_trading_metrics()
 
         # Balance alert
-        if health['balance'] < self.THRESHOLDS['min_balance']:
-            self._alerts.append(Alert(
-                level=AlertLevel.CRITICAL,
-                metric='balance',
-                message=f"Balance ${health['balance']:.2f} below minimum ${self.THRESHOLDS['min_balance']}",
-                value=health['balance'],
-                threshold=self.THRESHOLDS['min_balance'],
-                timestamp=datetime.now()
-            ))
+        if health["balance"] < self.THRESHOLDS["min_balance"]:
+            self._alerts.append(
+                Alert(
+                    level=AlertLevel.CRITICAL,
+                    metric="balance",
+                    message=f"Balance ${health['balance']:.2f} below minimum ${self.THRESHOLDS['min_balance']}",
+                    value=health["balance"],
+                    threshold=self.THRESHOLDS["min_balance"],
+                    timestamp=datetime.now(),
+                )
+            )
 
         # Daily loss alert
-        if health['daily_pnl'] < self.THRESHOLDS['max_daily_loss']:
-            self._alerts.append(Alert(
-                level=AlertLevel.WARNING,
-                metric='daily_pnl',
-                message=f"Daily P&L ${health['daily_pnl']:.2f} exceeds max loss ${self.THRESHOLDS['max_daily_loss']}",
-                value=health['daily_pnl'],
-                threshold=self.THRESHOLDS['max_daily_loss'],
-                timestamp=datetime.now()
-            ))
+        if health["daily_pnl"] < self.THRESHOLDS["max_daily_loss"]:
+            self._alerts.append(
+                Alert(
+                    level=AlertLevel.WARNING,
+                    metric="daily_pnl",
+                    message=f"Daily P&L ${health['daily_pnl']:.2f} exceeds max loss ${self.THRESHOLDS['max_daily_loss']}",
+                    value=health["daily_pnl"],
+                    threshold=self.THRESHOLDS["max_daily_loss"],
+                    timestamp=datetime.now(),
+                )
+            )
 
         # Trade gap alert (only if we've had at least one trade)
-        hours = activity.get('hours_since_trade')
-        if hours and hours > self.THRESHOLDS['max_trade_gap_hours']:
-            self._alerts.append(Alert(
-                level=AlertLevel.WARNING,
-                metric='trade_gap',
-                message=f"No trades for {hours:.1f} hours (threshold: {self.THRESHOLDS['max_trade_gap_hours']}h)",
-                value=hours,
-                threshold=self.THRESHOLDS['max_trade_gap_hours'],
-                timestamp=datetime.now()
-            ))
+        hours = activity.get("hours_since_trade")
+        if hours and hours > self.THRESHOLDS["max_trade_gap_hours"]:
+            self._alerts.append(
+                Alert(
+                    level=AlertLevel.WARNING,
+                    metric="trade_gap",
+                    message=f"No trades for {hours:.1f} hours (threshold: {self.THRESHOLDS['max_trade_gap_hours']}h)",
+                    value=hours,
+                    threshold=self.THRESHOLDS["max_trade_gap_hours"],
+                    timestamp=datetime.now(),
+                )
+            )
 
         # Stale prices alert
-        if health['price_age_minutes'] > self.THRESHOLDS['max_price_age_minutes']:
-            self._alerts.append(Alert(
-                level=AlertLevel.CRITICAL,
-                metric='price_freshness',
-                message=f"Price data {health['price_age_minutes']:.1f} min old (threshold: {self.THRESHOLDS['max_price_age_minutes']} min)",
-                value=health['price_age_minutes'],
-                threshold=self.THRESHOLDS['max_price_age_minutes'],
-                timestamp=datetime.now()
-            ))
+        if health["price_age_minutes"] > self.THRESHOLDS["max_price_age_minutes"]:
+            self._alerts.append(
+                Alert(
+                    level=AlertLevel.CRITICAL,
+                    metric="price_freshness",
+                    message=f"Price data {health['price_age_minutes']:.1f} min old (threshold: {self.THRESHOLDS['max_price_age_minutes']} min)",
+                    value=health["price_age_minutes"],
+                    threshold=self.THRESHOLDS["max_price_age_minutes"],
+                    timestamp=datetime.now(),
+                )
+            )
 
         # API errors alert
-        if health['api_errors_1h'] > self.THRESHOLDS['max_api_errors_hourly']:
-            self._alerts.append(Alert(
-                level=AlertLevel.WARNING,
-                metric='api_errors',
-                message=f"{health['api_errors_1h']} API errors in last hour (threshold: {self.THRESHOLDS['max_api_errors_hourly']})",
-                value=health['api_errors_1h'],
-                threshold=self.THRESHOLDS['max_api_errors_hourly'],
-                timestamp=datetime.now()
-            ))
+        if health["api_errors_1h"] > self.THRESHOLDS["max_api_errors_hourly"]:
+            self._alerts.append(
+                Alert(
+                    level=AlertLevel.WARNING,
+                    metric="api_errors",
+                    message=f"{health['api_errors_1h']} API errors in last hour (threshold: {self.THRESHOLDS['max_api_errors_hourly']})",
+                    value=health["api_errors_1h"],
+                    threshold=self.THRESHOLDS["max_api_errors_hourly"],
+                    timestamp=datetime.now(),
+                )
+            )
 
         # Win rate warning (only if enough trades)
-        if trading['total_trades'] >= 10 and trading['win_rate'] < self.THRESHOLDS['min_win_rate']:
-            self._alerts.append(Alert(
-                level=AlertLevel.INFO,
-                metric='win_rate',
-                message=f"Win rate {trading['win_rate']:.1f}% below {self.THRESHOLDS['min_win_rate']}%",
-                value=trading['win_rate'],
-                threshold=self.THRESHOLDS['min_win_rate'],
-                timestamp=datetime.now()
-            ))
+        if (
+            trading["total_trades"] >= 10
+            and trading["win_rate"] < self.THRESHOLDS["min_win_rate"]
+        ):
+            self._alerts.append(
+                Alert(
+                    level=AlertLevel.INFO,
+                    metric="win_rate",
+                    message=f"Win rate {trading['win_rate']:.1f}% below {self.THRESHOLDS['min_win_rate']}%",
+                    value=trading["win_rate"],
+                    threshold=self.THRESHOLDS["min_win_rate"],
+                    timestamp=datetime.now(),
+                )
+            )
 
         return self._alerts
 
     def get_all_metrics(self) -> Dict[str, Any]:
         """Get all metrics in one call.
 
         Returns:
             Dict with trading, activity, learning, health metrics and alerts.
         """
         return {
-            'trading': self.get_trading_metrics(),
-            'activity': self.get_activity_metrics(),
-            'learning': self.get_learning_metrics(),
-            'health': self.get_system_health(),
-            'alerts': [
-                {
-                    'level': a.level.value,
-                    'metric': a.metric,
-                    'message': a.message
-                }
+            "trading": self.get_trading_metrics(),
+            "activity": self.get_activity_metrics(),
+            "learning": self.get_learning_metrics(),
+            "health": self.get_system_health(),
+            "alerts": [
+                {"level": a.level.value, "metric": a.metric, "message": a.message}
                 for a in self.check_alerts()
             ],
-            'timestamp': datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
 
     def format_prometheus(self) -> str:
         """Format metrics in Prometheus exposition format.
 
@@ -373,11 +389,11 @@
         """
         lines = []
         metrics = self.get_all_metrics()
 
         # Trading metrics
-        t = metrics['trading']
+        t = metrics["trading"]
         lines.append("# HELP cryptobot_trades_total Total number of closed trades")
         lines.append("# TYPE cryptobot_trades_total counter")
         lines.append(f"cryptobot_trades_total {t['total_trades']}")
 
         lines.append("# HELP cryptobot_win_rate Win rate percentage")
@@ -395,11 +411,11 @@
         lines.append("# HELP cryptobot_avg_pnl Average PnL per trade")
         lines.append("# TYPE cryptobot_avg_pnl gauge")
         lines.append(f"cryptobot_avg_pnl {t['avg_pnl_per_trade']}")
 
         # Activity metrics
-        a = metrics['activity']
+        a = metrics["activity"]
         lines.append("# HELP cryptobot_open_positions Number of open positions")
         lines.append("# TYPE cryptobot_open_positions gauge")
         lines.append(f"cryptobot_open_positions {a['open_positions']}")
 
         lines.append("# HELP cryptobot_exposure_pct Exposure percentage")
@@ -413,11 +429,11 @@
         lines.append("# HELP cryptobot_trades_per_hour Average trades per hour")
         lines.append("# TYPE cryptobot_trades_per_hour gauge")
         lines.append(f"cryptobot_trades_per_hour {a['trades_per_hour']}")
 
         # Health metrics
-        h = metrics['health']
+        h = metrics["health"]
         lines.append("# HELP cryptobot_balance Account balance in USD")
         lines.append("# TYPE cryptobot_balance gauge")
         lines.append(f"cryptobot_balance {h['balance']}")
 
         lines.append("# HELP cryptobot_daily_pnl Daily PnL in USD")
@@ -431,11 +447,11 @@
         lines.append("# HELP cryptobot_price_age_minutes Age of price data in minutes")
         lines.append("# TYPE cryptobot_price_age_minutes gauge")
         lines.append(f"cryptobot_price_age_minutes {h['price_age_minutes']}")
 
         # Learning metrics
-        l = metrics['learning']
+        l = metrics["learning"]
         lines.append("# HELP cryptobot_learnings_total Total learnings")
         lines.append("# TYPE cryptobot_learnings_total counter")
         lines.append(f"cryptobot_learnings_total {l['total_learnings']}")
 
         lines.append("# HELP cryptobot_active_rules Active trading rules")
@@ -458,14 +474,14 @@
 
         Returns:
             Formatted string with performance summary.
         """
         metrics = self.get_all_metrics()
-        t = metrics['trading']
-        a = metrics['activity']
-        l = metrics['learning']
-        h = metrics['health']
+        t = metrics["trading"]
+        a = metrics["activity"]
+        l = metrics["learning"]
+        h = metrics["health"]
 
         lines = [
             "=" * 50,
             "  CRYPTO TRADING BOT - PERFORMANCE SUMMARY",
             "=" * 50,
@@ -491,48 +507,52 @@
             "-" * 30,
             f"  Trades Today:   {a['trades_today']}",
             f"  Trades/Hour:    {a['trades_per_hour']:.2f}",
         ]
 
-        if a.get('hours_since_trade'):
+        if a.get("hours_since_trade"):
             lines.append(f"  Last Trade:     {a['hours_since_trade']:.1f}h ago")
         else:
             lines.append("  Last Trade:     No trades yet")
 
-        lines.extend([
-            "",
-            "LEARNING SYSTEM",
-            "-" * 30,
-            f"  Total Learnings: {l['total_learnings']}",
-            f"  Today:           {l['learnings_today']}",
-            f"  Active Rules:    {l['active_rules']}",
-            f"  Testing Rules:   {l['testing_rules']}",
-            "",
-        ])
+        lines.extend(
+            [
+                "",
+                "LEARNING SYSTEM",
+                "-" * 30,
+                f"  Total Learnings: {l['total_learnings']}",
+                f"  Today:           {l['learnings_today']}",
+                f"  Active Rules:    {l['active_rules']}",
+                f"  Testing Rules:   {l['testing_rules']}",
+                "",
+            ]
+        )
 
         # Add alerts section
-        alerts = metrics['alerts']
+        alerts = metrics["alerts"]
         lines.append("ALERTS")
         lines.append("-" * 30)
         if alerts:
             for alert in alerts:
-                if alert['level'] == 'critical':
+                if alert["level"] == "critical":
                     icon = "[!!!]"
-                elif alert['level'] == 'warning':
+                elif alert["level"] == "warning":
                     icon = "[!]"
                 else:
                     icon = "[i]"
                 lines.append(f"  {icon} {alert['message']}")
         else:
             lines.append("  No active alerts")
 
-        lines.extend([
-            "",
-            "=" * 50,
-            f"  Generated: {metrics['timestamp']}",
-            "=" * 50,
-        ])
+        lines.extend(
+            [
+                "",
+                "=" * 50,
+                f"  Generated: {metrics['timestamp']}",
+                "=" * 50,
+            ]
+        )
 
         return "\n".join(lines)
 
 
 # Convenience function for command-line use
would reformat /mnt/c/documents/crypto-trading-bot/src/metrics.py
--- /mnt/c/documents/crypto-trading-bot/src/market_data.py	2026-01-14 18:44:57.962458+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/market_data.py	2026-02-04 21:34:25.181880+00:00
@@ -16,18 +16,17 @@
 from src.coin_config import get_coin_ids, get_tier, get_tier_config
 from src.volatility import VolatilityCalculator
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 
 # Default configuration
-DEFAULT_COINS = ['bitcoin', 'ethereum', 'ripple']
+DEFAULT_COINS = ["bitcoin", "ethereum", "ripple"]
 DEFAULT_UPDATE_INTERVAL = 30  # seconds
 API_TIMEOUT = 10  # seconds
 
 
 def format_price(price: float) -> str:
@@ -84,11 +83,11 @@
 
     def __init__(
         self,
         coins: Optional[List[str]] = None,
         update_interval: int = DEFAULT_UPDATE_INTERVAL,
-        db: Optional[Database] = None
+        db: Optional[Database] = None,
     ):
         """Initialize the market data fetcher.
 
         Args:
             coins: List of coin IDs to fetch (default: bitcoin, ethereum, ripple).
@@ -100,11 +99,13 @@
         self.update_interval = update_interval
         self.db = db or Database()
 
         logger.info(f"MarketDataFetcher initialized for coins: {self.coins}")
 
-    def fetch_prices(self, coins: Optional[List[str]] = None) -> Dict[str, Dict[str, float]]:
+    def fetch_prices(
+        self, coins: Optional[List[str]] = None
+    ) -> Dict[str, Dict[str, float]]:
         """Fetch current prices from CoinGecko API.
 
         This fetches REAL prices from the CoinGecko API. The response can be
         verified by running the equivalent curl command.
 
@@ -132,11 +133,11 @@
         coin_ids = ",".join(coins_to_fetch)
         url = f"{self.base_url}/simple/price"
         params = {
             "ids": coin_ids,
             "vs_currencies": "usd",
-            "include_24hr_change": "true"
+            "include_24hr_change": "true",
         }
 
         # Log the request for transparency
         full_url = f"{url}?ids={coin_ids}&vs_currencies=usd&include_24hr_change=true"
         logger.info(f"Fetching prices from: {full_url}")
@@ -152,53 +153,55 @@
             for coin, price_data in data.items():
                 logger.debug(f"  {coin}: ${price_data.get('usd', 'N/A')}")
 
             # Log to activity log
             self.db.log_activity(
-                activity_type='market_data',
-                description=f'Fetched prices for {len(data)} coins',
-                details=str(data)
+                activity_type="market_data",
+                description=f"Fetched prices for {len(data)} coins",
+                details=str(data),
             )
 
             return data
 
         except Timeout:
             logger.error(f"Timeout fetching prices from CoinGecko (>{API_TIMEOUT}s)")
             self.db.log_activity(
-                activity_type='error',
-                description='CoinGecko API timeout',
-                details=f'Timeout after {API_TIMEOUT} seconds'
+                activity_type="error",
+                description="CoinGecko API timeout",
+                details=f"Timeout after {API_TIMEOUT} seconds",
             )
             raise
 
         except HTTPError as e:
             if e.response.status_code == 429:
                 logger.warning("Rate limited by CoinGecko API")
                 self.db.log_activity(
-                    activity_type='warning',
-                    description='CoinGecko rate limit hit',
-                    details=str(e)
+                    activity_type="warning",
+                    description="CoinGecko rate limit hit",
+                    details=str(e),
                 )
             else:
                 logger.error(f"HTTP error from CoinGecko: {e}")
                 self.db.log_activity(
-                    activity_type='error',
-                    description=f'CoinGecko HTTP error: {e.response.status_code}',
-                    details=str(e)
+                    activity_type="error",
+                    description=f"CoinGecko HTTP error: {e.response.status_code}",
+                    details=str(e),
                 )
             raise
 
         except RequestException as e:
             logger.error(f"Error fetching prices: {e}")
             self.db.log_activity(
-                activity_type='error',
-                description='Failed to fetch market data',
-                details=str(e)
+                activity_type="error",
+                description="Failed to fetch market data",
+                details=str(e),
             )
             raise
 
-    def update_database(self, price_data: Optional[Dict[str, Dict[str, float]]] = None) -> int:
+    def update_database(
+        self, price_data: Optional[Dict[str, Dict[str, float]]] = None
+    ) -> int:
         """Store fetched prices in database.
 
         Args:
             price_data: Price data from fetch_prices(). If None, fetches fresh data.
 
@@ -216,26 +219,31 @@
 
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
 
             for coin, data in price_data.items():
-                price_usd = data.get('usd')
-                change_24h = data.get('usd_24h_change')
+                price_usd = data.get("usd")
+                change_24h = data.get("usd_24h_change")
 
                 if price_usd is None:
                     logger.warning(f"No USD price for {coin}, skipping")
                     continue
 
                 # Insert or replace (upsert)
-                cursor.execute("""
+                cursor.execute(
+                    """
                     INSERT OR REPLACE INTO market_data
                     (coin, price_usd, change_24h, last_updated)
                     VALUES (?, ?, ?, CURRENT_TIMESTAMP)
-                """, (coin, price_usd, change_24h))
+                """,
+                    (coin, price_usd, change_24h),
+                )
 
                 updated_count += 1
-                logger.debug(f"Updated {coin}: {format_price(price_usd)} ({change_24h:+.2f}%)")
+                logger.debug(
+                    f"Updated {coin}: {format_price(price_usd)} ({change_24h:+.2f}%)"
+                )
 
             conn.commit()
 
         logger.info(f"Updated {updated_count} coins in database")
         return updated_count
@@ -247,18 +255,20 @@
             Dictionary mapping coin IDs to price data from database.
             Example: {'bitcoin': {'price_usd': 94235.50, 'change_24h': 2.35, 'last_updated': '...'}}
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("SELECT coin, price_usd, change_24h, last_updated FROM market_data")
+            cursor.execute(
+                "SELECT coin, price_usd, change_24h, last_updated FROM market_data"
+            )
 
             prices = {}
             for row in cursor.fetchall():
                 prices[row[0]] = {
-                    'price_usd': row[1],
-                    'change_24h': row[2],
-                    'last_updated': row[3]
+                    "price_usd": row[1],
+                    "change_24h": row[2],
+                    "last_updated": row[3],
                 }
 
             return prices
 
     def get_price(self, coin: str) -> Optional[float]:
@@ -270,14 +280,11 @@
         Returns:
             Current USD price, or None if not found.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute(
-                "SELECT price_usd FROM market_data WHERE coin = ?",
-                (coin,)
-            )
+            cursor.execute("SELECT price_usd FROM market_data WHERE coin = ?", (coin,))
             row = cursor.fetchone()
             return row[0] if row else None
 
     def fetch_and_store(self) -> Dict[str, Dict[str, float]]:
         """Fetch prices from API and store in database.
@@ -360,11 +367,11 @@
             "ids": ids_param,
             "order": "market_cap_desc",
             "per_page": 100,  # Max allowed
             "page": 1,
             "sparkline": "false",
-            "price_change_percentage": "24h"
+            "price_change_percentage": "24h",
         }
 
         logger.info(f"Batch fetching {len(coin_ids)} coins with volume data...")
 
         try:
@@ -379,20 +386,20 @@
                     result[coin_id] = {
                         "price_usd": coin_data.get("current_price", 0),
                         "change_24h": coin_data.get("price_change_percentage_24h", 0),
                         "volume_24h": coin_data.get("total_volume", 0),
                         "market_cap": coin_data.get("market_cap", 0),
-                        "tier": get_tier(coin_id)
+                        "tier": get_tier(coin_id),
                     }
 
             logger.info(f"Fetched {len(result)} coins with volume data")
 
             # Log to activity
             self.db.log_activity(
-                activity_type='market_data',
-                description=f'Batch fetched {len(result)} coins with volume',
-                details=f'coins={len(result)}'
+                activity_type="market_data",
+                description=f"Batch fetched {len(result)} coins with volume",
+                details=f"coins={len(result)}",
             )
 
             return result
 
         except Timeout:
@@ -417,11 +424,11 @@
             result[coin_id] = {
                 "price_usd": data.get("usd", 0),
                 "change_24h": data.get("usd_24h_change", 0),
                 "volume_24h": 0,  # Not available in simple endpoint
                 "market_cap": 0,
-                "tier": get_tier(coin_id)
+                "tier": get_tier(coin_id),
             }
         return result
 
     def update_all_prices(self) -> Dict[str, Any]:
         """Update all coin prices in database with volume filtering.
@@ -451,15 +458,18 @@
                         f"${tier_config.min_volume_24h:,.0f} required"
                     )
                     continue
 
                 # Store in database
-                cursor.execute("""
+                cursor.execute(
+                    """
                     INSERT OR REPLACE INTO market_data
                     (coin, price_usd, change_24h, last_updated)
                     VALUES (?, ?, ?, datetime('now'))
-                """, (coin_id, data["price_usd"], data["change_24h"]))
+                """,
+                    (coin_id, data["price_usd"], data["change_24h"]),
+                )
 
                 stats["updated"] += 1
 
             conn.commit()
 
@@ -511,11 +521,11 @@
         coins: List of coins to include (default: bitcoin).
 
     Returns:
         Full URL that can be used with curl for verification.
     """
-    coins = coins or ['bitcoin']
+    coins = coins or ["bitcoin"]
     coin_ids = ",".join(coins)
     return f"https://api.coingecko.com/api/v3/simple/price?ids={coin_ids}&vs_currencies=usd&include_24hr_change=true"
 
 
 # Allow running directly for testing
@@ -537,19 +547,21 @@
         prices = fetcher.fetch_and_store()
 
         print("\nPrices fetched and stored:")
         print("-" * 40)
         for coin, data in prices.items():
-            price = data.get('usd', 0)
-            change = data.get('usd_24h_change', 0)
+            price = data.get("usd", 0)
+            change = data.get("usd_24h_change", 0)
             print(f"  {coin.upper():10} {format_price(price):>14}  ({change:+.2f}%)")
 
         print("-" * 40)
         print("\nDatabase contents (full precision):")
         db_prices = fetcher.get_current_prices()
         for coin, data in db_prices.items():
-            print(f"  {coin}: {format_price(data['price_usd'])} (updated: {data['last_updated']})")
+            print(
+                f"  {coin}: {format_price(data['price_usd'])} (updated: {data['last_updated']})"
+            )
 
         print("\n Prices are REAL and can be verified at:")
         print("   https://www.coingecko.com/")
 
     except Exception as e:
would reformat /mnt/c/documents/crypto-trading-bot/src/market_data.py
--- /mnt/c/documents/crypto-trading-bot/src/sentiment/social_sentiment.py	2026-02-04 15:30:45.137089+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/sentiment/social_sentiment.py	2026-02-04 21:34:25.198521+00:00
@@ -1,6 +1,7 @@
 """Social sentiment tracking via LunarCrush."""
+
 import logging
 import time
 from dataclasses import dataclass, field
 from datetime import datetime, timezone
 from typing import Optional, Dict, Any, List
@@ -11,16 +12,17 @@
 
 
 @dataclass
 class SocialMetrics:
     """Social media metrics for a coin."""
+
     coin: str
-    social_volume: int              # Total social mentions
-    social_score: float             # LunarCrush social score (0-100)
-    sentiment: float                # Sentiment score (0-100)
-    galaxy_score: float             # Overall LunarCrush score
-    alt_rank: int                   # Rank among altcoins (1 = best)
+    social_volume: int  # Total social mentions
+    social_score: float  # LunarCrush social score (0-100)
+    sentiment: float  # Sentiment score (0-100)
+    galaxy_score: float  # Overall LunarCrush score
+    alt_rank: int  # Rank among altcoins (1 = best)
     timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
 
     # Historical comparison
     avg_social_volume: Optional[float] = None
 
@@ -113,13 +115,11 @@
 
         try:
             params = {"key": self.api_key} if self.api_key else {}
 
             response = requests.get(
-                f"{self.BASE_URL}/{coin_upper}",
-                params=params,
-                timeout=10
+                f"{self.BASE_URL}/{coin_upper}", params=params, timeout=10
             )
             response.raise_for_status()
 
             data = response.json()
             metrics = self._parse_response(coin_upper, data)
@@ -205,11 +205,11 @@
             social_score=social_score,
             sentiment=sentiment,
             galaxy_score=galaxy_score,
             alt_rank=alt_rank,
             avg_social_volume=avg_volume,
-            timestamp=datetime.now(timezone.utc)
+            timestamp=datetime.now(timezone.utc),
         )
 
     def _empty_metrics(self, coin: str) -> SocialMetrics:
         """Return empty metrics when API fails."""
         return SocialMetrics(
@@ -217,11 +217,11 @@
             social_volume=0,
             social_score=50,
             sentiment=50,
             galaxy_score=50,
             alt_rank=100,
-            timestamp=datetime.now(timezone.utc)
+            timestamp=datetime.now(timezone.utc),
         )
 
     def _update_historical_volume(self, coin: str, volume: int) -> None:
         """Update historical volume tracking."""
         if coin not in self._historical_volumes:
--- /mnt/c/documents/crypto-trading-bot/src/sentiment/news_feed.py	2026-02-04 15:30:23.547383+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/sentiment/news_feed.py	2026-02-04 21:34:25.191614+00:00
@@ -1,6 +1,7 @@
 """News feed integration for market-moving news detection."""
+
 import logging
 import time
 from dataclasses import dataclass, field
 from datetime import datetime, timezone
 from typing import List, Optional, Dict, Any
@@ -11,15 +12,16 @@
 
 
 @dataclass
 class NewsItem:
     """A single news item."""
+
     title: str
     coins: List[str]
     published_at: datetime
-    sentiment_score: float          # -1 to +1
-    is_breaking: bool               # Published < 1 hour ago
+    sentiment_score: float  # -1 to +1
+    is_breaking: bool  # Published < 1 hour ago
     source: str
     url: Optional[str] = None
 
     @property
     def is_bullish(self) -> bool:
@@ -47,10 +49,11 @@
 
 
 @dataclass
 class NewsFeed:
     """Collection of news items for analysis."""
+
     items: List[NewsItem] = field(default_factory=list)
     timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
 
     @property
     def breaking_news(self) -> List[NewsItem]:
@@ -107,13 +110,11 @@
         self._cache: Optional[NewsFeed] = None
         self._cache_time: float = 0
         self._last_request_time: float = 0
 
     def get_news(
-        self,
-        filter_type: str = "hot",
-        currencies: Optional[List[str]] = None
+        self, filter_type: str = "hot", currencies: Optional[List[str]] = None
     ) -> NewsFeed:
         """Get news feed from CryptoPanic.
 
         Args:
             filter_type: Filter type (hot, rising, bullish, bearish, important)
@@ -129,15 +130,11 @@
         # Rate limiting
         self._wait_for_rate_limit()
 
         try:
             params = self._build_params(filter_type, currencies)
-            response = requests.get(
-                self.BASE_URL,
-                params=params,
-                timeout=10
-            )
+            response = requests.get(self.BASE_URL, params=params, timeout=10)
             response.raise_for_status()
 
             data = response.json()
             feed = self._parse_response(data)
 
@@ -173,15 +170,11 @@
             List of breaking NewsItem
         """
         feed = self.get_news(filter_type="important")
         return feed.breaking_news
 
-    def calculate_sentiment(
-        self,
-        positive_votes: int,
-        negative_votes: int
-    ) -> float:
+    def calculate_sentiment(self, positive_votes: int, negative_votes: int) -> float:
         """Calculate sentiment score from votes.
 
         Args:
             positive_votes: Number of positive votes
             negative_votes: Number of negative votes
@@ -193,19 +186,14 @@
         if total == 0:
             return 0.0
         return (positive_votes - negative_votes) / total
 
     def _build_params(
-        self,
-        filter_type: str,
-        currencies: Optional[List[str]]
+        self, filter_type: str, currencies: Optional[List[str]]
     ) -> Dict[str, str]:
         """Build API request parameters."""
-        params: Dict[str, str] = {
-            "filter": filter_type,
-            "public": "true"
-        }
+        params: Dict[str, str] = {"filter": filter_type, "public": "true"}
 
         if self.api_token:
             params["auth_token"] = self.api_token
 
         if currencies:
@@ -244,19 +232,21 @@
                 sentiment_score = self.calculate_sentiment(positive, negative)
 
                 # Get source
                 source = post.get("source", {}).get("title", "Unknown")
 
-                items.append(NewsItem(
-                    title=post.get("title", ""),
-                    coins=coins,
-                    published_at=published_at,
-                    sentiment_score=sentiment_score,
-                    is_breaking=is_breaking,
-                    source=source,
-                    url=post.get("url")
-                ))
+                items.append(
+                    NewsItem(
+                        title=post.get("title", ""),
+                        coins=coins,
+                        published_at=published_at,
+                        sentiment_score=sentiment_score,
+                        is_breaking=is_breaking,
+                        source=source,
+                        url=post.get("url"),
+                    )
+                )
 
             except Exception as e:
                 logger.debug(f"Failed to parse news item: {e}")
                 continue
 
would reformat /mnt/c/documents/crypto-trading-bot/src/sentiment/social_sentiment.py
would reformat /mnt/c/documents/crypto-trading-bot/src/sentiment/news_feed.py
--- /mnt/c/documents/crypto-trading-bot/src/technical/atr.py	2026-02-04 01:23:32.032104+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/atr.py	2026-02-04 21:34:25.206167+00:00
@@ -1,6 +1,7 @@
 """ATR (Average True Range) calculator for volatility measurement."""
+
 import logging
 from dataclasses import dataclass
 from datetime import datetime
 from typing import List, Optional, Tuple
 
@@ -10,13 +11,14 @@
 
 
 @dataclass
 class ATRData:
     """ATR calculation result."""
+
     coin: str
-    atr: float                # Absolute ATR value
-    atr_pct: float            # ATR as percentage of price
+    atr: float  # Absolute ATR value
+    atr_pct: float  # ATR as percentage of price
     period: int
     current_price: float
     timeframe: str
     timestamp: datetime
 
@@ -40,11 +42,13 @@
         Returns:
             Stop-loss distance in price units
         """
         return self.atr * multiplier
 
-    def suggested_stop_price(self, entry_price: float, direction: str, multiplier: float = 1.5) -> float:
+    def suggested_stop_price(
+        self, entry_price: float, direction: str, multiplier: float = 1.5
+    ) -> float:
         """Get suggested stop-loss price.
 
         Args:
             entry_price: Trade entry price
             direction: "LONG" or "SHORT"
@@ -82,14 +86,11 @@
         """
         self.candle_fetcher = candle_fetcher
         self.default_period = default_period
 
     def calculate(
-        self,
-        coin: str,
-        timeframe: str = "1h",
-        period: Optional[int] = None
+        self, coin: str, timeframe: str = "1h", period: Optional[int] = None
     ) -> ATRData:
         """Calculate ATR for a coin.
 
         Args:
             coin: Coin symbol (e.g., "BTC", "ETH")
@@ -100,25 +101,29 @@
             ATRData with calculated ATR value
         """
         period = period or self.default_period
 
         # Need period + 1 candles for true range calculation
-        candle_data = self.candle_fetcher.get_candles(coin, timeframe, limit=period + 50)
+        candle_data = self.candle_fetcher.get_candles(
+            coin, timeframe, limit=period + 50
+        )
         candles = candle_data.candles
 
         if len(candles) < period + 1:
-            logger.warning(f"Insufficient data for ATR: {len(candles)} candles, need {period + 1}")
+            logger.warning(
+                f"Insufficient data for ATR: {len(candles)} candles, need {period + 1}"
+            )
             # Return a default based on current price
             current_price = candles[-1].close if candles else 0
             return ATRData(
                 coin=coin,
                 atr=current_price * 0.02,  # 2% default
                 atr_pct=2.0,
                 period=period,
                 current_price=current_price,
                 timeframe=timeframe,
-                timestamp=datetime.now()
+                timestamp=datetime.now(),
             )
 
         atr_value = self._calculate_atr(candles, period)
         current_price = candles[-1].close
         atr_pct = (atr_value / current_price * 100) if current_price > 0 else 0
@@ -128,11 +133,11 @@
             atr=atr_value,
             atr_pct=atr_pct,
             period=period,
             current_price=current_price,
             timeframe=timeframe,
-            timestamp=datetime.now()
+            timestamp=datetime.now(),
         )
 
     def calculate_from_candles(self, candles: List[Candle], period: int = 14) -> float:
         """Calculate ATR from a list of candles.
 
@@ -183,14 +188,16 @@
         TR = max(H-L, |H-PC|, |L-PC|)
         """
         return max(
             candle.high - candle.low,
             abs(candle.high - prev_close),
-            abs(candle.low - prev_close)
+            abs(candle.low - prev_close),
         )
 
-    def get_position_size_modifier(self, coin: str, target_risk_pct: float = 2.0) -> float:
+    def get_position_size_modifier(
+        self, coin: str, target_risk_pct: float = 2.0
+    ) -> float:
         """Get position size modifier based on volatility.
 
         Higher volatility = smaller position to maintain consistent risk.
 
         Args:
@@ -216,11 +223,11 @@
         self,
         coin: str,
         direction: str,
         entry_price: float,
         sl_multiplier: float = 1.5,
-        tp_multiplier: float = 2.0
+        tp_multiplier: float = 2.0,
     ) -> Tuple[float, float]:
         """Calculate dynamic stop-loss and take-profit based on ATR.
 
         Args:
             coin: Coin symbol
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/atr.py
--- /mnt/c/documents/crypto-trading-bot/src/quick_update.py	2026-02-03 17:42:17.522294+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/quick_update.py	2026-02-04 21:34:25.210085+00:00
@@ -135,11 +135,15 @@
         result.processing_time_ms = elapsed_ms
 
         self.updates_processed += 1
 
         # Log summary
-        log_level = logging.INFO if coin_adaptation or result.pattern_deactivated else logging.DEBUG
+        log_level = (
+            logging.INFO
+            if coin_adaptation or result.pattern_deactivated
+            else logging.DEBUG
+        )
         logger.log(log_level, f"Quick update: {result}")
 
         # 4. Notify reflection engine (TASK-131)
         if self.reflection_engine:
             self.reflection_engine.on_trade_close()
@@ -195,11 +199,13 @@
                 "deactivated": not pattern.is_active,
             }
 
         return None
 
-    def _log_quick_update(self, trade_result: TradeResult, result: QuickUpdateResult) -> None:
+    def _log_quick_update(
+        self, trade_result: TradeResult, result: QuickUpdateResult
+    ) -> None:
         """Log the quick update for audit trail.
 
         Args:
             trade_result: The original trade.
             result: The update result.
@@ -248,11 +254,11 @@
     import tempfile
     import os
 
     logging.basicConfig(
         level=logging.INFO,
-        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
     )
 
     print("=" * 60)
     print("QuickUpdate Test")
     print("=" * 60)
@@ -274,38 +280,42 @@
 
         quick = QuickUpdate(scorer, patterns, db)
 
         # Test 1: Winning trade
         print("\n[TEST 1] Processing winning trade...")
-        result = quick.process_trade_close(TradeResult(
-            trade_id="test-001",
-            coin="SOL",
-            direction="LONG",
-            entry_price=100.0,
-            exit_price=102.0,
-            position_size_usd=50.0,
-            pnl_usd=1.0,
-            won=True,
-            exit_reason="take_profit",
-        ))
+        result = quick.process_trade_close(
+            TradeResult(
+                trade_id="test-001",
+                coin="SOL",
+                direction="LONG",
+                entry_price=100.0,
+                exit_price=102.0,
+                position_size_usd=50.0,
+                pnl_usd=1.0,
+                won=True,
+                exit_reason="take_profit",
+            )
+        )
         print(f"  Result: {result}")
         print(f"  Processing time: {result.processing_time_ms:.2f}ms")
 
         # Test 2: Multiple losing trades to trigger blacklist
         print("\n[TEST 2] Processing losing trades (triggering blacklist)...")
         for i in range(6):
-            result = quick.process_trade_close(TradeResult(
-                trade_id=f"test-loss-{i}",
-                coin="SHIB",
-                direction="LONG",
-                entry_price=0.00001,
-                exit_price=0.000009,
-                position_size_usd=50.0,
-                pnl_usd=-5.0,
-                won=False,
-                exit_reason="stop_loss",
-            ))
+            result = quick.process_trade_close(
+                TradeResult(
+                    trade_id=f"test-loss-{i}",
+                    coin="SHIB",
+                    direction="LONG",
+                    entry_price=0.00001,
+                    exit_price=0.000009,
+                    position_size_usd=50.0,
+                    pnl_usd=-5.0,
+                    won=False,
+                    exit_reason="stop_loss",
+                )
+            )
             if result.coin_adaptation:
                 print(f"  Trade {i+1}: {result}")
                 break
             else:
                 print(f"  Trade {i+1}: SHIB status = {result.new_coin_status}")
@@ -322,41 +332,46 @@
             description="Test pattern for quick update",
             entry_conditions={"test": True},
             exit_conditions={"stop_loss_pct": 2.0},
         )
 
-        result = quick.process_trade_close(TradeResult(
-            trade_id="test-pattern-001",
-            coin="ETH",
-            direction="LONG",
-            entry_price=2500.0,
-            exit_price=2550.0,
-            position_size_usd=50.0,
-            pnl_usd=1.0,
-            won=True,
-            exit_reason="take_profit",
-            pattern_id=pattern.pattern_id,
-        ))
+        result = quick.process_trade_close(
+            TradeResult(
+                trade_id="test-pattern-001",
+                coin="ETH",
+                direction="LONG",
+                entry_price=2500.0,
+                exit_price=2550.0,
+                position_size_usd=50.0,
+                pnl_usd=1.0,
+                won=True,
+                exit_reason="take_profit",
+                pattern_id=pattern.pattern_id,
+            )
+        )
         print(f"  Result: {result}")
         print(f"  Pattern confidence: {result.new_pattern_confidence:.2f}")
 
         # Test 4: Performance test
         print("\n[TEST 4] Performance test (100 trades)...")
         import time
+
         start = time.perf_counter()
         for i in range(100):
-            quick.process_trade_close(TradeResult(
-                trade_id=f"perf-{i}",
-                coin="BTC",
-                direction="LONG",
-                entry_price=45000.0,
-                exit_price=45100.0,
-                position_size_usd=50.0,
-                pnl_usd=0.11,
-                won=True,
-                exit_reason="take_profit",
-            ))
+            quick.process_trade_close(
+                TradeResult(
+                    trade_id=f"perf-{i}",
+                    coin="BTC",
+                    direction="LONG",
+                    entry_price=45000.0,
+                    exit_price=45100.0,
+                    position_size_usd=50.0,
+                    pnl_usd=0.11,
+                    won=True,
+                    exit_reason="take_profit",
+                )
+            )
         elapsed = time.perf_counter() - start
         print(f"  100 updates in {elapsed*1000:.1f}ms ({elapsed*10:.2f}ms per update)")
 
         # Print stats
         print("\n" + "-" * 40)
would reformat /mnt/c/documents/crypto-trading-bot/src/quick_update.py
--- /mnt/c/documents/crypto-trading-bot/src/sentiment/context_manager.py	2026-02-04 15:42:10.449804+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/sentiment/context_manager.py	2026-02-04 21:34:25.223221+00:00
@@ -1,6 +1,7 @@
 """Context Manager - Aggregates all sentiment sources for Strategist."""
+
 import logging
 from dataclasses import dataclass, field
 from datetime import datetime, timezone
 from typing import List, Optional, Dict, Any
 
@@ -13,10 +14,11 @@
 
 
 @dataclass
 class MarketContext:
     """Overall market context from sentiment sources."""
+
     fear_greed: Optional[FearGreedData] = None
     btc_change_1h: float = 0.0
     btc_change_24h: float = 0.0
     breaking_news: List[NewsItem] = field(default_factory=list)
     timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
@@ -69,19 +71,22 @@
             lines.append(" EXTREME GREED - Market may be overbought")
 
         if self.breaking_news:
             lines.append(f"Breaking News: {len(self.breaking_news)} items")
             for news in self.breaking_news[:3]:  # Top 3
-                sentiment = "" if news.is_bullish else "" if news.is_bearish else ""
+                sentiment = (
+                    "" if news.is_bullish else "" if news.is_bearish else ""
+                )
                 lines.append(f"  {sentiment} {news.title[:50]}...")
 
         return "\n".join(lines)
 
 
 @dataclass
 class CoinContext:
     """Coin-specific context from sentiment sources."""
+
     coin: str
     btc_correlation: Optional[BTCCorrelation] = None
     recent_news: List[NewsItem] = field(default_factory=list)
     social_metrics: Optional[SocialMetrics] = None
     timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
@@ -92,11 +97,15 @@
         return self.btc_correlation.is_btc_driven if self.btc_correlation else False
 
     @property
     def correlation_strength(self) -> str:
         """BTC correlation strength."""
-        return self.btc_correlation.correlation_strength if self.btc_correlation else "unknown"
+        return (
+            self.btc_correlation.correlation_strength
+            if self.btc_correlation
+            else "unknown"
+        )
 
     @property
     def is_trending(self) -> bool:
         """Coin is trending on social media."""
         return self.social_metrics.is_trending if self.social_metrics else False
@@ -120,26 +129,32 @@
         """Format coin context for LLM prompt."""
         lines = [f"=== {self.coin} CONTEXT ==="]
 
         if self.btc_correlation:
             corr = self.btc_correlation
-            lines.append(f"BTC Correlation: {corr.correlation_24h:.2f} ({corr.correlation_strength})")
+            lines.append(
+                f"BTC Correlation: {corr.correlation_24h:.2f} ({corr.correlation_strength})"
+            )
             if corr.is_btc_driven:
                 lines.append(f"   Move is BTC-driven ({corr.move_type})")
 
         if self.social_metrics:
             sm = self.social_metrics
-            lines.append(f"Social: Rank #{sm.alt_rank}, Sentiment {sm.sentiment:.0f}/100 ({sm.sentiment_label})")
+            lines.append(
+                f"Social: Rank #{sm.alt_rank}, Sentiment {sm.sentiment:.0f}/100 ({sm.sentiment_label})"
+            )
             if sm.is_trending:
                 lines.append("   TRENDING")
             if sm.has_social_spike:
                 lines.append(f"   Social spike: {sm.volume_multiplier:.1f}x normal")
 
         if self.recent_news:
             lines.append(f"Recent News: {len(self.recent_news)} items")
             for news in self.recent_news[:2]:
-                sentiment = "" if news.is_bullish else "" if news.is_bearish else ""
+                sentiment = (
+                    "" if news.is_bullish else "" if news.is_bearish else ""
+                )
                 lines.append(f"  {sentiment} {news.title[:40]}...")
 
         return "\n".join(lines)
 
 
@@ -166,11 +181,11 @@
     def __init__(
         self,
         fear_greed_fetcher: Optional[FearGreedFetcher] = None,
         btc_tracker: Optional[BTCCorrelationTracker] = None,
         news_fetcher: Optional[NewsFeedFetcher] = None,
-        social_fetcher: Optional[SocialSentimentFetcher] = None
+        social_fetcher: Optional[SocialSentimentFetcher] = None,
     ):
         """Initialize with sentiment sources.
 
         Args:
             fear_greed_fetcher: FearGreedFetcher instance (created if None)
@@ -196,11 +211,11 @@
         return MarketContext(
             fear_greed=fear_greed,
             btc_change_1h=btc_changes[0],
             btc_change_24h=btc_changes[1],
             breaking_news=breaking_news,
-            timestamp=datetime.now(timezone.utc)
+            timestamp=datetime.now(timezone.utc),
         )
 
     def get_coin_context(self, coin: str) -> CoinContext:
         """Get context for a specific coin.
 
@@ -217,11 +232,11 @@
         return CoinContext(
             coin=coin.upper(),
             btc_correlation=btc_correlation,
             recent_news=recent_news,
             social_metrics=social_metrics,
-            timestamp=datetime.now(timezone.utc)
+            timestamp=datetime.now(timezone.utc),
         )
 
     def should_avoid_trading(self, coin: str) -> tuple[bool, str]:
         """Determine if trading should be avoided.
 
--- /mnt/c/documents/crypto-trading-bot/src/technical/rsi.py	2026-02-04 01:23:07.927329+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/rsi.py	2026-02-04 21:34:25.223047+00:00
@@ -1,6 +1,7 @@
 """RSI (Relative Strength Index) calculator for overbought/oversold detection."""
+
 import logging
 from dataclasses import dataclass
 from datetime import datetime
 from typing import List, Optional
 
@@ -10,12 +11,13 @@
 
 
 @dataclass
 class RSIData:
     """RSI calculation result."""
+
     coin: str
-    value: float              # 0-100
+    value: float  # 0-100
     period: int
     timeframe: str
     timestamp: datetime
 
     @property
@@ -62,14 +64,11 @@
         """
         self.candle_fetcher = candle_fetcher
         self.default_period = default_period
 
     def calculate(
-        self,
-        coin: str,
-        timeframe: str = "1h",
-        period: Optional[int] = None
+        self, coin: str, timeframe: str = "1h", period: Optional[int] = None
     ) -> RSIData:
         """Calculate RSI for a coin.
 
         Args:
             coin: Coin symbol (e.g., "BTC", "ETH")
@@ -80,31 +79,35 @@
             RSIData with calculated RSI value
         """
         period = period or self.default_period
 
         # Need period + 1 candles to calculate period price changes
-        candle_data = self.candle_fetcher.get_candles(coin, timeframe, limit=period + 50)
+        candle_data = self.candle_fetcher.get_candles(
+            coin, timeframe, limit=period + 50
+        )
         closes = candle_data.closes()
 
         if len(closes) < period + 1:
-            logger.warning(f"Insufficient data for RSI: {len(closes)} candles, need {period + 1}")
+            logger.warning(
+                f"Insufficient data for RSI: {len(closes)} candles, need {period + 1}"
+            )
             return RSIData(
                 coin=coin,
                 value=50.0,  # Neutral default
                 period=period,
                 timeframe=timeframe,
-                timestamp=datetime.now()
+                timestamp=datetime.now(),
             )
 
         rsi_value = self._calculate_rsi(closes, period)
 
         return RSIData(
             coin=coin,
             value=rsi_value,
             period=period,
             timeframe=timeframe,
-            timestamp=datetime.now()
+            timestamp=datetime.now(),
         )
 
     def calculate_from_closes(self, closes: List[float], period: int = 14) -> float:
         """Calculate RSI from a list of close prices.
 
@@ -158,13 +161,11 @@
         rsi = 100 - (100 / (1 + rs))
 
         return rsi
 
     def get_multi_timeframe(
-        self,
-        coin: str,
-        timeframes: List[str] = None
+        self, coin: str, timeframes: List[str] = None
     ) -> dict[str, RSIData]:
         """Get RSI across multiple timeframes.
 
         Args:
             coin: Coin symbol
would reformat /mnt/c/documents/crypto-trading-bot/src/sentiment/context_manager.py
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/rsi.py
--- /mnt/c/documents/crypto-trading-bot/src/technical/candle_fetcher.py	2026-02-04 01:06:06.981263+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/candle_fetcher.py	2026-02-04 21:34:25.233202+00:00
@@ -1,6 +1,7 @@
 """Candle data fetcher for technical indicator calculations."""
+
 import logging
 from dataclasses import dataclass, field
 from datetime import datetime, timedelta
 from typing import Optional, List, Dict
 import requests
@@ -9,10 +10,11 @@
 
 
 @dataclass
 class Candle:
     """Single OHLCV candle."""
+
     timestamp: int
     open: float
     high: float
     low: float
     close: float
@@ -40,10 +42,11 @@
 
 
 @dataclass
 class CandleData:
     """Collection of candles for a coin/interval."""
+
     coin: str
     interval: str
     candles: List[Candle] = field(default_factory=list)
     last_updated: datetime = field(default_factory=datetime.now)
 
@@ -129,14 +132,11 @@
         """
         self.cache_duration = timedelta(seconds=cache_seconds)
         self._cache: Dict[str, CandleData] = {}
 
     def get_candles(
-        self,
-        coin: str,
-        interval: str = "1h",
-        limit: int = 200
+        self, coin: str, interval: str = "1h", limit: int = 200
     ) -> CandleData:
         """Get candles for a coin.
 
         Args:
             coin: Coin symbol (e.g., "BTC", "ETH", "SOL")
@@ -158,18 +158,20 @@
         try:
             symbol = self._get_symbol(coin)
             bybit_interval = self.INTERVALS.get(interval)
 
             if not bybit_interval:
-                logger.error(f"Invalid interval: {interval}. Valid: {list(self.INTERVALS.keys())}")
+                logger.error(
+                    f"Invalid interval: {interval}. Valid: {list(self.INTERVALS.keys())}"
+                )
                 return self._get_cached_or_empty(coin, interval)
 
             params = {
                 "category": "linear",  # Perpetual futures for more liquidity
                 "symbol": symbol,
                 "interval": bybit_interval,
-                "limit": min(limit, 200)
+                "limit": min(limit, 200),
             }
 
             response = requests.get(self.API_URL, params=params, timeout=10)
             response.raise_for_status()
             data = response.json()
@@ -179,28 +181,30 @@
                 return self._get_cached_or_empty(coin, interval)
 
             candles = []
             for item in data.get("result", {}).get("list", []):
                 # Bybit returns: [timestamp, open, high, low, close, volume, turnover]
-                candles.append(Candle(
-                    timestamp=int(item[0]),
-                    open=float(item[1]),
-                    high=float(item[2]),
-                    low=float(item[3]),
-                    close=float(item[4]),
-                    volume=float(item[5]),
-                    turnover=float(item[6]) if len(item) > 6 else 0.0
-                ))
+                candles.append(
+                    Candle(
+                        timestamp=int(item[0]),
+                        open=float(item[1]),
+                        high=float(item[2]),
+                        low=float(item[3]),
+                        close=float(item[4]),
+                        volume=float(item[5]),
+                        turnover=float(item[6]) if len(item) > 6 else 0.0,
+                    )
+                )
 
             # Bybit returns newest first, reverse to chronological order
             candles.reverse()
 
             result = CandleData(
                 coin=coin,
                 interval=interval,
                 candles=candles,
-                last_updated=datetime.now()
+                last_updated=datetime.now(),
             )
 
             self._cache[cache_key] = result
             logger.debug(f"Fetched {len(candles)} {interval} candles for {coin}")
             return result
--- /mnt/c/documents/crypto-trading-bot/src/technical/vwap.py	2026-02-04 15:19:27.032969+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/vwap.py	2026-02-04 21:34:25.233800+00:00
@@ -1,6 +1,7 @@
 """VWAP (Volume-Weighted Average Price) calculator."""
+
 import logging
 from dataclasses import dataclass
 from datetime import datetime, timezone
 from typing import List, Optional
 
@@ -10,14 +11,15 @@
 
 
 @dataclass
 class VWAPData:
     """VWAP calculation result."""
+
     coin: str
-    vwap: float                   # Volume-weighted average price
-    current_price: float          # Current price
-    deviation_pct: float          # % above/below VWAP
+    vwap: float  # Volume-weighted average price
+    current_price: float  # Current price
+    deviation_pct: float  # % above/below VWAP
     timestamp: datetime
 
     @property
     def is_above_vwap(self) -> bool:
         """Price is above VWAP."""
@@ -43,11 +45,11 @@
     def mean_reversion_signal(self) -> Optional[str]:
         """Mean reversion signal based on deviation."""
         if self.deviation_pct > 3:
             return "SHORT"  # Extended above, likely to revert
         if self.deviation_pct < -3:
-            return "LONG"   # Extended below, likely to revert
+            return "LONG"  # Extended below, likely to revert
         return None
 
 
 class VWAPCalculator:
     """Calculates VWAP (Volume-Weighted Average Price).
@@ -69,14 +71,11 @@
             candle_fetcher: CandleFetcher instance for getting price data
         """
         self.candle_fetcher = candle_fetcher
 
     def calculate(
-        self,
-        coin: str,
-        timeframe: str = "1h",
-        use_daily_reset: bool = True
+        self, coin: str, timeframe: str = "1h", use_daily_reset: bool = True
     ) -> VWAPData:
         """Calculate VWAP for a coin.
 
         Args:
             coin: Coin symbol (e.g., "BTC", "ETH")
@@ -94,11 +93,11 @@
             return VWAPData(
                 coin=coin,
                 vwap=0.0,
                 current_price=0.0,
                 deviation_pct=0.0,
-                timestamp=datetime.now()
+                timestamp=datetime.now(),
             )
 
         # Filter to current day if using daily reset
         if use_daily_reset:
             candles = self._filter_to_today(candles)
@@ -119,11 +118,11 @@
         return VWAPData(
             coin=coin,
             vwap=vwap,
             current_price=current_price,
             deviation_pct=deviation_pct,
-            timestamp=datetime.now()
+            timestamp=datetime.now(),
         )
 
     def calculate_from_candles(self, candles: List[Candle]) -> float:
         """Calculate VWAP from a list of candles.
 
@@ -136,13 +135,11 @@
             VWAP value
         """
         return self._calculate_vwap(candles)
 
     def get_bands(
-        self,
-        coin: str,
-        std_multiplier: float = 2.0
+        self, coin: str, std_multiplier: float = 2.0
     ) -> tuple[float, float, float]:
         """Calculate VWAP with standard deviation bands.
 
         Args:
             coin: Coin symbol
@@ -165,11 +162,11 @@
 
         if not squared_deviations:
             return vwap, vwap, vwap
 
         variance = sum(squared_deviations) / len(squared_deviations)
-        std_dev = variance ** 0.5
+        std_dev = variance**0.5
 
         upper_band = vwap + (std_dev * std_multiplier)
         lower_band = vwap - (std_dev * std_multiplier)
 
         return vwap, upper_band, lower_band
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/candle_fetcher.py
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/vwap.py
--- /mnt/c/documents/crypto-trading-bot/src/technical/support_resistance.py	2026-02-04 15:19:53.880259+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/support_resistance.py	2026-02-04 21:34:25.239709+00:00
@@ -1,6 +1,7 @@
 """Support and Resistance level detection."""
+
 import logging
 from dataclasses import dataclass, field
 from datetime import datetime
 from typing import List, Optional
 from collections import defaultdict
@@ -11,25 +12,27 @@
 
 
 @dataclass
 class PriceLevel:
     """A support or resistance price level."""
+
     price: float
-    level_type: str               # "support" or "resistance"
-    strength: int                 # Number of touches
+    level_type: str  # "support" or "resistance"
+    strength: int  # Number of touches
     last_touch: datetime
-    zone_low: float               # Level is actually a zone
+    zone_low: float  # Level is actually a zone
     zone_high: float
 
     def price_in_zone(self, price: float) -> bool:
         """Check if a price is within this level's zone."""
         return self.zone_low <= price <= self.zone_high
 
 
 @dataclass
 class SRLevels:
     """Support and resistance levels for a coin."""
+
     coin: str
     support_levels: List[PriceLevel] = field(default_factory=list)
     resistance_levels: List[PriceLevel] = field(default_factory=list)
     current_price: float = 0.0
     nearest_support: Optional[PriceLevel] = None
@@ -39,20 +42,24 @@
     @property
     def support_distance_pct(self) -> Optional[float]:
         """Distance to nearest support as percentage."""
         if not self.nearest_support or self.current_price == 0:
             return None
-        return ((self.current_price - self.nearest_support.price)
-                / self.current_price * 100)
+        return (
+            (self.current_price - self.nearest_support.price) / self.current_price * 100
+        )
 
     @property
     def resistance_distance_pct(self) -> Optional[float]:
         """Distance to nearest resistance as percentage."""
         if not self.nearest_resistance or self.current_price == 0:
             return None
-        return ((self.nearest_resistance.price - self.current_price)
-                / self.current_price * 100)
+        return (
+            (self.nearest_resistance.price - self.current_price)
+            / self.current_price
+            * 100
+        )
 
     @property
     def in_support_zone(self) -> bool:
         """Check if price is in a support zone."""
         if not self.nearest_support:
@@ -83,11 +90,11 @@
 
     def __init__(
         self,
         candle_fetcher: CandleFetcher,
         lookback: int = 5,
-        tolerance_pct: float = 0.5
+        tolerance_pct: float = 0.5,
     ):
         """Initialize S/R detector.
 
         Args:
             candle_fetcher: CandleFetcher instance for getting price data
@@ -96,16 +103,11 @@
         """
         self.candle_fetcher = candle_fetcher
         self.lookback = lookback
         self.tolerance_pct = tolerance_pct
 
-    def detect(
-        self,
-        coin: str,
-        timeframe: str = "4h",
-        limit: int = 200
-    ) -> SRLevels:
+    def detect(self, coin: str, timeframe: str = "4h", limit: int = 200) -> SRLevels:
         """Detect support and resistance levels for a coin.
 
         Args:
             coin: Coin symbol (e.g., "BTC", "ETH")
             timeframe: Candle timeframe (default "4h" for meaningful levels)
@@ -152,11 +154,11 @@
             support_levels=support_levels,
             resistance_levels=resistance_levels,
             current_price=current_price,
             nearest_support=nearest_support,
             nearest_resistance=nearest_resistance,
-            timestamp=datetime.now()
+            timestamp=datetime.now(),
         )
 
     def find_swing_points(self, candles: List[Candle]) -> List[tuple[float, str]]:
         """Find swing highs and lows in candle data.
 
@@ -168,15 +170,11 @@
         Returns:
             List of (price, type) tuples
         """
         return self._find_swing_points(candles)
 
-    def cluster_levels(
-        self,
-        points: List[float],
-        level_type: str
-    ) -> List[PriceLevel]:
+    def cluster_levels(self, points: List[float], level_type: str) -> List[PriceLevel]:
         """Cluster price points into levels.
 
         Public method for testing.
 
         Args:
@@ -199,12 +197,12 @@
 
         for i in range(lookback, len(candles) - lookback):
             candle = candles[i]
 
             # Get surrounding candles
-            left_candles = candles[i - lookback:i]
-            right_candles = candles[i + 1:i + lookback + 1]
+            left_candles = candles[i - lookback : i]
+            right_candles = candles[i + 1 : i + lookback + 1]
 
             # Check for swing high
             left_highs = [c.high for c in left_candles]
             right_highs = [c.high for c in right_candles]
 
@@ -218,15 +216,11 @@
             if candle.low < min(left_lows) and candle.low < min(right_lows):
                 points.append((candle.low, "support"))
 
         return points
 
-    def _cluster_levels(
-        self,
-        points: List[float],
-        level_type: str
-    ) -> List[PriceLevel]:
+    def _cluster_levels(self, points: List[float], level_type: str) -> List[PriceLevel]:
         """Cluster nearby price points into zones.
 
         Points within tolerance_pct are merged.
         Strength = number of points in cluster.
         """
@@ -265,18 +259,20 @@
             # Expand zone slightly
             zone_range = avg_price * (self.tolerance_pct / 100)
             zone_low = min(zone_low, avg_price - zone_range)
             zone_high = max(zone_high, avg_price + zone_range)
 
-            levels.append(PriceLevel(
-                price=avg_price,
-                level_type=level_type,
-                strength=len(cluster),
-                last_touch=datetime.now(),
-                zone_low=zone_low,
-                zone_high=zone_high
-            ))
+            levels.append(
+                PriceLevel(
+                    price=avg_price,
+                    level_type=level_type,
+                    strength=len(cluster),
+                    last_touch=datetime.now(),
+                    zone_low=zone_low,
+                    zone_high=zone_high,
+                )
+            )
 
         # Sort by strength (most touches first)
         levels.sort(key=lambda l: l.strength, reverse=True)
 
         return levels
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/support_resistance.py
--- /mnt/c/documents/crypto-trading-bot/src/technical/funding.py	2026-02-04 01:24:00.575990+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/funding.py	2026-02-04 21:34:25.247384+00:00
@@ -1,6 +1,7 @@
 """Funding Rate fetcher for perpetual futures market positioning."""
+
 import logging
 from dataclasses import dataclass
 from datetime import datetime, timedelta
 from typing import Optional, List, Dict
 import requests
@@ -9,14 +10,15 @@
 
 
 @dataclass
 class FundingData:
     """Funding rate data for a coin."""
+
     coin: str
-    current_rate: float       # Current funding rate (per 8h)
-    predicted_rate: float     # Next predicted rate
-    annualized: float         # Annualized rate percentage
+    current_rate: float  # Current funding rate (per 8h)
+    predicted_rate: float  # Next predicted rate
+    annualized: float  # Annualized rate percentage
     timestamp: datetime
 
     @property
     def is_extreme_long(self) -> bool:
         """Market is crowded long (expensive to hold longs)."""
@@ -44,11 +46,11 @@
     def contrarian_signal(self) -> Optional[str]:
         """Contrarian trading signal based on extreme funding."""
         if self.is_extreme_long:
             return "SHORT"  # Crowded longs often get squeezed
         if self.is_extreme_short:
-            return "LONG"   # Crowded shorts often get squeezed
+            return "LONG"  # Crowded shorts often get squeezed
         return None
 
 
 class FundingRateFetcher:
     """Fetches funding rates from Bybit for perpetual futures.
@@ -140,11 +142,11 @@
             result = FundingData(
                 coin=coin,
                 current_rate=current_rate,
                 predicted_rate=predicted_rate,
                 annualized=annualized,
-                timestamp=datetime.now()
+                timestamp=datetime.now(),
             )
 
             self._cache[coin] = (result, datetime.now())
             logger.debug(f"{coin} funding: {current_rate*100:.4f}% ({result.bias})")
 
@@ -159,11 +161,11 @@
             return FundingData(
                 coin=coin,
                 current_rate=0.0,
                 predicted_rate=0.0,
                 annualized=0.0,
-                timestamp=datetime.now()
+                timestamp=datetime.now(),
             )
 
     def get_historical(self, coin: str, limit: int = 10) -> List[dict]:
         """Get historical funding rates.
 
@@ -224,14 +226,11 @@
             return self.SYMBOL_MAP[coin_upper]
         return f"{coin_upper}USDT"
 
     def _fetch_ticker(self, symbol: str) -> dict:
         """Fetch ticker data including funding rate."""
-        params = {
-            "category": "linear",
-            "symbol": symbol
-        }
+        params = {"category": "linear", "symbol": symbol}
 
         response = requests.get(self.TICKERS_URL, params=params, timeout=10)
         response.raise_for_status()
         data = response.json()
 
@@ -244,15 +243,11 @@
 
         return tickers[0]
 
     def _fetch_history(self, symbol: str, limit: int = 10) -> List[dict]:
         """Fetch historical funding rates."""
-        params = {
-            "category": "linear",
-            "symbol": symbol,
-            "limit": limit
-        }
+        params = {"category": "linear", "symbol": symbol, "limit": limit}
 
         response = requests.get(self.API_URL, params=params, timeout=10)
         response.raise_for_status()
         data = response.json()
 
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/funding.py
--- /mnt/c/documents/crypto-trading-bot/src/journal.py	2026-02-03 01:11:59.604383+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/journal.py	2026-02-04 21:34:25.250440+00:00
@@ -30,32 +30,34 @@
 
 # =============================================================================
 # Data Classes
 # =============================================================================
 
+
 @dataclass
 class MarketContext:
     """
     Market conditions at time of trade.
 
     Captured at entry to understand what environment the trade was made in.
     The Reflection Engine uses this to find patterns like:
     - "We lose money in volatile markets"
     - "Trending BTC helps altcoin longs"
     """
-    regime: Optional[str] = None           # "trending", "ranging", "volatile"
-    volatility: Optional[float] = None     # ATR or similar measure
-    funding_rate: Optional[float] = None   # Exchange funding rate
-    cvd: Optional[float] = None            # Cumulative volume delta
-    btc_trend: Optional[str] = None        # "up", "down", "sideways"
-    btc_price: Optional[float] = None      # BTC price at time
+
+    regime: Optional[str] = None  # "trending", "ranging", "volatile"
+    volatility: Optional[float] = None  # ATR or similar measure
+    funding_rate: Optional[float] = None  # Exchange funding rate
+    cvd: Optional[float] = None  # Cumulative volume delta
+    btc_trend: Optional[str] = None  # "up", "down", "sideways"
+    btc_price: Optional[float] = None  # BTC price at time
 
     def to_dict(self) -> dict:
         return asdict(self)
 
     @classmethod
-    def from_dict(cls, d: dict) -> 'MarketContext':
+    def from_dict(cls, d: dict) -> "MarketContext":
         if d is None:
             return cls()
         return cls(**{k: v for k, v in d.items() if k in cls.__dataclass_fields__})
 
 
@@ -68,47 +70,48 @@
     - Why we entered (conditions, reasoning, market state)
     - What happened (entry price, exit price, duration)
     - The outcome (P&L, exit reason)
     - What happened next (did we exit too early?)
     """
+
     # Identity
     id: str
-    position_id: str                       # Links to Sniper position
+    position_id: str  # Links to Sniper position
 
     # Entry details
     entry_time: datetime
     entry_price: float
-    entry_reason: str                      # Human-readable reasoning
+    entry_reason: str  # Human-readable reasoning
 
     # Trade parameters
     coin: str
-    direction: str                         # "LONG" or "SHORT"
+    direction: str  # "LONG" or "SHORT"
     position_size_usd: float
     stop_loss_price: float
     take_profit_price: float
 
     # Strategy context
     strategy_id: str
     condition_id: str
-    pattern_id: Optional[str] = None       # If pattern-based entry
+    pattern_id: Optional[str] = None  # If pattern-based entry
 
     # Market context at entry
     market_regime: Optional[str] = None
     volatility: Optional[float] = None
     funding_rate: Optional[float] = None
     cvd: Optional[float] = None
     btc_trend: Optional[str] = None
     btc_price: Optional[float] = None
 
     # Timing context
-    hour_of_day: int = 0                   # 0-23 UTC
-    day_of_week: int = 0                   # 0-6 (Mon-Sun)
+    hour_of_day: int = 0  # 0-23 UTC
+    day_of_week: int = 0  # 0-6 (Mon-Sun)
 
     # Exit details (filled when closed)
     exit_time: Optional[datetime] = None
     exit_price: Optional[float] = None
-    exit_reason: Optional[str] = None      # "stop_loss", "take_profit", "manual"
+    exit_reason: Optional[str] = None  # "stop_loss", "take_profit", "manual"
 
     # Outcome (filled when closed)
     pnl_usd: Optional[float] = None
     pnl_pct: Optional[float] = None
     duration_seconds: Optional[int] = None
@@ -118,28 +121,28 @@
     price_5min_after: Optional[float] = None
     price_15min_after: Optional[float] = None
     missed_profit_usd: Optional[float] = None
 
     # Metadata
-    status: str = "open"                   # "open", "closed", "post_tracked"
+    status: str = "open"  # "open", "closed", "post_tracked"
     created_at: datetime = field(default_factory=datetime.now)
     updated_at: datetime = field(default_factory=datetime.now)
 
     def to_dict(self) -> dict:
         """Convert to dictionary for database storage."""
         d = asdict(self)
         # Convert datetimes to ISO strings
-        for key in ['entry_time', 'exit_time', 'created_at', 'updated_at']:
+        for key in ["entry_time", "exit_time", "created_at", "updated_at"]:
             if d.get(key) and isinstance(d[key], datetime):
                 d[key] = d[key].isoformat()
         return d
 
     @classmethod
-    def from_dict(cls, d: dict) -> 'JournalEntry':
+    def from_dict(cls, d: dict) -> "JournalEntry":
         """Create from dictionary (database row)."""
         # Convert ISO strings back to datetimes
-        for key in ['entry_time', 'exit_time', 'created_at', 'updated_at']:
+        for key in ["entry_time", "exit_time", "created_at", "updated_at"]:
             if d.get(key) and isinstance(d[key], str):
                 try:
                     d[key] = datetime.fromisoformat(d[key])
                 except (ValueError, TypeError):
                     d[key] = None
@@ -159,10 +162,11 @@
 
 
 # =============================================================================
 # Database Operations
 # =============================================================================
+
 
 class JournalDatabase:
     """
     SQLite database operations for the trade journal.
 
@@ -233,31 +237,31 @@
             conn.commit()
 
     def insert(self, entry: JournalEntry) -> None:
         """Insert a new journal entry."""
         d = entry.to_dict()
-        columns = ', '.join(d.keys())
-        placeholders = ', '.join(['?' for _ in d])
+        columns = ", ".join(d.keys())
+        placeholders = ", ".join(["?" for _ in d])
 
         with self._get_connection() as conn:
             cursor = conn.cursor()
             cursor.execute(
                 f"INSERT OR REPLACE INTO trade_journal ({columns}) VALUES ({placeholders})",
-                list(d.values())
+                list(d.values()),
             )
             conn.commit()
 
     def update(self, entry_id: str, updates: dict) -> None:
         """Update an existing entry."""
-        updates['updated_at'] = datetime.now().isoformat()
-        set_clause = ', '.join(f"{k} = ?" for k in updates.keys())
+        updates["updated_at"] = datetime.now().isoformat()
+        set_clause = ", ".join(f"{k} = ?" for k in updates.keys())
 
         with self._get_connection() as conn:
             cursor = conn.cursor()
             cursor.execute(
                 f"UPDATE trade_journal SET {set_clause} WHERE id = ?",
-                list(updates.values()) + [entry_id]
+                list(updates.values()) + [entry_id],
             )
             conn.commit()
 
     def get(self, entry_id: str) -> Optional[JournalEntry]:
         """Get a single entry by ID."""
@@ -272,47 +276,43 @@
     def get_by_position(self, position_id: str) -> Optional[JournalEntry]:
         """Get entry by position ID."""
         with self._get_connection() as conn:
             cursor = conn.cursor()
             cursor.execute(
-                "SELECT * FROM trade_journal WHERE position_id = ?",
-                (position_id,)
+                "SELECT * FROM trade_journal WHERE position_id = ?", (position_id,)
             )
             row = cursor.fetchone()
             if row:
                 return JournalEntry.from_dict(dict(row))
             return None
 
-    def query(self,
-              where: str = "1=1",
-              params: tuple = (),
-              order_by: str = "entry_time DESC",
-              limit: int = 100) -> list[JournalEntry]:
+    def query(
+        self,
+        where: str = "1=1",
+        params: tuple = (),
+        order_by: str = "entry_time DESC",
+        limit: int = 100,
+    ) -> list[JournalEntry]:
         """Execute a query with WHERE clause."""
         with self._get_connection() as conn:
             cursor = conn.cursor()
             cursor.execute(
                 f"SELECT * FROM trade_journal WHERE {where} ORDER BY {order_by} LIMIT ?",
-                params + (limit,)
+                params + (limit,),
             )
             return [JournalEntry.from_dict(dict(row)) for row in cursor.fetchall()]
 
     def count(self, where: str = "1=1", params: tuple = ()) -> int:
         """Count entries matching criteria."""
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute(
-                f"SELECT COUNT(*) FROM trade_journal WHERE {where}",
-                params
-            )
+            cursor.execute(f"SELECT COUNT(*) FROM trade_journal WHERE {where}", params)
             return cursor.fetchone()[0]
 
-    def aggregate(self,
-                  select: str,
-                  where: str = "1=1",
-                  params: tuple = (),
-                  group_by: str = None) -> list[dict]:
+    def aggregate(
+        self, select: str, where: str = "1=1", params: tuple = (), group_by: str = None
+    ) -> list[dict]:
         """Run aggregate query."""
         query = f"SELECT {select} FROM trade_journal WHERE {where}"
         if group_by:
             query += f" GROUP BY {group_by}"
 
@@ -324,10 +324,11 @@
 
 
 # =============================================================================
 # Async Write Queue
 # =============================================================================
+
 
 class AsyncWriteQueue:
     """
     Background write queue to avoid blocking the Sniper.
 
@@ -366,15 +367,15 @@
 
         logger.debug("Async write queue stopped")
 
     def enqueue_insert(self, entry: JournalEntry) -> None:
         """Queue an insert operation."""
-        self.queue.put(('insert', entry))
+        self.queue.put(("insert", entry))
 
     def enqueue_update(self, entry_id: str, updates: dict) -> None:
         """Queue an update operation."""
-        self.queue.put(('update', (entry_id, updates)))
+        self.queue.put(("update", (entry_id, updates)))
 
     def _process_queue(self) -> None:
         """Process queued writes in background thread."""
         while self._running:
             try:
@@ -386,22 +387,23 @@
                 logger.error(f"Write queue error: {e}")
 
     def _execute(self, operation: str, args: Any) -> None:
         """Execute a queued operation."""
         try:
-            if operation == 'insert':
+            if operation == "insert":
                 self.db.insert(args)
-            elif operation == 'update':
+            elif operation == "update":
                 entry_id, updates = args
                 self.db.update(entry_id, updates)
         except Exception as e:
             logger.error(f"Database write error: {e}")
 
 
 # =============================================================================
 # Trade Journal
 # =============================================================================
+
 
 class TradeJournal:
     """
     Comprehensive trade journaling system.
 
@@ -426,14 +428,16 @@
         recent = journal.get_recent(hours=24)
         losers = journal.get_losers(limit=10)
         by_hour = journal.get_performance_by_hour()
     """
 
-    def __init__(self,
-                 db_path: Optional[str] = None,
-                 market_feed: Optional['MarketFeed'] = None,
-                 enable_async: bool = True):
+    def __init__(
+        self,
+        db_path: Optional[str] = None,
+        market_feed: Optional["MarketFeed"] = None,
+        enable_async: bool = True,
+    ):
         """
         Initialize the Trade Journal.
 
         Args:
             db_path: Path to SQLite database (default: data/trading_bot.db)
@@ -479,14 +483,16 @@
 
     # =========================================================================
     # Entry Recording (called by Sniper)
     # =========================================================================
 
-    def record_entry(self,
-                     position: 'Position',
-                     timestamp: int,
-                     market_context: Optional[MarketContext] = None) -> str:
+    def record_entry(
+        self,
+        position: "Position",
+        timestamp: int,
+        market_context: Optional[MarketContext] = None,
+    ) -> str:
         """
         Record a new trade entry.
 
         Args:
             position: The opened position from Sniper
@@ -546,16 +552,18 @@
 
     # =========================================================================
     # Exit Recording (called by Sniper)
     # =========================================================================
 
-    def record_exit(self,
-                    position: 'Position',
-                    exit_price: float,
-                    timestamp: int,
-                    reason: str,
-                    pnl: float) -> Optional[str]:
+    def record_exit(
+        self,
+        position: "Position",
+        exit_price: float,
+        timestamp: int,
+        reason: str,
+        pnl: float,
+    ) -> Optional[str]:
         """
         Record a trade exit.
 
         Args:
             position: The position being closed
@@ -583,22 +591,22 @@
         pnl_pct = (pnl / position.size_usd) * 100 if position.size_usd > 0 else 0
         duration = int((exit_time - entry.entry_time).total_seconds())
 
         # Update entry
         updates = {
-            'exit_time': exit_time.isoformat(),
-            'exit_price': exit_price,
-            'exit_reason': reason,
-            'pnl_usd': pnl,
-            'pnl_pct': pnl_pct,
-            'duration_seconds': duration,
-            'status': 'closed',
+            "exit_time": exit_time.isoformat(),
+            "exit_price": exit_price,
+            "exit_reason": reason,
+            "pnl_usd": pnl,
+            "pnl_pct": pnl_pct,
+            "duration_seconds": duration,
+            "status": "closed",
         }
 
         # Apply updates to entry object
         for key, value in updates.items():
-            if key == 'exit_time':
+            if key == "exit_time":
                 entry.exit_time = exit_time
             else:
                 setattr(entry, key, value)
 
         # Queue async write
@@ -630,33 +638,33 @@
 
         try:
             loop = asyncio.get_event_loop()
             if loop.is_running():
                 task = asyncio.create_task(
-                    self._capture_post_trade_prices(entry.id, entry.coin, entry.direction, entry.exit_price)
+                    self._capture_post_trade_prices(
+                        entry.id, entry.coin, entry.direction, entry.exit_price
+                    )
                 )
                 self._post_trade_tasks[entry.id] = task
             else:
                 # Run in thread if no event loop
                 threading.Thread(
                     target=self._capture_post_trade_sync,
                     args=(entry.id, entry.coin, entry.direction, entry.exit_price),
-                    daemon=True
+                    daemon=True,
                 ).start()
         except RuntimeError:
             # No event loop
             threading.Thread(
                 target=self._capture_post_trade_sync,
                 args=(entry.id, entry.coin, entry.direction, entry.exit_price),
-                daemon=True
+                daemon=True,
             ).start()
 
-    async def _capture_post_trade_prices(self,
-                                          entry_id: str,
-                                          coin: str,
-                                          direction: str,
-                                          exit_price: float) -> None:
+    async def _capture_post_trade_prices(
+        self, entry_id: str, coin: str, direction: str, exit_price: float
+    ) -> None:
         """
         Capture prices at 1, 5, and 15 minutes after exit.
 
         This answers: "Did we exit too early?"
         """
@@ -665,32 +673,32 @@
         try:
             # Wait 1 minute, capture
             await asyncio.sleep(60)
             tick = self.market_feed.get_price(coin)
             if tick:
-                prices['price_1min_after'] = tick.price
+                prices["price_1min_after"] = tick.price
 
             # Wait 4 more minutes (total 5), capture
             await asyncio.sleep(240)
             tick = self.market_feed.get_price(coin)
             if tick:
-                prices['price_5min_after'] = tick.price
+                prices["price_5min_after"] = tick.price
 
             # Wait 10 more minutes (total 15), capture
             await asyncio.sleep(600)
             tick = self.market_feed.get_price(coin)
             if tick:
-                prices['price_15min_after'] = tick.price
+                prices["price_15min_after"] = tick.price
 
             # Calculate missed profit
-            if prices.get('price_15min_after'):
+            if prices.get("price_15min_after"):
                 missed = self._calculate_missed_profit(
-                    direction, exit_price, prices['price_15min_after']
+                    direction, exit_price, prices["price_15min_after"]
                 )
-                prices['missed_profit_usd'] = missed
-
-            prices['status'] = 'post_tracked'
+                prices["missed_profit_usd"] = missed
+
+            prices["status"] = "post_tracked"
 
             # Update database
             if self._write_queue:
                 self._write_queue.enqueue_update(entry_id, prices)
             else:
@@ -703,55 +711,52 @@
         except Exception as e:
             logger.error(f"Post-trade capture error for {entry_id}: {e}")
         finally:
             self._post_trade_tasks.pop(entry_id, None)
 
-    def _capture_post_trade_sync(self,
-                                  entry_id: str,
-                                  coin: str,
-                                  direction: str,
-                                  exit_price: float) -> None:
+    def _capture_post_trade_sync(
+        self, entry_id: str, coin: str, direction: str, exit_price: float
+    ) -> None:
         """Synchronous version for when no event loop is available."""
         import time
 
         prices = {}
 
         try:
             # Wait 1 minute
             time.sleep(60)
             tick = self.market_feed.get_price(coin)
             if tick:
-                prices['price_1min_after'] = tick.price
+                prices["price_1min_after"] = tick.price
 
             # Wait 4 more minutes
             time.sleep(240)
             tick = self.market_feed.get_price(coin)
             if tick:
-                prices['price_5min_after'] = tick.price
+                prices["price_5min_after"] = tick.price
 
             # Wait 10 more minutes
             time.sleep(600)
             tick = self.market_feed.get_price(coin)
             if tick:
-                prices['price_15min_after'] = tick.price
-
-            if prices.get('price_15min_after'):
+                prices["price_15min_after"] = tick.price
+
+            if prices.get("price_15min_after"):
                 missed = self._calculate_missed_profit(
-                    direction, exit_price, prices['price_15min_after']
+                    direction, exit_price, prices["price_15min_after"]
                 )
-                prices['missed_profit_usd'] = missed
-
-            prices['status'] = 'post_tracked'
+                prices["missed_profit_usd"] = missed
+
+            prices["status"] = "post_tracked"
             self.db.update(entry_id, prices)
 
         except Exception as e:
             logger.error(f"Post-trade capture error: {e}")
 
-    def _calculate_missed_profit(self,
-                                  direction: str,
-                                  exit_price: float,
-                                  later_price: float) -> float:
+    def _calculate_missed_profit(
+        self, direction: str, exit_price: float, later_price: float
+    ) -> float:
         """
         Calculate profit missed by exiting when we did.
 
         For LONG: if price went higher, we missed profit
         For SHORT: if price went lower, we missed profit
@@ -779,14 +784,13 @@
         # Check pending first
         if position_id in self.pending_entries:
             return self.pending_entries[position_id]
         return self.db.get_by_position(position_id)
 
-    def get_recent(self,
-                   hours: int = 24,
-                   status: Optional[str] = None,
-                   limit: int = 100) -> list[JournalEntry]:
+    def get_recent(
+        self, hours: int = 24, status: Optional[str] = None, limit: int = 100
+    ) -> list[JournalEntry]:
         """
         Get recent journal entries.
 
         Args:
             hours: How far back to look
@@ -803,91 +807,73 @@
 
         return self.db.query(where=where, params=params, limit=limit)
 
     def get_by_coin(self, coin: str, limit: int = 100) -> list[JournalEntry]:
         """Get entries for a specific coin."""
-        return self.db.query(
-            where="coin = ?",
-            params=(coin.upper(),),
-            limit=limit
-        )
+        return self.db.query(where="coin = ?", params=(coin.upper(),), limit=limit)
 
     def get_by_strategy(self, strategy_id: str, limit: int = 100) -> list[JournalEntry]:
         """Get entries for a specific strategy."""
         return self.db.query(
-            where="strategy_id = ?",
-            params=(strategy_id,),
-            limit=limit
+            where="strategy_id = ?", params=(strategy_id,), limit=limit
         )
 
     def get_by_exit_reason(self, reason: str, limit: int = 100) -> list[JournalEntry]:
         """Get entries by exit reason."""
-        return self.db.query(
-            where="exit_reason = ?",
-            params=(reason,),
-            limit=limit
-        )
+        return self.db.query(where="exit_reason = ?", params=(reason,), limit=limit)
 
     def get_by_time_of_day(self, hour: int, limit: int = 100) -> list[JournalEntry]:
         """Get entries that occurred at a specific hour (0-23 UTC)."""
-        return self.db.query(
-            where="hour_of_day = ?",
-            params=(hour,),
-            limit=limit
-        )
+        return self.db.query(where="hour_of_day = ?", params=(hour,), limit=limit)
 
     def get_by_day_of_week(self, day: int, limit: int = 100) -> list[JournalEntry]:
         """Get entries that occurred on a specific day (0=Mon, 6=Sun)."""
-        return self.db.query(
-            where="day_of_week = ?",
-            params=(day,),
-            limit=limit
-        )
+        return self.db.query(where="day_of_week = ?", params=(day,), limit=limit)
 
     def get_winners(self, limit: int = 100) -> list[JournalEntry]:
         """Get profitable trades."""
         return self.db.query(
             where="pnl_usd > 0 AND status != 'open'",
             params=(),
             order_by="pnl_usd DESC",
-            limit=limit
+            limit=limit,
         )
 
     def get_losers(self, limit: int = 100) -> list[JournalEntry]:
         """Get losing trades."""
         return self.db.query(
             where="pnl_usd < 0 AND status != 'open'",
             params=(),
             order_by="pnl_usd ASC",
-            limit=limit
+            limit=limit,
         )
 
     def get_by_market_regime(self, regime: str, limit: int = 100) -> list[JournalEntry]:
         """Get entries that occurred in a specific market regime."""
-        return self.db.query(
-            where="market_regime = ?",
-            params=(regime,),
-            limit=limit
-        )
-
-    def get_early_exits(self, min_missed_profit: float = 1.0, limit: int = 100) -> list[JournalEntry]:
+        return self.db.query(where="market_regime = ?", params=(regime,), limit=limit)
+
+    def get_early_exits(
+        self, min_missed_profit: float = 1.0, limit: int = 100
+    ) -> list[JournalEntry]:
         """Get trades where we exited too early (missed significant profit)."""
         return self.db.query(
             where="missed_profit_usd > ? AND status = 'post_tracked'",
             params=(min_missed_profit,),
             order_by="missed_profit_usd DESC",
-            limit=limit
+            limit=limit,
         )
 
     # =========================================================================
     # Statistics
     # =========================================================================
 
-    def get_stats(self,
-                  coin: Optional[str] = None,
-                  strategy_id: Optional[str] = None,
-                  hours: Optional[int] = None) -> dict:
+    def get_stats(
+        self,
+        coin: Optional[str] = None,
+        strategy_id: Optional[str] = None,
+        hours: Optional[int] = None,
+    ) -> dict:
         """
         Get performance statistics.
 
         Args:
             coin: Filter by coin
@@ -927,46 +913,46 @@
                 MIN(pnl_usd) as worst_trade,
                 AVG(duration_seconds) as avg_duration,
                 AVG(ABS(pnl_pct)) as avg_move_pct
             """,
             where=where,
-            params=tuple(params)
+            params=tuple(params),
         )
 
         if not result:
             return self._empty_stats()
 
         stats = result[0]
-        total = stats['total_trades'] or 0
-        wins = stats['wins'] or 0
+        total = stats["total_trades"] or 0
+        wins = stats["wins"] or 0
 
         return {
-            'total_trades': total,
-            'wins': wins,
-            'losses': stats['losses'] or 0,
-            'win_rate': (wins / total * 100) if total > 0 else 0,
-            'total_pnl': stats['total_pnl'] or 0,
-            'avg_pnl': stats['avg_pnl'] or 0,
-            'best_trade': stats['best_trade'] or 0,
-            'worst_trade': stats['worst_trade'] or 0,
-            'avg_duration_seconds': stats['avg_duration'] or 0,
-            'avg_move_pct': stats['avg_move_pct'] or 0,
+            "total_trades": total,
+            "wins": wins,
+            "losses": stats["losses"] or 0,
+            "win_rate": (wins / total * 100) if total > 0 else 0,
+            "total_pnl": stats["total_pnl"] or 0,
+            "avg_pnl": stats["avg_pnl"] or 0,
+            "best_trade": stats["best_trade"] or 0,
+            "worst_trade": stats["worst_trade"] or 0,
+            "avg_duration_seconds": stats["avg_duration"] or 0,
+            "avg_move_pct": stats["avg_move_pct"] or 0,
         }
 
     def _empty_stats(self) -> dict:
         """Return empty stats dict."""
         return {
-            'total_trades': 0,
-            'wins': 0,
-            'losses': 0,
-            'win_rate': 0,
-            'total_pnl': 0,
-            'avg_pnl': 0,
-            'best_trade': 0,
-            'worst_trade': 0,
-            'avg_duration_seconds': 0,
-            'avg_move_pct': 0,
+            "total_trades": 0,
+            "wins": 0,
+            "losses": 0,
+            "win_rate": 0,
+            "total_pnl": 0,
+            "avg_pnl": 0,
+            "best_trade": 0,
+            "worst_trade": 0,
+            "avg_duration_seconds": 0,
+            "avg_move_pct": 0,
         }
 
     def get_performance_by_hour(self) -> dict[int, dict]:
         """
         Get performance broken down by hour of day.
@@ -981,22 +967,23 @@
                 SUM(CASE WHEN pnl_usd > 0 THEN 1 ELSE 0 END) as wins,
                 SUM(pnl_usd) as total_pnl,
                 AVG(pnl_usd) as avg_pnl
             """,
             where="status != 'open'",
-            group_by="hour_of_day"
+            group_by="hour_of_day",
         )
 
         return {
-            r['hour_of_day']: {
-                'trades': r['trades'],
-                'wins': r['wins'],
-                'win_rate': (r['wins'] / r['trades'] * 100) if r['trades'] > 0 else 0,
-                'total_pnl': r['total_pnl'] or 0,
-                'avg_pnl': r['avg_pnl'] or 0,
+            r["hour_of_day"]: {
+                "trades": r["trades"],
+                "wins": r["wins"],
+                "win_rate": (r["wins"] / r["trades"] * 100) if r["trades"] > 0 else 0,
+                "total_pnl": r["total_pnl"] or 0,
+                "avg_pnl": r["avg_pnl"] or 0,
             }
-            for r in results if r['hour_of_day'] is not None
+            for r in results
+            if r["hour_of_day"] is not None
         }
 
     def get_performance_by_day(self) -> dict[int, dict]:
         """
         Get performance broken down by day of week.
@@ -1011,22 +998,23 @@
                 SUM(CASE WHEN pnl_usd > 0 THEN 1 ELSE 0 END) as wins,
                 SUM(pnl_usd) as total_pnl,
                 AVG(pnl_usd) as avg_pnl
             """,
             where="status != 'open'",
-            group_by="day_of_week"
+            group_by="day_of_week",
         )
 
         return {
-            r['day_of_week']: {
-                'trades': r['trades'],
-                'wins': r['wins'],
-                'win_rate': (r['wins'] / r['trades'] * 100) if r['trades'] > 0 else 0,
-                'total_pnl': r['total_pnl'] or 0,
-                'avg_pnl': r['avg_pnl'] or 0,
+            r["day_of_week"]: {
+                "trades": r["trades"],
+                "wins": r["wins"],
+                "win_rate": (r["wins"] / r["trades"] * 100) if r["trades"] > 0 else 0,
+                "total_pnl": r["total_pnl"] or 0,
+                "avg_pnl": r["avg_pnl"] or 0,
             }
-            for r in results if r['day_of_week'] is not None
+            for r in results
+            if r["day_of_week"] is not None
         }
 
     def get_performance_by_coin(self) -> dict[str, dict]:
         """
         Get performance broken down by coin.
@@ -1041,22 +1029,23 @@
                 SUM(CASE WHEN pnl_usd > 0 THEN 1 ELSE 0 END) as wins,
                 SUM(pnl_usd) as total_pnl,
                 AVG(pnl_usd) as avg_pnl
             """,
             where="status != 'open'",
-            group_by="coin"
+            group_by="coin",
         )
 
         return {
-            r['coin']: {
-                'trades': r['trades'],
-                'wins': r['wins'],
-                'win_rate': (r['wins'] / r['trades'] * 100) if r['trades'] > 0 else 0,
-                'total_pnl': r['total_pnl'] or 0,
-                'avg_pnl': r['avg_pnl'] or 0,
+            r["coin"]: {
+                "trades": r["trades"],
+                "wins": r["wins"],
+                "win_rate": (r["wins"] / r["trades"] * 100) if r["trades"] > 0 else 0,
+                "total_pnl": r["total_pnl"] or 0,
+                "avg_pnl": r["avg_pnl"] or 0,
             }
-            for r in results if r['coin'] is not None
+            for r in results
+            if r["coin"] is not None
         }
 
     def get_performance_by_exit_reason(self) -> dict[str, dict]:
         """
         Get performance broken down by exit reason.
@@ -1071,22 +1060,23 @@
                 SUM(CASE WHEN pnl_usd > 0 THEN 1 ELSE 0 END) as wins,
                 SUM(pnl_usd) as total_pnl,
                 AVG(pnl_usd) as avg_pnl
             """,
             where="status != 'open' AND exit_reason IS NOT NULL",
-            group_by="exit_reason"
+            group_by="exit_reason",
         )
 
         return {
-            r['exit_reason']: {
-                'trades': r['trades'],
-                'wins': r['wins'],
-                'win_rate': (r['wins'] / r['trades'] * 100) if r['trades'] > 0 else 0,
-                'total_pnl': r['total_pnl'] or 0,
-                'avg_pnl': r['avg_pnl'] or 0,
+            r["exit_reason"]: {
+                "trades": r["trades"],
+                "wins": r["wins"],
+                "win_rate": (r["wins"] / r["trades"] * 100) if r["trades"] > 0 else 0,
+                "total_pnl": r["total_pnl"] or 0,
+                "avg_pnl": r["avg_pnl"] or 0,
             }
-            for r in results if r['exit_reason'] is not None
+            for r in results
+            if r["exit_reason"] is not None
         }
 
     # =========================================================================
     # Lifecycle
     # =========================================================================
would reformat /mnt/c/documents/crypto-trading-bot/src/journal.py
--- /mnt/c/documents/crypto-trading-bot/src/market_feed.py	2026-02-03 20:32:17.814248+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/market_feed.py	2026-02-04 21:34:25.255013+00:00
@@ -17,47 +17,53 @@
 
 try:
     import websockets
     from websockets.exceptions import ConnectionClosed, WebSocketException
 except ImportError:
-    raise ImportError("websockets library required. Install with: pip install websockets")
+    raise ImportError(
+        "websockets library required. Install with: pip install websockets"
+    )
 
 logger = logging.getLogger(__name__)
 
 
 @dataclass
 class PriceTick:
     """Real-time price update."""
-    coin: str           # "BTC", "ETH", etc.
-    price: float        # Current price in USDT
-    timestamp: int      # Unix timestamp in milliseconds
-    volume_24h: float   # 24h volume (updated periodically)
-    change_24h: float   # 24h % change (updated periodically)
+
+    coin: str  # "BTC", "ETH", etc.
+    price: float  # Current price in USDT
+    timestamp: int  # Unix timestamp in milliseconds
+    volume_24h: float  # 24h volume (updated periodically)
+    change_24h: float  # 24h % change (updated periodically)
 
 
 @dataclass
 class TradeEvent:
     """Individual trade event for order flow analysis."""
+
     coin: str
     price: float
     quantity: float
     is_buyer_maker: bool  # True = sell (taker sold), False = buy (taker bought)
     timestamp: int
 
 
 @dataclass
 class CoinConfig:
     """Configuration for a monitored coin."""
-    symbol: str         # "BTC"
-    binance: str        # "BTCUSDT"
-    tier: int           # 1, 2, or 3
-    name: str           # "Bitcoin"
+
+    symbol: str  # "BTC"
+    binance: str  # "BTCUSDT"
+    tier: int  # 1, 2, or 3
+    name: str  # "Bitcoin"
 
 
 @dataclass
 class FeedStatus:
     """Current status of the market feed."""
+
     connected: bool = False
     exchange: str = ""
     last_message_time: Optional[float] = None
     reconnect_count: int = 0
     messages_received: int = 0
@@ -83,33 +89,24 @@
         feed.subscribe_price(lambda tick: print(f"{tick.coin}: ${tick.price}"))
         await feed.connect()
     """
 
     EXCHANGES = {
-        'bybit': {
-            'url': 'wss://stream.bybit.com/v5/public/spot',
-            'type': 'bybit'
+        "bybit": {"url": "wss://stream.bybit.com/v5/public/spot", "type": "bybit"},
+        "bybit_linear": {
+            "url": "wss://stream.bybit.com/v5/public/linear",
+            "type": "bybit",
         },
-        'bybit_linear': {
-            'url': 'wss://stream.bybit.com/v5/public/linear',
-            'type': 'bybit'
-        },
-        'binance': {
-            'url': 'wss://stream.binance.com:9443/stream',
-            'type': 'binance'
-        },
-        'binance_us': {
-            'url': 'wss://stream.binance.us:9443/stream',
-            'type': 'binance'
-        },
+        "binance": {"url": "wss://stream.binance.com:9443/stream", "type": "binance"},
+        "binance_us": {"url": "wss://stream.binance.us:9443/stream", "type": "binance"},
     }
 
     def __init__(
         self,
         coins: Optional[list[str]] = None,
-        exchange: str = 'bybit',
-        config_path: Optional[str] = None
+        exchange: str = "bybit",
+        config_path: Optional[str] = None,
     ):
         """
         Initialize MarketFeed.
 
         Args:
@@ -117,17 +114,17 @@
                    If None, loads from config/coins.json.
             exchange: Exchange to use ('bybit', 'binance', 'binance_us').
             config_path: Path to coins.json config file.
         """
         self.config = self._load_config(config_path)
-        self.exchange = exchange or self.config.get('exchange', 'bybit')
+        self.exchange = exchange or self.config.get("exchange", "bybit")
         self.coin_configs = self._parse_coin_configs(coins)
 
         # Validate exchange
         if self.exchange not in self.EXCHANGES:
             logger.warning(f"Unknown exchange '{self.exchange}', defaulting to 'bybit'")
-            self.exchange = 'bybit'
+            self.exchange = "bybit"
 
         # WebSocket state
         self.ws: Optional[websockets.WebSocketClientProtocol] = None
         self._running = False
         self._listen_task: Optional[asyncio.Task] = None
@@ -147,63 +144,64 @@
 
         # Status tracking
         self.status = FeedStatus(exchange=self.exchange)
 
         # Reconnection settings
-        ws_config = self.config.get('websocket', {})
-        self._reconnect_delay = ws_config.get('reconnect_delay_initial', 1.0)
-        self._reconnect_delay_max = ws_config.get('reconnect_delay_max', 30.0)
-        self._ping_interval = ws_config.get('ping_interval', 20)
-        self._stale_threshold = ws_config.get('stale_threshold_seconds', 5)
+        ws_config = self.config.get("websocket", {})
+        self._reconnect_delay = ws_config.get("reconnect_delay_initial", 1.0)
+        self._reconnect_delay_max = ws_config.get("reconnect_delay_max", 30.0)
+        self._ping_interval = ws_config.get("ping_interval", 20)
+        self._stale_threshold = ws_config.get("stale_threshold_seconds", 5)
 
         # Symbol mapping
         self._symbol_to_coin: dict[str, str] = {}
         self._setup_symbol_mapping()
 
-        logger.info(f"MarketFeed initialized: {self.exchange}, {len(self.coin_configs)} coins")
+        logger.info(
+            f"MarketFeed initialized: {self.exchange}, {len(self.coin_configs)} coins"
+        )
 
     def _load_config(self, config_path: Optional[str] = None) -> dict:
         """Load configuration from coins.json."""
         if config_path is None:
             possible_paths = [
-                Path(__file__).parent.parent / 'config' / 'coins.json',
-                Path('config/coins.json'),
-                Path('/mnt/c/documents/crypto-trading-bot/config/coins.json'),
+                Path(__file__).parent.parent / "config" / "coins.json",
+                Path("config/coins.json"),
+                Path("/mnt/c/documents/crypto-trading-bot/config/coins.json"),
             ]
             for path in possible_paths:
                 if path.exists():
                     config_path = str(path)
                     break
             else:
                 logger.warning("coins.json not found, using defaults")
                 return self._default_config()
 
-        with open(config_path, 'r') as f:
+        with open(config_path, "r") as f:
             return json.load(f)
 
     def _default_config(self) -> dict:
         return {
-            'exchange': 'bybit',
-            'monitored_coins': [],
-            'websocket': {
-                'reconnect_delay_initial': 1.0,
-                'reconnect_delay_max': 30.0,
-                'ping_interval': 20,
-                'stale_threshold_seconds': 5
-            }
+            "exchange": "bybit",
+            "monitored_coins": [],
+            "websocket": {
+                "reconnect_delay_initial": 1.0,
+                "reconnect_delay_max": 30.0,
+                "ping_interval": 20,
+                "stale_threshold_seconds": 5,
+            },
         }
 
-    def _parse_coin_configs(self, coins: Optional[list[str]] = None) -> list[CoinConfig]:
+    def _parse_coin_configs(
+        self, coins: Optional[list[str]] = None
+    ) -> list[CoinConfig]:
         """Parse coin configurations."""
         all_configs = [
             CoinConfig(
-                symbol=c['symbol'],
-                binance=c['binance'],
-                tier=c['tier'],
-                name=c['name']
+                symbol=c["symbol"], binance=c["binance"], tier=c["tier"], name=c["name"]
             )
-            for c in self.config.get('monitored_coins', [])
+            for c in self.config.get("monitored_coins", [])
         ]
 
         if coins is None:
             return all_configs
 
@@ -212,36 +210,33 @@
 
         # Add unknown coins with defaults
         existing = {c.symbol for c in filtered}
         for coin in coins_upper:
             if coin not in existing:
-                filtered.append(CoinConfig(
-                    symbol=coin,
-                    binance=f"{coin}USDT",
-                    tier=3,
-                    name=coin
-                ))
+                filtered.append(
+                    CoinConfig(symbol=coin, binance=f"{coin}USDT", tier=3, name=coin)
+                )
 
         return filtered
 
     def _setup_symbol_mapping(self):
         """Set up symbol to coin mapping based on exchange."""
-        exchange_type = self.EXCHANGES[self.exchange]['type']
+        exchange_type = self.EXCHANGES[self.exchange]["type"]
 
         for coin in self.coin_configs:
-            if exchange_type == 'bybit':
+            if exchange_type == "bybit":
                 # Bybit uses BTCUSDT format
                 symbol = f"{coin.symbol}USDT"
                 self._symbol_to_coin[symbol] = coin.symbol
             else:
                 # Binance uses btcusdt lowercase
                 symbol = coin.binance.lower()
                 self._symbol_to_coin[symbol] = coin.symbol
 
     def _get_ws_url(self) -> str:
         """Get WebSocket URL for the configured exchange."""
-        return self.EXCHANGES[self.exchange]['url']
+        return self.EXCHANGES[self.exchange]["url"]
 
     async def connect(self):
         """
         Connect to exchange WebSocket and start receiving data.
 
@@ -255,11 +250,11 @@
         await self._connect()
 
     async def _connect(self):
         """Internal connection method with reconnection logic."""
         url = self._get_ws_url()
-        exchange_type = self.EXCHANGES[self.exchange]['type']
+        exchange_type = self.EXCHANGES[self.exchange]["type"]
 
         while self._running:
             try:
                 logger.info(f"Connecting to {self.exchange} WebSocket...")
                 self.ws = await websockets.connect(
@@ -269,21 +264,28 @@
                     close_timeout=10,
                 )
 
                 self.status.connected = True
                 self.status.last_message_time = time.time()
-                self._reconnect_delay = self.config.get('websocket', {}).get('reconnect_delay_initial', 1.0)
+                self._reconnect_delay = self.config.get("websocket", {}).get(
+                    "reconnect_delay_initial", 1.0
+                )
 
                 # Subscribe to streams based on exchange type
-                if exchange_type == 'bybit':
+                if exchange_type == "bybit":
                     await self._subscribe_bybit()
                 else:
                     # Binance uses URL-based subscription
                     pass
 
-                logger.info(f"Connected to {self.exchange} ({len(self.coin_configs)} coins)")
-                self._emit_status('connected', {'exchange': self.exchange, 'coins': len(self.coin_configs)})
+                logger.info(
+                    f"Connected to {self.exchange} ({len(self.coin_configs)} coins)"
+                )
+                self._emit_status(
+                    "connected",
+                    {"exchange": self.exchange, "coins": len(self.coin_configs)},
+                )
 
                 # Start background tasks
                 self._listen_task = asyncio.create_task(self._listen(exchange_type))
                 self._ping_task = asyncio.create_task(self._ping_loop(exchange_type))
                 self._monitor_task = asyncio.create_task(self._monitor_connection())
@@ -292,17 +294,17 @@
 
             except (ConnectionClosed, WebSocketException, OSError) as e:
                 self.status.connected = False
                 self.status.errors += 1
                 logger.error(f"WebSocket error: {e}")
-                self._emit_status('disconnected', {'error': str(e)})
+                self._emit_status("disconnected", {"error": str(e)})
 
             except Exception as e:
                 self.status.connected = False
                 self.status.errors += 1
                 logger.exception(f"Unexpected error: {e}")
-                self._emit_status('error', {'error': str(e)})
+                self._emit_status("error", {"error": str(e)})
 
             # Cancel background tasks
             for task in [self._ping_task, self._monitor_task]:
                 if task and not task.done():
                     task.cancel()
@@ -312,15 +314,19 @@
                         pass
 
             # Reconnect if still running
             if self._running:
                 self.status.reconnect_count += 1
-                logger.info(f"Reconnecting in {self._reconnect_delay:.1f}s (attempt {self.status.reconnect_count})")
-                self._emit_status('reconnecting', {'delay': self._reconnect_delay})
+                logger.info(
+                    f"Reconnecting in {self._reconnect_delay:.1f}s (attempt {self.status.reconnect_count})"
+                )
+                self._emit_status("reconnecting", {"delay": self._reconnect_delay})
 
                 await asyncio.sleep(self._reconnect_delay)
-                self._reconnect_delay = min(self._reconnect_delay * 2, self._reconnect_delay_max)
+                self._reconnect_delay = min(
+                    self._reconnect_delay * 2, self._reconnect_delay_max
+                )
 
     async def _subscribe_bybit(self):
         """Subscribe to Bybit streams in batches (Bybit limits to 10 args per request)."""
         # Build all subscription args
         args = []
@@ -329,33 +335,34 @@
             args.append(f"tickers.{coin.symbol}USDT")
 
         # Batch into groups of 10 (Bybit limit)
         batch_size = 10
         for i in range(0, len(args), batch_size):
-            batch = args[i:i + batch_size]
-            subscribe_msg = {
-                "op": "subscribe",
-                "args": batch
-            }
+            batch = args[i : i + batch_size]
+            subscribe_msg = {"op": "subscribe", "args": batch}
             await self.ws.send(json.dumps(subscribe_msg))
-            logger.debug(f"Subscribed to batch {i//batch_size + 1}: {len(batch)} streams")
+            logger.debug(
+                f"Subscribed to batch {i//batch_size + 1}: {len(batch)} streams"
+            )
             # Small delay between batches to avoid rate limiting
             if i + batch_size < len(args):
                 await asyncio.sleep(0.1)
 
-        logger.info(f"Subscribed to {len(args)} Bybit streams in {(len(args) + batch_size - 1) // batch_size} batches")
+        logger.info(
+            f"Subscribed to {len(args)} Bybit streams in {(len(args) + batch_size - 1) // batch_size} batches"
+        )
 
     async def _listen(self, exchange_type: str):
         """Listen for WebSocket messages."""
         try:
             async for message in self.ws:
                 self.status.messages_received += 1
                 self.status.last_message_time = time.time()
 
                 try:
                     data = json.loads(message)
-                    if exchange_type == 'bybit':
+                    if exchange_type == "bybit":
                         await self._handle_bybit_message(data)
                     else:
                         await self._handle_binance_message(data)
                 except json.JSONDecodeError:
                     logger.warning(f"Invalid JSON: {message[:100]}")
@@ -391,56 +398,56 @@
                 "price24hPcnt": "0.0234",
                 "turnover24h": "1000000"
             }
         }
         """
-        topic = data.get('topic', '')
-
-        if topic.startswith('publicTrade.'):
-            for trade in data.get('data', []):
+        topic = data.get("topic", "")
+
+        if topic.startswith("publicTrade."):
+            for trade in data.get("data", []):
                 await self._handle_bybit_trade(trade)
-        elif topic.startswith('tickers.'):
-            await self._handle_bybit_ticker(data.get('data', {}))
-        elif data.get('op') == 'subscribe':
+        elif topic.startswith("tickers."):
+            await self._handle_bybit_ticker(data.get("data", {}))
+        elif data.get("op") == "subscribe":
             # Subscription confirmation
-            if data.get('success'):
+            if data.get("success"):
                 logger.debug("Bybit subscription confirmed")
             else:
                 logger.warning(f"Bybit subscription failed: {data}")
 
     async def _handle_bybit_trade(self, trade: dict):
         """Handle Bybit trade event."""
-        symbol = trade.get('s', '')
+        symbol = trade.get("s", "")
         coin = self._symbol_to_coin.get(symbol)
 
         if not coin:
             return
 
-        price = float(trade.get('p', 0))
-        quantity = float(trade.get('v', 0))
-        side = trade.get('S', '')
-        timestamp = int(trade.get('T', 0))
+        price = float(trade.get("p", 0))
+        quantity = float(trade.get("v", 0))
+        side = trade.get("S", "")
+        timestamp = int(trade.get("T", 0))
 
         # is_buyer_maker = True means the maker was a buyer (so taker sold)
-        is_buyer_maker = side == 'Sell'
+        is_buyer_maker = side == "Sell"
 
         trade_event = TradeEvent(
             coin=coin,
             price=price,
             quantity=quantity,
             is_buyer_maker=is_buyer_maker,
-            timestamp=timestamp
+            timestamp=timestamp,
         )
 
         # Update price cache
         ticker = self._ticker_data.get(coin, {})
         self.current_prices[coin] = PriceTick(
             coin=coin,
             price=price,
             timestamp=timestamp,
-            volume_24h=ticker.get('volume_24h', 0),
-            change_24h=ticker.get('change_24h', 0)
+            volume_24h=ticker.get("volume_24h", 0),
+            change_24h=ticker.get("change_24h", 0),
         )
 
         # Fire callbacks
         for callback in self._trade_callbacks:
             try:
@@ -454,62 +461,59 @@
             except Exception as e:
                 logger.error(f"Price callback error: {e}")
 
     async def _handle_bybit_ticker(self, data: dict):
         """Handle Bybit ticker update."""
-        symbol = data.get('symbol', '')
+        symbol = data.get("symbol", "")
         coin = self._symbol_to_coin.get(symbol)
 
         if not coin:
             return
 
-        change_pct = float(data.get('price24hPcnt', 0)) * 100  # Convert to percentage
-        volume = float(data.get('turnover24h', 0))
-
-        self._ticker_data[coin] = {
-            'volume_24h': volume,
-            'change_24h': change_pct
-        }
+        change_pct = float(data.get("price24hPcnt", 0)) * 100  # Convert to percentage
+        volume = float(data.get("turnover24h", 0))
+
+        self._ticker_data[coin] = {"volume_24h": volume, "change_24h": change_pct}
 
     async def _handle_binance_message(self, data: dict):
         """Handle Binance WebSocket message."""
-        stream = data.get('stream', '')
-        payload = data.get('data', {})
-
-        if '@trade' in stream:
+        stream = data.get("stream", "")
+        payload = data.get("data", {})
+
+        if "@trade" in stream:
             await self._handle_binance_trade(payload)
-        elif '@miniTicker' in stream:
+        elif "@miniTicker" in stream:
             await self._handle_binance_ticker(payload)
 
     async def _handle_binance_trade(self, data: dict):
         """Handle Binance trade event."""
-        symbol = data.get('s', '').lower()
+        symbol = data.get("s", "").lower()
         coin = self._symbol_to_coin.get(symbol)
 
         if not coin:
             return
 
-        price = float(data.get('p', 0))
-        quantity = float(data.get('q', 0))
-        timestamp = int(data.get('T', 0))
-        is_buyer_maker = data.get('m', False)
+        price = float(data.get("p", 0))
+        quantity = float(data.get("q", 0))
+        timestamp = int(data.get("T", 0))
+        is_buyer_maker = data.get("m", False)
 
         trade = TradeEvent(
             coin=coin,
             price=price,
             quantity=quantity,
             is_buyer_maker=is_buyer_maker,
-            timestamp=timestamp
+            timestamp=timestamp,
         )
 
         ticker = self._ticker_data.get(coin, {})
         self.current_prices[coin] = PriceTick(
             coin=coin,
             price=price,
             timestamp=timestamp,
-            volume_24h=ticker.get('volume_24h', 0),
-            change_24h=ticker.get('change_24h', 0)
+            volume_24h=ticker.get("volume_24h", 0),
+            change_24h=ticker.get("change_24h", 0),
         )
 
         for callback in self._trade_callbacks:
             try:
                 callback(trade)
@@ -522,34 +526,31 @@
             except Exception as e:
                 logger.error(f"Price callback error: {e}")
 
     async def _handle_binance_ticker(self, data: dict):
         """Handle Binance mini ticker."""
-        symbol = data.get('s', '').lower()
+        symbol = data.get("s", "").lower()
         coin = self._symbol_to_coin.get(symbol)
 
         if not coin:
             return
 
-        close = float(data.get('c', 0))
-        open_price = float(data.get('o', 0))
-        volume = float(data.get('q', 0))
+        close = float(data.get("c", 0))
+        open_price = float(data.get("o", 0))
+        volume = float(data.get("q", 0))
 
         change_24h = ((close - open_price) / open_price * 100) if open_price > 0 else 0
 
-        self._ticker_data[coin] = {
-            'volume_24h': volume,
-            'change_24h': change_24h
-        }
+        self._ticker_data[coin] = {"volume_24h": volume, "change_24h": change_24h}
 
     async def _ping_loop(self, exchange_type: str):
         """Send periodic pings to keep connection alive."""
         while self._running and self.ws:
             try:
                 await asyncio.sleep(self._ping_interval)
                 if self.ws and self.ws.open:
-                    if exchange_type == 'bybit':
+                    if exchange_type == "bybit":
                         # Bybit uses JSON ping
                         await self.ws.send(json.dumps({"op": "ping"}))
                     else:
                         await self.ws.ping()
             except Exception as e:
@@ -563,11 +564,11 @@
 
             if self.status.last_message_time:
                 elapsed = time.time() - self.status.last_message_time
                 if elapsed > self._stale_threshold:
                     logger.warning(f"Feed stale: no data for {elapsed:.1f}s")
-                    self._emit_status('stale', {'seconds': elapsed})
+                    self._emit_status("stale", {"seconds": elapsed})
 
     def subscribe_price(self, callback: Callable[[PriceTick], None]):
         """Subscribe to price updates."""
         self._price_callbacks.append(callback)
         logger.debug(f"Price callback registered (total: {len(self._price_callbacks)})")
@@ -617,21 +618,22 @@
         logger.info("MarketFeed disconnected")
 
     def get_status(self) -> dict:
         """Get current feed status."""
         return {
-            'connected': self.status.connected,
-            'exchange': self.status.exchange,
-            'coins': len(self.coin_configs),
-            'messages_received': self.status.messages_received,
-            'reconnect_count': self.status.reconnect_count,
-            'errors': self.status.errors,
-            'prices_cached': len(self.current_prices),
-            'last_message_age': (
+            "connected": self.status.connected,
+            "exchange": self.status.exchange,
+            "coins": len(self.coin_configs),
+            "messages_received": self.status.messages_received,
+            "reconnect_count": self.status.reconnect_count,
+            "errors": self.status.errors,
+            "prices_cached": len(self.current_prices),
+            "last_message_age": (
                 time.time() - self.status.last_message_time
-                if self.status.last_message_time else None
-            )
+                if self.status.last_message_time
+                else None
+            ),
         }
 
     def get_health(self) -> dict:
         """Get component health status for monitoring.
 
@@ -639,11 +641,12 @@
             Dict with status (healthy/degraded/failed), last_activity, error_count, metrics.
         """
         now = time.time()
         last_msg_age = (
             now - self.status.last_message_time
-            if self.status.last_message_time else None
+            if self.status.last_message_time
+            else None
         )
 
         # Determine health status
         if not self.status.connected:
             status = "failed"
@@ -654,33 +657,41 @@
         else:
             status = "healthy"
 
         return {
             "status": status,
-            "last_activity": datetime.fromtimestamp(
-                self.status.last_message_time
-            ).isoformat() if self.status.last_message_time else None,
+            "last_activity": (
+                datetime.fromtimestamp(self.status.last_message_time).isoformat()
+                if self.status.last_message_time
+                else None
+            ),
             "error_count": self.status.errors,
             "metrics": {
                 "connected": self.status.connected,
                 "exchange": self.status.exchange,
                 "messages_received": self.status.messages_received,
                 "reconnect_count": self.status.reconnect_count,
-                "last_message_age_seconds": round(last_msg_age, 2) if last_msg_age else None,
+                "last_message_age_seconds": (
+                    round(last_msg_age, 2) if last_msg_age else None
+                ),
                 "coins_with_prices": len(self.current_prices),
-            }
+            },
         }
 
 
-async def test_feed(coins: list[str] = ['BTC', 'ETH', 'SOL'], duration: int = 30, exchange: str = 'bybit'):
+async def test_feed(
+    coins: list[str] = ["BTC", "ETH", "SOL"],
+    duration: int = 30,
+    exchange: str = "bybit",
+):
     """Test the market feed."""
     feed = MarketFeed(coins, exchange=exchange)
-    count = {'trades': 0}
+    count = {"trades": 0}
 
     def on_price(tick: PriceTick):
-        count['trades'] += 1
-        if count['trades'] % 5 == 0:
+        count["trades"] += 1
+        if count["trades"] % 5 == 0:
             print(f"{tick.coin}: ${tick.price:,.2f} ({tick.change_24h:+.2f}%)")
 
     def on_status(event: str, details: dict):
         print(f"[STATUS] {event}: {details}")
 
@@ -700,11 +711,11 @@
             print(f"  {coin}: ${price.price:,.2f}")
 
     await asyncio.gather(run(), stop())
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     logging.basicConfig(
         level=logging.INFO,
-        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
     )
     asyncio.run(test_feed())
would reformat /mnt/c/documents/crypto-trading-bot/src/market_feed.py
--- /mnt/c/documents/crypto-trading-bot/src/technical/orderbook.py	2026-02-04 15:31:46.889343+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/orderbook.py	2026-02-04 21:34:25.262045+00:00
@@ -1,6 +1,7 @@
 """Order Book analysis for bid/ask imbalance and wall detection."""
+
 import logging
 import time
 from dataclasses import dataclass, field
 from datetime import datetime, timezone
 from typing import List, Optional, Dict, Any
@@ -11,14 +12,15 @@
 
 
 @dataclass
 class PriceWall:
     """A significant order at a price level."""
+
     price: float
     size: float
-    side: str                       # "bid" or "ask"
-    distance_pct: float             # Distance from current price
+    side: str  # "bid" or "ask"
+    distance_pct: float  # Distance from current price
 
     @property
     def is_bid_wall(self) -> bool:
         """Wall is on bid side (support)."""
         return self.side == "bid"
@@ -30,17 +32,18 @@
 
 
 @dataclass
 class OrderBookDepth:
     """Order book analysis result."""
+
     coin: str
-    bid_volume: float               # Total bid volume
-    ask_volume: float               # Total ask volume
-    imbalance: float                # (bid - ask) / (bid + ask), -1 to +1
-    bid_walls: List[PriceWall]      # Large bid orders
-    ask_walls: List[PriceWall]      # Large ask orders
-    spread_pct: float               # Bid-ask spread as percentage
+    bid_volume: float  # Total bid volume
+    ask_volume: float  # Total ask volume
+    imbalance: float  # (bid - ask) / (bid + ask), -1 to +1
+    bid_walls: List[PriceWall]  # Large bid orders
+    ask_walls: List[PriceWall]  # Large ask orders
+    spread_pct: float  # Bid-ask spread as percentage
     best_bid: float
     best_ask: float
     mid_price: float
     timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
 
@@ -114,14 +117,11 @@
         """
         self.wall_multiplier = wall_multiplier
         self._cache: Dict[str, tuple[OrderBookDepth, float]] = {}
 
     def analyze(
-        self,
-        coin: str,
-        depth: int = 50,
-        use_cache: bool = True
+        self, coin: str, depth: int = 50, use_cache: bool = True
     ) -> OrderBookDepth:
         """Analyze order book for a coin.
 
         Args:
             coin: Coin symbol (e.g., "BTC", "ETH")
@@ -144,13 +144,13 @@
             response = requests.get(
                 self.BASE_URL,
                 params={
                     "category": "linear",
                     "symbol": symbol,
-                    "limit": min(depth, 200)
+                    "limit": min(depth, 200),
                 },
-                timeout=5
+                timeout=5,
             )
             response.raise_for_status()
 
             data = response.json()
             result = self._parse_response(coin_upper, data)
@@ -181,14 +181,11 @@
         if total == 0:
             return 0.0
         return (bid_volume - ask_volume) / total
 
     def detect_walls(
-        self,
-        orders: List[tuple[float, float]],
-        side: str,
-        mid_price: float
+        self, orders: List[tuple[float, float]], side: str, mid_price: float
     ) -> List[PriceWall]:
         """Detect large orders (walls) in order book.
 
         Args:
             orders: List of (price, size) tuples
@@ -207,17 +204,18 @@
         threshold = avg_size * self.wall_multiplier
 
         walls = []
         for price, size in orders:
             if size > threshold:
-                distance_pct = abs((price - mid_price) / mid_price * 100) if mid_price else 0
-                walls.append(PriceWall(
-                    price=price,
-                    size=size,
-                    side=side,
-                    distance_pct=distance_pct
-                ))
+                distance_pct = (
+                    abs((price - mid_price) / mid_price * 100) if mid_price else 0
+                )
+                walls.append(
+                    PriceWall(
+                        price=price, size=size, side=side, distance_pct=distance_pct
+                    )
+                )
 
         return walls
 
     def get_spread(self, best_bid: float, best_ask: float) -> float:
         """Calculate spread as percentage.
@@ -272,11 +270,11 @@
             ask_walls=ask_walls,
             spread_pct=spread_pct,
             best_bid=best_bid,
             best_ask=best_ask,
             mid_price=mid_price,
-            timestamp=datetime.now(timezone.utc)
+            timestamp=datetime.now(timezone.utc),
         )
 
     def _empty_depth(self, coin: str) -> OrderBookDepth:
         """Return empty depth when API fails."""
         return OrderBookDepth(
@@ -288,7 +286,7 @@
             ask_walls=[],
             spread_pct=0.0,
             best_bid=0.0,
             best_ask=0.0,
             mid_price=0.0,
-            timestamp=datetime.now(timezone.utc)
+            timestamp=datetime.now(timezone.utc),
         )
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/orderbook.py
--- /mnt/c/documents/crypto-trading-bot/src/pattern_library.py	2026-02-03 16:54:56.919497+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/pattern_library.py	2026-02-04 21:34:25.264374+00:00
@@ -29,40 +29,42 @@
 # Minimum uses before confidence is meaningful
 MIN_USES_FOR_CONFIDENCE = 3
 
 # Position modifiers based on confidence
 CONFIDENCE_MODIFIERS = {
-    "high": 1.25,      # >= 0.7
-    "medium": 1.0,     # 0.5 - 0.7
-    "low": 0.75,       # 0.3 - 0.5
-    "very_low": 0.0,   # < 0.3 (deactivated)
+    "high": 1.25,  # >= 0.7
+    "medium": 1.0,  # 0.5 - 0.7
+    "low": 0.75,  # 0.3 - 0.5
+    "very_low": 0.0,  # < 0.3 (deactivated)
 }
 
 
 @dataclass
 class PatternMatch:
     """Result of matching market conditions to a pattern."""
+
     pattern: TradingPattern
-    match_score: float              # 0-1, how well conditions match
-    matched_conditions: Dict[str, Any]   # Which conditions were satisfied
-    missing_conditions: Dict[str, Any]   # Which conditions were not satisfied
+    match_score: float  # 0-1, how well conditions match
+    matched_conditions: Dict[str, Any]  # Which conditions were satisfied
+    missing_conditions: Dict[str, Any]  # Which conditions were not satisfied
 
     @property
     def is_full_match(self) -> bool:
         """Check if all conditions matched."""
         return len(self.missing_conditions) == 0
 
 
 @dataclass
 class PatternSuggestion:
     """A pattern suggestion for the Strategist."""
+
     pattern: TradingPattern
-    suggested_direction: str        # "LONG" or "SHORT"
+    suggested_direction: str  # "LONG" or "SHORT"
     suggested_entry: Dict[str, Any]  # Entry parameters
-    suggested_exit: Dict[str, Any]   # Exit parameters
-    confidence: float               # Overall confidence
-    reasoning: str                  # Why this pattern applies
+    suggested_exit: Dict[str, Any]  # Exit parameters
+    confidence: float  # Overall confidence
+    reasoning: str  # Why this pattern applies
 
 
 # Seed patterns for initial library
 SEED_PATTERNS = [
     {
@@ -135,11 +137,13 @@
 
         # Seed patterns if empty
         if seed_patterns and len(brain.get_active_patterns()) == 0:
             self._seed_patterns()
 
-        logger.info(f"PatternLibrary initialized: {len(self.brain.get_active_patterns())} active patterns")
+        logger.info(
+            f"PatternLibrary initialized: {len(self.brain.get_active_patterns())} active patterns"
+        )
 
     def _seed_patterns(self) -> None:
         """Add seed patterns to empty library."""
         for seed in SEED_PATTERNS:
             pattern = TradingPattern(
@@ -173,21 +177,24 @@
         Returns:
             List of active TradingPattern objects.
         """
         return self.brain.get_active_patterns()
 
-    def get_high_confidence_patterns(self, min_confidence: float = HIGH_CONFIDENCE) -> List[TradingPattern]:
+    def get_high_confidence_patterns(
+        self, min_confidence: float = HIGH_CONFIDENCE
+    ) -> List[TradingPattern]:
         """Get patterns with high confidence.
 
         Args:
             min_confidence: Minimum confidence threshold (default: 0.7).
 
         Returns:
             List of high-confidence patterns sorted by confidence.
         """
         patterns = [
-            p for p in self.brain.get_active_patterns()
+            p
+            for p in self.brain.get_active_patterns()
             if p.confidence >= min_confidence
         ]
         return sorted(patterns, key=lambda p: p.confidence, reverse=True)
 
     def get_patterns_by_type(self, pattern_type: str) -> List[TradingPattern]:
@@ -198,12 +205,11 @@
 
         Returns:
             List of matching patterns.
         """
         return [
-            p for p in self.brain.get_active_patterns()
-            if pattern_type in p.pattern_id
+            p for p in self.brain.get_active_patterns() if pattern_type in p.pattern_id
         ]
 
     # =========================================================================
     # Pattern Creation
     # =========================================================================
@@ -212,11 +218,11 @@
         self,
         pattern_type: str,
         description: str,
         entry_conditions: Dict[str, Any],
         exit_conditions: Dict[str, Any],
-        source_trade_id: Optional[str] = None
+        source_trade_id: Optional[str] = None,
     ) -> TradingPattern:
         """Create a new pattern.
 
         Args:
             pattern_type: Type of pattern (e.g., "breakout", "support_bounce").
@@ -243,11 +249,13 @@
         self.brain.add_pattern(pattern)
         logger.info(f"Created pattern: {pattern_id} - {description}")
 
         return pattern
 
-    def create_pattern_from_trade(self, trade: Dict[str, Any]) -> Optional[TradingPattern]:
+    def create_pattern_from_trade(
+        self, trade: Dict[str, Any]
+    ) -> Optional[TradingPattern]:
         """Extract a pattern from a successful trade.
 
         Only creates patterns from winning trades with sufficient context.
 
         Args:
@@ -281,22 +289,32 @@
         if trade.get("btc_trend"):
             entry_conditions["btc_trend"] = trade["btc_trend"]
 
         # Volatility context
         if trade.get("volatility"):
-            entry_conditions["volatility_level"] = self._get_volatility_level(trade["volatility"])
+            entry_conditions["volatility_level"] = self._get_volatility_level(
+                trade["volatility"]
+            )
 
         # Exit conditions from trade
         exit_conditions = {}
         if trade.get("stop_loss_price") and trade.get("entry_price"):
-            stop_pct = abs(trade["stop_loss_price"] - trade["entry_price"]) / trade["entry_price"] * 100
+            stop_pct = (
+                abs(trade["stop_loss_price"] - trade["entry_price"])
+                / trade["entry_price"]
+                * 100
+            )
             exit_conditions["stop_loss_pct"] = round(stop_pct, 1)
         else:
             exit_conditions["stop_loss_pct"] = 2.0  # Default
 
         if trade.get("take_profit_price") and trade.get("entry_price"):
-            tp_pct = abs(trade["take_profit_price"] - trade["entry_price"]) / trade["entry_price"] * 100
+            tp_pct = (
+                abs(trade["take_profit_price"] - trade["entry_price"])
+                / trade["entry_price"]
+                * 100
+            )
             exit_conditions["take_profit_pct"] = round(tp_pct, 1)
         else:
             exit_conditions["take_profit_pct"] = 2.0  # Default
 
         # Generate description
@@ -338,11 +356,13 @@
         elif volatility < 3.0:
             return "medium"
         else:
             return "high"
 
-    def _generate_description(self, trade: Dict[str, Any], conditions: Dict[str, Any]) -> str:
+    def _generate_description(
+        self, trade: Dict[str, Any], conditions: Dict[str, Any]
+    ) -> str:
         """Generate human-readable pattern description."""
         direction = conditions.get("direction", "LONG")
         coin = trade.get("coin", "unknown")
         regime = conditions.get("market_regime", "")
         hour_range = conditions.get("hour_range", "")
@@ -376,11 +396,13 @@
                 matches.append(match)
 
         # Sort by match score descending
         return sorted(matches, key=lambda m: m.match_score, reverse=True)
 
-    def _match_single_pattern(self, pattern: TradingPattern, market_state: Dict[str, Any]) -> PatternMatch:
+    def _match_single_pattern(
+        self, pattern: TradingPattern, market_state: Dict[str, Any]
+    ) -> PatternMatch:
         """Match market state against a single pattern.
 
         Args:
             pattern: Pattern to match against.
             market_state: Current market conditions.
@@ -450,11 +472,13 @@
                 return False
 
         # Direct equality
         return actual == required
 
-    def find_similar_patterns(self, conditions: Dict[str, Any], min_similarity: float = 0.5) -> List[TradingPattern]:
+    def find_similar_patterns(
+        self, conditions: Dict[str, Any], min_similarity: float = 0.5
+    ) -> List[TradingPattern]:
         """Find patterns with similar entry conditions.
 
         Args:
             conditions: Conditions to compare.
             min_similarity: Minimum similarity score (0-1).
@@ -463,17 +487,21 @@
             List of similar patterns.
         """
         similar = []
 
         for pattern in self.brain.get_active_patterns():
-            similarity = self._calculate_similarity(pattern.entry_conditions, conditions)
+            similarity = self._calculate_similarity(
+                pattern.entry_conditions, conditions
+            )
             if similarity >= min_similarity:
                 similar.append(pattern)
 
         return similar
 
-    def _calculate_similarity(self, conditions1: Dict[str, Any], conditions2: Dict[str, Any]) -> float:
+    def _calculate_similarity(
+        self, conditions1: Dict[str, Any], conditions2: Dict[str, Any]
+    ) -> float:
         """Calculate similarity between two condition sets."""
         all_keys = set(conditions1.keys()) | set(conditions2.keys())
         if not all_keys:
             return 0.0
 
@@ -505,11 +533,13 @@
 
         # Check for deactivation
         if new_confidence < DEACTIVATE_THRESHOLD:
             pattern = self.brain.get_pattern(pattern_id)
             if pattern and pattern.times_used >= MIN_USES_FOR_CONFIDENCE:
-                self.deactivate_pattern(pattern_id, f"Confidence dropped to {new_confidence:.2f}")
+                self.deactivate_pattern(
+                    pattern_id, f"Confidence dropped to {new_confidence:.2f}"
+                )
 
     def update_confidence(self, pattern_id: str) -> float:
         """Recalculate and update confidence for a pattern.
 
         Args:
@@ -591,11 +621,13 @@
             Dictionary with categorized patterns and suggestions.
         """
         active = self.brain.get_active_patterns()
 
         high_confidence = [p for p in active if p.confidence >= HIGH_CONFIDENCE]
-        medium_confidence = [p for p in active if MEDIUM_CONFIDENCE <= p.confidence < HIGH_CONFIDENCE]
+        medium_confidence = [
+            p for p in active if MEDIUM_CONFIDENCE <= p.confidence < HIGH_CONFIDENCE
+        ]
 
         return {
             "high_confidence": high_confidence,
             "medium_confidence": medium_confidence,
             "total_active": len(active),
@@ -609,11 +641,13 @@
                 }
                 for p in sorted(active, key=lambda x: x.confidence, reverse=True)[:10]
             ],
         }
 
-    def get_suggested_patterns(self, coin: str, market_state: Dict[str, Any]) -> List[PatternSuggestion]:
+    def get_suggested_patterns(
+        self, coin: str, market_state: Dict[str, Any]
+    ) -> List[PatternSuggestion]:
         """Get pattern suggestions for current market conditions.
 
         Args:
             coin: Coin being considered.
             market_state: Current market conditions.
@@ -693,18 +727,21 @@
                 "avg_win_rate": 0.0,
                 "total_uses": 0,
             }
 
         high = sum(1 for p in active if p.confidence >= HIGH_CONFIDENCE)
-        medium = sum(1 for p in active if MEDIUM_CONFIDENCE <= p.confidence < HIGH_CONFIDENCE)
+        medium = sum(
+            1 for p in active if MEDIUM_CONFIDENCE <= p.confidence < HIGH_CONFIDENCE
+        )
         low = sum(1 for p in active if p.confidence < MEDIUM_CONFIDENCE)
 
         total_uses = sum(p.times_used for p in active)
         patterns_with_data = [p for p in active if p.times_used > 0]
         avg_win_rate = (
             sum(p.win_rate for p in patterns_with_data) / len(patterns_with_data)
-            if patterns_with_data else 0.0
+            if patterns_with_data
+            else 0.0
         )
 
         return {
             "total_patterns": len(active),
             "high_confidence": high,
would reformat /mnt/c/documents/crypto-trading-bot/src/pattern_library.py
--- /mnt/c/documents/crypto-trading-bot/src/technical/volume_profile.py	2026-02-04 15:31:20.366136+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/volume_profile.py	2026-02-04 21:34:25.269136+00:00
@@ -1,6 +1,7 @@
 """Volume Profile analysis for identifying key price levels."""
+
 import logging
 from dataclasses import dataclass, field
 from datetime import datetime
 from typing import List, Optional
 from collections import defaultdict
@@ -11,24 +12,26 @@
 
 
 @dataclass
 class VolumeLevel:
     """A price level with associated volume."""
+
     price: float
     volume: float
-    pct_of_total: float             # Percentage of total volume
+    pct_of_total: float  # Percentage of total volume
 
 
 @dataclass
 class VolumeProfile:
     """Volume profile analysis result."""
+
     coin: str
-    poc: float                      # Point of Control (highest volume price)
-    value_area_high: float          # Top of Value Area (70% of volume)
-    value_area_low: float           # Bottom of Value Area
-    hvn_levels: List[float]         # High Volume Nodes
-    lvn_levels: List[float]         # Low Volume Nodes
+    poc: float  # Point of Control (highest volume price)
+    value_area_high: float  # Top of Value Area (70% of volume)
+    value_area_low: float  # Bottom of Value Area
+    hvn_levels: List[float]  # High Volume Nodes
+    lvn_levels: List[float]  # Low Volume Nodes
     current_price: float
     total_volume: float
     timestamp: datetime = field(default_factory=datetime.now)
 
     @property
@@ -55,11 +58,13 @@
     @property
     def value_area_width_pct(self) -> float:
         """Width of value area as percentage."""
         if self.value_area_low == 0:
             return 0.0
-        return ((self.value_area_high - self.value_area_low) / self.value_area_low) * 100
+        return (
+            (self.value_area_high - self.value_area_low) / self.value_area_low
+        ) * 100
 
     @property
     def nearest_hvn(self) -> Optional[float]:
         """Nearest high volume node to current price."""
         if not self.hvn_levels:
@@ -94,11 +99,11 @@
 
     def __init__(
         self,
         candle_fetcher: CandleFetcher,
         num_levels: int = 50,
-        value_area_pct: float = 0.70
+        value_area_pct: float = 0.70,
     ):
         """Initialize Volume Profile calculator.
 
         Args:
             candle_fetcher: CandleFetcher instance for getting price data
@@ -108,14 +113,11 @@
         self.candle_fetcher = candle_fetcher
         self.num_levels = num_levels
         self.value_area_pct = value_area_pct
 
     def calculate(
-        self,
-        coin: str,
-        timeframe: str = "1h",
-        limit: int = 200
+        self, coin: str, timeframe: str = "1h", limit: int = 200
     ) -> VolumeProfile:
         """Calculate volume profile for a coin.
 
         Args:
             coin: Coin symbol (e.g., "BTC", "ETH")
@@ -158,14 +160,16 @@
             value_area_low=value_area_low,
             hvn_levels=hvn_levels,
             lvn_levels=lvn_levels,
             current_price=current_price,
             total_volume=total_volume,
-            timestamp=datetime.now()
+            timestamp=datetime.now(),
         )
 
-    def calculate_from_candles(self, candles: List[Candle], coin: str = "UNKNOWN") -> VolumeProfile:
+    def calculate_from_candles(
+        self, candles: List[Candle], coin: str = "UNKNOWN"
+    ) -> VolumeProfile:
         """Calculate volume profile from a list of candles.
 
         Useful for testing or when you already have candle data.
 
         Args:
@@ -197,11 +201,11 @@
             value_area_low=value_area_low,
             hvn_levels=hvn_levels,
             lvn_levels=lvn_levels,
             current_price=current_price,
             total_volume=total_volume,
-            timestamp=datetime.now()
+            timestamp=datetime.now(),
         )
 
     def _build_volume_distribution(self, candles: List[Candle]) -> dict[float, float]:
         """Build volume distribution across price levels."""
         if not candles:
@@ -222,25 +226,20 @@
         # Distribute volume across levels
         volume_dist: dict[float, float] = defaultdict(float)
 
         for candle in candles:
             # Distribute candle volume across its price range
-            candle_levels = self._get_candle_levels(
-                candle, price_low, level_size
-            )
+            candle_levels = self._get_candle_levels(candle, price_low, level_size)
             vol_per_level = candle.volume / len(candle_levels) if candle_levels else 0
 
             for level in candle_levels:
                 volume_dist[level] += vol_per_level
 
         return dict(volume_dist)
 
     def _get_candle_levels(
-        self,
-        candle: Candle,
-        price_low: float,
-        level_size: float
+        self, candle: Candle, price_low: float, level_size: float
     ) -> List[float]:
         """Get price levels that a candle spans."""
         if level_size == 0:
             return [candle.close]
 
@@ -259,12 +258,11 @@
         if not volume_dist:
             return 0.0
         return max(volume_dist.keys(), key=lambda x: volume_dist[x])
 
     def _calculate_value_area(
-        self,
-        volume_dist: dict[float, float]
+        self, volume_dist: dict[float, float]
     ) -> tuple[float, float]:
         """Calculate Value Area (70% of volume centered on POC)."""
         if not volume_dist:
             return 0.0, 0.0
 
@@ -272,11 +270,15 @@
         target_volume = total_volume * self.value_area_pct
 
         # Sort levels by price
         sorted_levels = sorted(volume_dist.keys())
         poc = self._calculate_poc(volume_dist)
-        poc_idx = sorted_levels.index(poc) if poc in sorted_levels else len(sorted_levels) // 2
+        poc_idx = (
+            sorted_levels.index(poc)
+            if poc in sorted_levels
+            else len(sorted_levels) // 2
+        )
 
         # Expand from POC until we have 70% of volume
         accumulated_volume = volume_dist.get(poc, 0)
         low_idx = poc_idx
         high_idx = poc_idx
@@ -287,12 +289,16 @@
             can_go_higher = high_idx < len(sorted_levels) - 1
 
             if not can_go_lower and not can_go_higher:
                 break
 
-            lower_vol = volume_dist.get(sorted_levels[low_idx - 1], 0) if can_go_lower else 0
-            higher_vol = volume_dist.get(sorted_levels[high_idx + 1], 0) if can_go_higher else 0
+            lower_vol = (
+                volume_dist.get(sorted_levels[low_idx - 1], 0) if can_go_lower else 0
+            )
+            higher_vol = (
+                volume_dist.get(sorted_levels[high_idx + 1], 0) if can_go_higher else 0
+            )
 
             if lower_vol >= higher_vol and can_go_lower:
                 low_idx -= 1
                 accumulated_volume += lower_vol
             elif can_go_higher:
@@ -337,7 +343,7 @@
             value_area_low=current_price,
             hvn_levels=[],
             lvn_levels=[],
             current_price=current_price,
             total_volume=0.0,
-            timestamp=datetime.now()
+            timestamp=datetime.now(),
         )
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/volume_profile.py
--- /mnt/c/documents/crypto-trading-bot/src/trading_engine.py	2026-01-14 16:36:51.900901+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/trading_engine.py	2026-02-04 21:34:25.285890+00:00
@@ -13,19 +13,19 @@
 from src.risk_manager import RiskManager
 from src.learning_system import RuleManager
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 
 @dataclass
 class TradeResult:
     """Result of a trade execution attempt."""
+
     success: bool
     trade_id: Optional[int]
     message: str
 
 
@@ -57,23 +57,20 @@
         Returns:
             Current price in USD, or None if no data exists.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute(
-                "SELECT price_usd FROM market_data WHERE coin = ?",
-                (coin,)
-            )
+            cursor.execute("SELECT price_usd FROM market_data WHERE coin = ?", (coin,))
             row = cursor.fetchone()
             return row[0] if row else None
 
     def execute_buy(
         self,
         coin: str,
         size_usd: float,
         reason: str,
-        rule_ids: Optional[List[int]] = None
+        rule_ids: Optional[List[int]] = None,
     ) -> TradeResult:
         """Execute a paper BUY order.
 
         Args:
             coin: Cryptocurrency to buy (e.g., 'bitcoin').
@@ -87,60 +84,78 @@
         logger.info(f"Attempting BUY: {coin} ${size_usd:.2f} - {reason}")
 
         # Step 1: Get current price from market_data (MUST exist)
         current_price = self.get_current_price(coin)
         if current_price is None:
-            message = f"No market data for {coin}. Cannot execute trade without real price."
+            message = (
+                f"No market data for {coin}. Cannot execute trade without real price."
+            )
             logger.warning(message)
             self.db.log_activity("trade_rejected", message)
             return TradeResult(success=False, trade_id=None, message=message)
 
         # Step 2: Validate with RiskManager (REJECT if invalid, don't auto-reduce)
         validation = self.risk_manager.validate_trade(coin, size_usd, "BUY")
         if not validation.valid:
             logger.warning(f"Trade rejected: {validation.reason}")
-            self.db.log_activity("trade_rejected", f"BUY {coin} ${size_usd:.2f}: {validation.reason}")
+            self.db.log_activity(
+                "trade_rejected", f"BUY {coin} ${size_usd:.2f}: {validation.reason}"
+            )
             return TradeResult(success=False, trade_id=None, message=validation.reason)
 
         # Step 3: Calculate stop loss and take profit
         stop_loss_price = self.risk_manager.calculate_stop_loss(current_price)
-        take_profit_price = self.risk_manager.calculate_take_profit(current_price, size_usd)
+        take_profit_price = self.risk_manager.calculate_take_profit(
+            current_price, size_usd
+        )
 
         # Step 4: Insert into open_trades
-        rule_ids_str = ','.join(str(r) for r in rule_ids) if rule_ids else None
-
-        with self.db._get_connection() as conn:
-            cursor = conn.cursor()
-
-            cursor.execute("""
+        rule_ids_str = ",".join(str(r) for r in rule_ids) if rule_ids else None
+
+        with self.db._get_connection() as conn:
+            cursor = conn.cursor()
+
+            cursor.execute(
+                """
                 INSERT INTO open_trades (
                     coin_name, entry_price, size_usd, current_price,
                     unrealized_pnl, unrealized_pnl_pct, stop_loss_price,
                     take_profit_price, entry_reason, opened_at, rule_ids_used
                 ) VALUES (?, ?, ?, ?, 0, 0, ?, ?, ?, datetime('now'), ?)
-            """, (
-                coin, current_price, size_usd, current_price,
-                stop_loss_price, take_profit_price, reason, rule_ids_str
-            ))
+            """,
+                (
+                    coin,
+                    current_price,
+                    size_usd,
+                    current_price,
+                    stop_loss_price,
+                    take_profit_price,
+                    reason,
+                    rule_ids_str,
+                ),
+            )
 
             trade_id = cursor.lastrowid
 
             # Step 5: Update account_state
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE account_state SET
                     available_balance = available_balance - ?,
                     in_positions = in_positions + ?
                 WHERE id = 1
-            """, (size_usd, size_usd))
+            """,
+                (size_usd, size_usd),
+            )
 
             conn.commit()
 
         # Step 6: Log activity
         self.db.log_activity(
             "trade_opened",
             f"BUY {coin} ${size_usd:.2f} @ ${current_price:.2f}",
-            f"trade_id={trade_id}, stop_loss=${stop_loss_price:.2f}, take_profit=${take_profit_price:.2f}"
+            f"trade_id={trade_id}, stop_loss=${stop_loss_price:.2f}, take_profit=${take_profit_price:.2f}",
         )
 
         message = f"Opened trade #{trade_id}: BUY {coin} ${size_usd:.2f} @ ${current_price:.2f}"
         logger.info(message)
 
@@ -164,79 +179,97 @@
             message = f"Trade #{trade_id} not found in open_trades"
             logger.warning(message)
             return TradeResult(success=False, trade_id=trade_id, message=message)
 
         # Step 2: Get current price
-        current_price = self.get_current_price(trade['coin_name'])
+        current_price = self.get_current_price(trade["coin_name"])
         if current_price is None:
             # Use the last known current_price from the trade record
-            current_price = trade['current_price']
-            logger.warning(f"No market data for {trade['coin_name']}, using last known price ${current_price:.2f}")
+            current_price = trade["current_price"]
+            logger.warning(
+                f"No market data for {trade['coin_name']}, using last known price ${current_price:.2f}"
+            )
 
         # Step 3: Calculate final P&L
-        entry_price = trade['entry_price']
-        size_usd = trade['size_usd']
+        entry_price = trade["entry_price"]
+        size_usd = trade["size_usd"]
         price_change_pct = (current_price - entry_price) / entry_price
         pnl_usd = size_usd * price_change_pct
         pnl_pct = price_change_pct * 100
 
         # Step 4: Calculate duration
-        opened_at = datetime.fromisoformat(trade['opened_at'].replace(' ', 'T'))
+        opened_at = datetime.fromisoformat(trade["opened_at"].replace(" ", "T"))
         closed_at = datetime.now()
         duration_seconds = int((closed_at - opened_at).total_seconds())
 
         # Step 5: Move from open_trades to closed_trades
-        rule_ids_used = trade.get('rule_ids_used')
+        rule_ids_used = trade.get("rule_ids_used")
 
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
 
             # Insert into closed_trades (including rule_ids_used)
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT INTO closed_trades (
                     coin_name, entry_price, exit_price, size_usd,
                     pnl_usd, pnl_pct, entry_reason, exit_reason,
                     opened_at, closed_at, duration_seconds, rule_ids_used
                 ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'), ?, ?)
-            """, (
-                trade['coin_name'], entry_price, current_price, size_usd,
-                pnl_usd, pnl_pct, trade['entry_reason'], exit_reason,
-                trade['opened_at'], duration_seconds, rule_ids_used
-            ))
+            """,
+                (
+                    trade["coin_name"],
+                    entry_price,
+                    current_price,
+                    size_usd,
+                    pnl_usd,
+                    pnl_pct,
+                    trade["entry_reason"],
+                    exit_reason,
+                    trade["opened_at"],
+                    duration_seconds,
+                    rule_ids_used,
+                ),
+            )
 
             # Delete from open_trades
             cursor.execute("DELETE FROM open_trades WHERE id = ?", (trade_id,))
 
             # Update account_state
             # Balance changes by P&L, available_balance gets size back + P&L
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE account_state SET
                     balance = balance + ?,
                     available_balance = available_balance + ? + ?,
                     in_positions = in_positions - ?,
                     total_pnl = total_pnl + ?,
                     daily_pnl = daily_pnl + ?,
                     trade_count_today = trade_count_today + 1
                 WHERE id = 1
-            """, (pnl_usd, size_usd, pnl_usd, size_usd, pnl_usd, pnl_usd))
+            """,
+                (pnl_usd, size_usd, pnl_usd, size_usd, pnl_usd, pnl_usd),
+            )
 
             conn.commit()
 
         # Step 6: Record rule outcomes (if any rules were used)
         if rule_ids_used:
             trade_success = pnl_usd >= 0
-            rule_ids = [int(r) for r in rule_ids_used.split(',') if r.strip()]
+            rule_ids = [int(r) for r in rule_ids_used.split(",") if r.strip()]
             for rule_id in rule_ids:
                 self.rule_manager.record_rule_outcome(rule_id, success=trade_success)
-            logger.info(f"Recorded {len(rule_ids)} rule outcomes (success={trade_success})")
+            logger.info(
+                f"Recorded {len(rule_ids)} rule outcomes (success={trade_success})"
+            )
 
         # Step 7: Log activity
         pnl_sign = "+" if pnl_usd >= 0 else ""
         self.db.log_activity(
             "trade_closed",
             f"CLOSED {trade['coin_name']} @ ${current_price:.2f} P&L: {pnl_sign}${pnl_usd:.2f} ({exit_reason})",
-            f"trade_id={trade_id}, entry=${entry_price:.2f}, duration={duration_seconds}s"
+            f"trade_id={trade_id}, entry=${entry_price:.2f}, duration={duration_seconds}s",
         )
 
         message = f"Closed trade #{trade_id}: {trade['coin_name']} P&L: {pnl_sign}${pnl_usd:.2f} ({pnl_pct:+.2f}%)"
         logger.info(message)
 
@@ -254,52 +287,57 @@
 
         closed_trades = []
         open_trades = self.get_open_trades()
 
         for trade in open_trades:
-            coin = trade['coin_name']
-            trade_id = trade['id']
+            coin = trade["coin_name"]
+            trade_id = trade["id"]
 
             # Get current price
             current_price = self.get_current_price(coin)
             if current_price is None:
                 logger.warning(f"No market data for {coin}, skipping position update")
                 continue
 
             # Update current price and unrealized P&L
-            entry_price = trade['entry_price']
-            size_usd = trade['size_usd']
+            entry_price = trade["entry_price"]
+            size_usd = trade["size_usd"]
             price_change_pct = (current_price - entry_price) / entry_price
             unrealized_pnl = size_usd * price_change_pct
             unrealized_pnl_pct = price_change_pct * 100
 
             with self.db._get_connection() as conn:
                 cursor = conn.cursor()
-                cursor.execute("""
+                cursor.execute(
+                    """
                     UPDATE open_trades SET
                         current_price = ?,
                         unrealized_pnl = ?,
                         unrealized_pnl_pct = ?
                     WHERE id = ?
-                """, (current_price, unrealized_pnl, unrealized_pnl_pct, trade_id))
+                """,
+                    (current_price, unrealized_pnl, unrealized_pnl_pct, trade_id),
+                )
                 conn.commit()
 
             # Check stop loss / take profit
             exit_check = self.risk_manager.should_exit_trade(
                 entry_price, current_price, size_usd
             )
 
-            if exit_check['should_exit']:
-                result = self.close_trade(trade_id, exit_check['reason'])
+            if exit_check["should_exit"]:
+                result = self.close_trade(trade_id, exit_check["reason"])
                 if result.success:
-                    closed_trades.append({
-                        'trade_id': trade_id,
-                        'coin': coin,
-                        'reason': exit_check['reason'],
-                        'pnl_usd': exit_check['pnl_usd'],
-                        'pnl_pct': exit_check['pnl_pct']
-                    })
+                    closed_trades.append(
+                        {
+                            "trade_id": trade_id,
+                            "coin": coin,
+                            "reason": exit_check["reason"],
+                            "pnl_usd": exit_check["pnl_usd"],
+                            "pnl_pct": exit_check["pnl_pct"],
+                        }
+                    )
 
         logger.info(f"Position update complete. Closed {len(closed_trades)} trades.")
         return closed_trades
 
     def get_open_trades(self) -> List[Dict[str, Any]]:
@@ -316,13 +354,23 @@
                        take_profit_price, entry_reason, opened_at
                 FROM open_trades
                 ORDER BY opened_at DESC
             """)
 
-            columns = ['id', 'coin_name', 'entry_price', 'size_usd', 'current_price',
-                      'unrealized_pnl', 'unrealized_pnl_pct', 'stop_loss_price',
-                      'take_profit_price', 'entry_reason', 'opened_at']
+            columns = [
+                "id",
+                "coin_name",
+                "entry_price",
+                "size_usd",
+                "current_price",
+                "unrealized_pnl",
+                "unrealized_pnl_pct",
+                "stop_loss_price",
+                "take_profit_price",
+                "entry_reason",
+                "opened_at",
+            ]
 
             return [dict(zip(columns, row)) for row in cursor.fetchall()]
 
     def get_trade_by_id(self, trade_id: int) -> Optional[Dict[str, Any]]:
         """Get a specific open trade by ID.
@@ -333,25 +381,39 @@
         Returns:
             Trade dictionary or None if not found.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT id, coin_name, entry_price, size_usd, current_price,
                        unrealized_pnl, unrealized_pnl_pct, stop_loss_price,
                        take_profit_price, entry_reason, opened_at, rule_ids_used
                 FROM open_trades
                 WHERE id = ?
-            """, (trade_id,))
+            """,
+                (trade_id,),
+            )
 
             row = cursor.fetchone()
             if row is None:
                 return None
 
-            columns = ['id', 'coin_name', 'entry_price', 'size_usd', 'current_price',
-                      'unrealized_pnl', 'unrealized_pnl_pct', 'stop_loss_price',
-                      'take_profit_price', 'entry_reason', 'opened_at', 'rule_ids_used']
+            columns = [
+                "id",
+                "coin_name",
+                "entry_price",
+                "size_usd",
+                "current_price",
+                "unrealized_pnl",
+                "unrealized_pnl_pct",
+                "stop_loss_price",
+                "take_profit_price",
+                "entry_reason",
+                "opened_at",
+                "rule_ids_used",
+            ]
 
             return dict(zip(columns, row))
 
     def get_closed_trades(self, limit: int = 10) -> List[Dict[str, Any]]:
         """Get recent closed trades.
@@ -362,22 +424,36 @@
         Returns:
             List of closed trade dictionaries.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT id, coin_name, entry_price, exit_price, size_usd,
                        pnl_usd, pnl_pct, entry_reason, exit_reason,
                        opened_at, closed_at, duration_seconds
                 FROM closed_trades
                 ORDER BY closed_at DESC
                 LIMIT ?
-            """, (limit,))
-
-            columns = ['id', 'coin_name', 'entry_price', 'exit_price', 'size_usd',
-                      'pnl_usd', 'pnl_pct', 'entry_reason', 'exit_reason',
-                      'opened_at', 'closed_at', 'duration_seconds']
+            """,
+                (limit,),
+            )
+
+            columns = [
+                "id",
+                "coin_name",
+                "entry_price",
+                "exit_price",
+                "size_usd",
+                "pnl_usd",
+                "pnl_pct",
+                "entry_reason",
+                "exit_reason",
+                "opened_at",
+                "closed_at",
+                "duration_seconds",
+            ]
 
             return [dict(zip(columns, row)) for row in cursor.fetchall()]
 
     def get_account_summary(self) -> Dict[str, Any]:
         """Get current account summary.
@@ -386,9 +462,6 @@
             Account state with trade counts.
         """
         state = self.db.get_account_state()
         open_count = len(self.get_open_trades())
 
-        return {
-            **state,
-            'open_trade_count': open_count
-        }
+        return {**state, "open_trade_count": open_count}
would reformat /mnt/c/documents/crypto-trading-bot/src/trading_engine.py
--- /mnt/c/documents/crypto-trading-bot/src/database.py	2026-02-03 18:31:49.417171+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/database.py	2026-02-04 21:34:25.285762+00:00
@@ -6,12 +6,11 @@
 from pathlib import Path
 from typing import Optional, List, Dict, Any
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 
 class Database:
@@ -644,18 +643,23 @@
         set_clause = ", ".join(f"{k} = ?" for k in kwargs.keys())
         values = list(kwargs.values())
 
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute(f"""
+            cursor.execute(
+                f"""
                 UPDATE account_state
                 SET {set_clause}, last_updated = CURRENT_TIMESTAMP
                 WHERE id = (SELECT MAX(id) FROM account_state)
-            """, values)
-            conn.commit()
-
-    def log_activity(self, activity_type: str, description: str, details: Optional[str] = None) -> int:
+            """,
+                values,
+            )
+            conn.commit()
+
+    def log_activity(
+        self, activity_type: str, description: str, details: Optional[str] = None
+    ) -> int:
         """Log an activity to the activity_log table.
 
         Args:
             activity_type: Type of activity (e.g., 'trade', 'learning', 'error')
             description: Human-readable description
@@ -664,14 +668,17 @@
         Returns:
             The ID of the inserted log entry.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT INTO activity_log (activity_type, description, details)
                 VALUES (?, ?, ?)
-            """, (activity_type, description, details))
+            """,
+                (activity_type, description, details),
+            )
             conn.commit()
             return cursor.lastrowid
 
     def get_recent_activity(self, limit: int = 10) -> List[Dict[str, Any]]:
         """Get recent activity log entries.
@@ -682,15 +689,18 @@
         Returns:
             List of activity log entries as dictionaries.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT * FROM activity_log
                 ORDER BY created_at DESC
                 LIMIT ?
-            """, (limit,))
+            """,
+                (limit,),
+            )
             return [dict(row) for row in cursor.fetchall()]
 
     # ========== Reflections (TASK-131 Deep Reflection) ==========
 
     def log_reflection(
@@ -713,15 +723,18 @@
         Returns:
             The ID of the inserted reflection.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT INTO reflections
                 (timestamp, trades_analyzed, period_hours, insights, summary, total_time_ms)
                 VALUES (CURRENT_TIMESTAMP, ?, ?, ?, ?, ?)
-            """, (trades_analyzed, period_hours, insights, summary, total_time_ms))
+            """,
+                (trades_analyzed, period_hours, insights, summary, total_time_ms),
+            )
             conn.commit()
             return cursor.lastrowid
 
     def get_recent_reflections(self, limit: int = 10) -> List[Dict[str, Any]]:
         """Get recent reflection results.
@@ -732,15 +745,18 @@
         Returns:
             List of reflection records as dictionaries.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT * FROM reflections
                 ORDER BY timestamp DESC
                 LIMIT ?
-            """, (limit,))
+            """,
+                (limit,),
+            )
             return [dict(row) for row in cursor.fetchall()]
 
     # ========== Active Conditions (TASK-110 Strategist) ==========
 
     def save_condition(self, condition: Dict[str, Any]) -> None:
@@ -748,43 +764,52 @@
 
         Args:
             condition: Dictionary with condition fields from TradeCondition.to_dict()
         """
         import json
-        with self._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+
+        with self._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 INSERT OR REPLACE INTO active_conditions
                 (id, coin, direction, trigger_price, trigger_condition,
                  stop_loss_pct, take_profit_pct, position_size_usd,
                  strategy_id, reasoning, created_at, valid_until, additional_filters)
                 VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
-            """, (
-                condition["id"],
-                condition["coin"],
-                condition["direction"],
-                condition["trigger_price"],
-                condition["trigger_condition"],
-                condition["stop_loss_pct"],
-                condition["take_profit_pct"],
-                condition["position_size_usd"],
-                condition.get("strategy_id"),
-                condition.get("reasoning"),
-                condition["created_at"],
-                condition["valid_until"],
-                json.dumps(condition.get("additional_filters")) if condition.get("additional_filters") else None,
-            ))
+            """,
+                (
+                    condition["id"],
+                    condition["coin"],
+                    condition["direction"],
+                    condition["trigger_price"],
+                    condition["trigger_condition"],
+                    condition["stop_loss_pct"],
+                    condition["take_profit_pct"],
+                    condition["position_size_usd"],
+                    condition.get("strategy_id"),
+                    condition.get("reasoning"),
+                    condition["created_at"],
+                    condition["valid_until"],
+                    (
+                        json.dumps(condition.get("additional_filters"))
+                        if condition.get("additional_filters")
+                        else None
+                    ),
+                ),
+            )
             conn.commit()
             logger.debug(f"Saved condition {condition['id']} for {condition['coin']}")
 
     def get_active_conditions(self) -> List[Dict[str, Any]]:
         """Get all non-expired, non-triggered conditions.
 
         Returns:
             List of active condition dictionaries.
         """
         import json
+
         with self._get_connection() as conn:
             cursor = conn.cursor()
             cursor.execute("""
                 SELECT * FROM active_conditions
                 WHERE triggered = FALSE
@@ -808,15 +833,19 @@
 
         Returns:
             Condition dictionary or None if not found.
         """
         import json
-        with self._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+
+        with self._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 SELECT * FROM active_conditions WHERE id = ?
-            """, (condition_id,))
+            """,
+                (condition_id,),
+            )
             row = cursor.fetchone()
             if row:
                 cond = dict(row)
                 if cond.get("additional_filters"):
                     cond["additional_filters"] = json.loads(cond["additional_filters"])
@@ -829,15 +858,18 @@
         Args:
             condition_id: The condition ID to mark as triggered.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE active_conditions
                 SET triggered = TRUE, triggered_at = datetime('now')
                 WHERE id = ?
-            """, (condition_id,))
+            """,
+                (condition_id,),
+            )
             conn.commit()
             logger.info(f"Marked condition {condition_id} as triggered")
 
     def delete_expired_conditions(self) -> int:
         """Delete all expired conditions.
@@ -882,19 +914,23 @@
 
         Returns:
             List of condition dictionaries for this coin.
         """
         import json
-        with self._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+
+        with self._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 SELECT * FROM active_conditions
                 WHERE coin = ?
                 AND triggered = FALSE
                 AND valid_until > datetime('now')
                 ORDER BY created_at DESC
-            """, (coin,))
+            """,
+                (coin,),
+            )
             rows = cursor.fetchall()
             conditions = []
             for row in rows:
                 cond = dict(row)
                 if cond.get("additional_filters"):
@@ -910,30 +946,33 @@
         Args:
             score_data: Dictionary from CoinScore.to_dict()
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT OR REPLACE INTO coin_scores
                 (coin, total_trades, wins, losses, total_pnl, avg_pnl, win_rate,
                  avg_winner, avg_loser, is_blacklisted, blacklist_reason, trend, last_updated)
                 VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
-            """, (
-                score_data["coin"],
-                score_data["total_trades"],
-                score_data["wins"],
-                score_data["losses"],
-                score_data["total_pnl"],
-                score_data["avg_pnl"],
-                score_data["win_rate"],
-                score_data["avg_winner"],
-                score_data["avg_loser"],
-                score_data["is_blacklisted"],
-                score_data["blacklist_reason"],
-                score_data["trend"],
-                score_data["last_updated"],
-            ))
+            """,
+                (
+                    score_data["coin"],
+                    score_data["total_trades"],
+                    score_data["wins"],
+                    score_data["losses"],
+                    score_data["total_pnl"],
+                    score_data["avg_pnl"],
+                    score_data["win_rate"],
+                    score_data["avg_winner"],
+                    score_data["avg_loser"],
+                    score_data["is_blacklisted"],
+                    score_data["blacklist_reason"],
+                    score_data["trend"],
+                    score_data["last_updated"],
+                ),
+            )
             conn.commit()
 
     def get_coin_score(self, coin: str) -> Optional[Dict[str, Any]]:
         """Get score for a specific coin.
 
@@ -969,25 +1008,30 @@
         with self._get_connection() as conn:
             cursor = conn.cursor()
             cursor.execute("SELECT coin FROM coin_scores WHERE is_blacklisted = TRUE")
             return [row[0] for row in cursor.fetchall()]
 
-    def update_coin_blacklist(self, coin: str, is_blacklisted: bool, reason: str = "") -> None:
+    def update_coin_blacklist(
+        self, coin: str, is_blacklisted: bool, reason: str = ""
+    ) -> None:
         """Update blacklist status for a coin.
 
         Args:
             coin: Coin symbol.
             is_blacklisted: Whether to blacklist.
             reason: Reason for blacklisting (if applicable).
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE coin_scores
                 SET is_blacklisted = ?, blacklist_reason = ?, last_updated = CURRENT_TIMESTAMP
                 WHERE coin = ?
-            """, (is_blacklisted, reason, coin))
+            """,
+                (is_blacklisted, reason, coin),
+            )
             conn.commit()
 
     # ========== Trading Patterns (TASK-120 Knowledge Brain) ==========
 
     def save_pattern(self, pattern_data: Dict[str, Any]) -> None:
@@ -996,30 +1040,33 @@
         Args:
             pattern_data: Dictionary from TradingPattern.to_dict()
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT OR REPLACE INTO trading_patterns
                 (pattern_id, description, entry_conditions, exit_conditions,
                  times_used, wins, losses, total_pnl, confidence, is_active,
                  created_at, last_used)
                 VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
-            """, (
-                pattern_data["pattern_id"],
-                pattern_data["description"],
-                pattern_data["entry_conditions"],
-                pattern_data["exit_conditions"],
-                pattern_data["times_used"],
-                pattern_data["wins"],
-                pattern_data["losses"],
-                pattern_data["total_pnl"],
-                pattern_data["confidence"],
-                pattern_data["is_active"],
-                pattern_data["created_at"],
-                pattern_data["last_used"],
-            ))
+            """,
+                (
+                    pattern_data["pattern_id"],
+                    pattern_data["description"],
+                    pattern_data["entry_conditions"],
+                    pattern_data["exit_conditions"],
+                    pattern_data["times_used"],
+                    pattern_data["wins"],
+                    pattern_data["losses"],
+                    pattern_data["total_pnl"],
+                    pattern_data["confidence"],
+                    pattern_data["is_active"],
+                    pattern_data["created_at"],
+                    pattern_data["last_used"],
+                ),
+            )
             conn.commit()
 
     def get_pattern(self, pattern_id: str) -> Optional[Dict[str, Any]]:
         """Get a trading pattern by ID.
 
@@ -1029,11 +1076,13 @@
         Returns:
             Pattern dictionary or None if not found.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("SELECT * FROM trading_patterns WHERE pattern_id = ?", (pattern_id,))
+            cursor.execute(
+                "SELECT * FROM trading_patterns WHERE pattern_id = ?", (pattern_id,)
+            )
             row = cursor.fetchone()
             return dict(row) if row else None
 
     def get_active_patterns(self) -> List[Dict[str, Any]]:
         """Get all active trading patterns.
@@ -1058,34 +1107,40 @@
             won: Whether the trade was a winner.
             pnl: P&L from the trade.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE trading_patterns
                 SET times_used = times_used + 1,
                     wins = wins + ?,
                     losses = losses + ?,
                     total_pnl = total_pnl + ?,
                     last_used = CURRENT_TIMESTAMP
                 WHERE pattern_id = ?
-            """, (1 if won else 0, 0 if won else 1, pnl, pattern_id))
+            """,
+                (1 if won else 0, 0 if won else 1, pnl, pattern_id),
+            )
             conn.commit()
 
     def deactivate_pattern(self, pattern_id: str) -> None:
         """Deactivate a pattern.
 
         Args:
             pattern_id: Pattern ID.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE trading_patterns
                 SET is_active = FALSE
                 WHERE pattern_id = ?
-            """, (pattern_id,))
+            """,
+                (pattern_id,),
+            )
             conn.commit()
 
     # ========== Regime Rules (TASK-120 Knowledge Brain) ==========
 
     def save_rule(self, rule_data: Dict[str, Any]) -> None:
@@ -1094,25 +1149,28 @@
         Args:
             rule_data: Dictionary from RegimeRule.to_dict()
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT OR REPLACE INTO regime_rules
                 (rule_id, description, condition, action, times_triggered,
                  estimated_saves, is_active, created_at)
                 VALUES (?, ?, ?, ?, ?, ?, ?, ?)
-            """, (
-                rule_data["rule_id"],
-                rule_data["description"],
-                rule_data["condition"],
-                rule_data["action"],
-                rule_data["times_triggered"],
-                rule_data["estimated_saves"],
-                rule_data["is_active"],
-                rule_data["created_at"],
-            ))
+            """,
+                (
+                    rule_data["rule_id"],
+                    rule_data["description"],
+                    rule_data["condition"],
+                    rule_data["action"],
+                    rule_data["times_triggered"],
+                    rule_data["estimated_saves"],
+                    rule_data["is_active"],
+                    rule_data["created_at"],
+                ),
+            )
             conn.commit()
 
     def get_rule(self, rule_id: str) -> Optional[Dict[str, Any]]:
         """Get a regime rule by ID.
 
@@ -1150,31 +1208,37 @@
             rule_id: Rule ID.
             estimated_save: Estimated P&L saved by following this rule.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE regime_rules
                 SET times_triggered = times_triggered + 1,
                     estimated_saves = estimated_saves + ?
                 WHERE rule_id = ?
-            """, (estimated_save, rule_id))
+            """,
+                (estimated_save, rule_id),
+            )
             conn.commit()
 
     def deactivate_rule(self, rule_id: str) -> None:
         """Deactivate a regime rule.
 
         Args:
             rule_id: Rule ID.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE regime_rules
                 SET is_active = FALSE
                 WHERE rule_id = ?
-            """, (rule_id,))
+            """,
+                (rule_id,),
+            )
             conn.commit()
 
     # ========== Coin Adaptations (TASK-121 Coin Scoring) ==========
 
     def save_coin_adaptation(self, adaptation_data: Dict[str, Any]) -> int:
@@ -1185,53 +1249,66 @@
 
         Returns:
             ID of the inserted record.
         """
         import json
-        with self._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+
+        with self._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 INSERT INTO coin_adaptations
                 (coin, timestamp, old_status, new_status, reason, trigger_stats)
                 VALUES (?, ?, ?, ?, ?, ?)
-            """, (
-                adaptation_data["coin"],
-                adaptation_data["timestamp"],
-                adaptation_data["old_status"],
-                adaptation_data["new_status"],
-                adaptation_data["reason"],
-                json.dumps(adaptation_data.get("trigger_stats", {})),
-            ))
+            """,
+                (
+                    adaptation_data["coin"],
+                    adaptation_data["timestamp"],
+                    adaptation_data["old_status"],
+                    adaptation_data["new_status"],
+                    adaptation_data["reason"],
+                    json.dumps(adaptation_data.get("trigger_stats", {})),
+                ),
+            )
             conn.commit()
             return cursor.lastrowid
 
-    def get_coin_adaptations(self, coin: Optional[str] = None, limit: int = 50) -> List[Dict[str, Any]]:
+    def get_coin_adaptations(
+        self, coin: Optional[str] = None, limit: int = 50
+    ) -> List[Dict[str, Any]]:
         """Get coin adaptation history.
 
         Args:
             coin: Optional coin to filter by.
             limit: Maximum number of records.
 
         Returns:
             List of adaptation records.
         """
         import json
+
         with self._get_connection() as conn:
             cursor = conn.cursor()
             if coin:
-                cursor.execute("""
+                cursor.execute(
+                    """
                     SELECT * FROM coin_adaptations
                     WHERE coin = ?
                     ORDER BY timestamp DESC
                     LIMIT ?
-                """, (coin, limit))
+                """,
+                    (coin, limit),
+                )
             else:
-                cursor.execute("""
+                cursor.execute(
+                    """
                     SELECT * FROM coin_adaptations
                     ORDER BY timestamp DESC
                     LIMIT ?
-                """, (limit,))
+                """,
+                    (limit,),
+                )
 
             results = []
             for row in cursor.fetchall():
                 record = dict(row)
                 if record.get("trigger_stats"):
@@ -1247,26 +1324,29 @@
 
         Returns:
             List of recent adaptation records.
         """
         import json
-        with self._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+
+        with self._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 SELECT * FROM coin_adaptations
                 WHERE timestamp > datetime('now', ? || ' hours')
                 ORDER BY timestamp DESC
-            """, (f"-{hours}",))
+            """,
+                (f"-{hours}",),
+            )
 
             results = []
             for row in cursor.fetchall():
                 record = dict(row)
                 if record.get("trigger_stats"):
                     record["trigger_stats"] = json.loads(record["trigger_stats"])
                 results.append(record)
             return results
-
 
     # ========== Adaptations (TASK-133 Adaptation Application) ==========
 
     def log_adaptation(
         self,
@@ -1294,25 +1374,28 @@
         Returns:
             The ID of the inserted adaptation.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT INTO adaptations
                 (adaptation_id, insight_type, action, target, description,
                  pre_metrics, insight_confidence, insight_evidence)
                 VALUES (?, ?, ?, ?, ?, ?, ?, ?)
-            """, (
-                adaptation_id,
-                insight_type,
-                action,
-                target,
-                description,
-                pre_metrics,
-                insight_confidence,
-                insight_evidence,
-            ))
+            """,
+                (
+                    adaptation_id,
+                    insight_type,
+                    action,
+                    target,
+                    description,
+                    pre_metrics,
+                    insight_confidence,
+                    insight_evidence,
+                ),
+            )
             conn.commit()
             logger.info(f"Logged adaptation: [{action}] {target}")
             return cursor.lastrowid
 
     def get_adaptations(self, hours: int = 24, limit: int = 50) -> List[Dict[str, Any]]:
@@ -1324,18 +1407,22 @@
 
         Returns:
             List of adaptation records as dictionaries.
         """
         import json
-        with self._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+
+        with self._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 SELECT * FROM adaptations
                 WHERE timestamp > datetime('now', ? || ' hours')
                 ORDER BY timestamp DESC
                 LIMIT ?
-            """, (f"-{hours}", limit))
+            """,
+                (f"-{hours}", limit),
+            )
 
             results = []
             for row in cursor.fetchall():
                 record = dict(row)
                 # Parse JSON fields
@@ -1344,40 +1431,48 @@
                         record["pre_metrics"] = json.loads(record["pre_metrics"])
                     except json.JSONDecodeError:
                         pass
                 if record.get("insight_evidence"):
                     try:
-                        record["insight_evidence"] = json.loads(record["insight_evidence"])
+                        record["insight_evidence"] = json.loads(
+                            record["insight_evidence"]
+                        )
                     except json.JSONDecodeError:
                         pass
                 if record.get("post_metrics"):
                     try:
                         record["post_metrics"] = json.loads(record["post_metrics"])
                     except json.JSONDecodeError:
                         pass
                 results.append(record)
             return results
 
-    def get_adaptations_for_target(self, target: str, hours: int = 24) -> List[Dict[str, Any]]:
+    def get_adaptations_for_target(
+        self, target: str, hours: int = 24
+    ) -> List[Dict[str, Any]]:
         """Get recent adaptations for a specific target.
 
         Args:
             target: The target (coin symbol, rule_id, etc.).
             hours: Number of hours to look back.
 
         Returns:
             List of adaptation records for this target.
         """
         import json
-        with self._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+
+        with self._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 SELECT * FROM adaptations
                 WHERE target = ?
                 AND timestamp > datetime('now', ? || ' hours')
                 ORDER BY timestamp DESC
-            """, (target, f"-{hours}"))
+            """,
+                (target, f"-{hours}"),
+            )
 
             results = []
             for row in cursor.fetchall():
                 record = dict(row)
                 if record.get("pre_metrics"):
@@ -1403,24 +1498,33 @@
             effectiveness: Effectiveness rating.
             effectiveness_measured_at: When effectiveness was measured.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 UPDATE adaptations
                 SET post_metrics = ?,
                     effectiveness = ?,
                     effectiveness_measured_at = ?
                 WHERE adaptation_id = ?
-            """, (
-                post_metrics,
-                effectiveness,
-                effectiveness_measured_at.isoformat() if isinstance(effectiveness_measured_at, datetime) else effectiveness_measured_at,
-                adaptation_id,
-            ))
-            conn.commit()
-            logger.debug(f"Updated effectiveness for adaptation {adaptation_id}: {effectiveness}")
+            """,
+                (
+                    post_metrics,
+                    effectiveness,
+                    (
+                        effectiveness_measured_at.isoformat()
+                        if isinstance(effectiveness_measured_at, datetime)
+                        else effectiveness_measured_at
+                    ),
+                    adaptation_id,
+                ),
+            )
+            conn.commit()
+            logger.debug(
+                f"Updated effectiveness for adaptation {adaptation_id}: {effectiveness}"
+            )
 
     def get_adaptations_by_effectiveness(
         self,
         effectiveness: str,
         hours: int = 168,
@@ -1433,18 +1537,22 @@
 
         Returns:
             List of adaptation records with this effectiveness.
         """
         import json
-        with self._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+
+        with self._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 SELECT * FROM adaptations
                 WHERE effectiveness = ?
                 AND timestamp > datetime('now', ? || ' hours')
                 ORDER BY effectiveness_measured_at DESC
-            """, (effectiveness, f"-{hours}"))
+            """,
+                (effectiveness, f"-{hours}"),
+            )
 
             results = []
             for row in cursor.fetchall():
                 record = dict(row)
                 # Parse JSON fields
@@ -1465,18 +1573,22 @@
 
         Returns:
             List of unmeasured adaptation records.
         """
         import json
-        with self._get_connection() as conn:
-            cursor = conn.cursor()
-            cursor.execute("""
+
+        with self._get_connection() as conn:
+            cursor = conn.cursor()
+            cursor.execute(
+                """
                 SELECT * FROM adaptations
                 WHERE effectiveness IS NULL
                 AND timestamp < datetime('now', ? || ' hours')
                 ORDER BY timestamp ASC
-            """, (f"-{min_hours}",))
+            """,
+                (f"-{min_hours}",),
+            )
 
             results = []
             for row in cursor.fetchall():
                 record = dict(row)
                 if record.get("pre_metrics"):
@@ -1494,28 +1606,33 @@
 
         Args:
             state: Dictionary of state to persist.
         """
         import json
+
         with self._get_connection() as conn:
             cursor = conn.cursor()
             for key, value in state.items():
                 value_json = json.dumps(value) if not isinstance(value, str) else value
-                cursor.execute("""
+                cursor.execute(
+                    """
                     INSERT OR REPLACE INTO runtime_state (key, value, updated_at)
                     VALUES (?, ?, CURRENT_TIMESTAMP)
-                """, (key, value_json))
+                """,
+                    (key, value_json),
+                )
             conn.commit()
             logger.debug(f"Saved runtime state: {len(state)} keys")
 
     def get_runtime_state(self) -> Dict[str, Any]:
         """Load runtime state after restart.
 
         Returns:
             Dictionary of saved state.
         """
         import json
+
         with self._get_connection() as conn:
             cursor = conn.cursor()
             cursor.execute("SELECT key, value FROM runtime_state")
             rows = cursor.fetchall()
 
@@ -1549,37 +1666,40 @@
         Returns:
             The ID of the inserted snapshot.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT INTO profit_snapshots
                 (timestamp, timeframe, total_pnl, realized_pnl, unrealized_pnl,
                  total_trades, winning_trades, losing_trades, win_rate,
                  avg_win, avg_loss, profit_factor, max_drawdown, max_drawdown_pct,
                  sharpe_ratio, starting_balance, ending_balance, return_pct)
                 VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
-            """, (
-                snapshot["timestamp"],
-                snapshot["timeframe"],
-                snapshot["total_pnl"],
-                snapshot["realized_pnl"],
-                snapshot.get("unrealized_pnl", 0),
-                snapshot["total_trades"],
-                snapshot["winning_trades"],
-                snapshot["losing_trades"],
-                snapshot["win_rate"],
-                snapshot.get("avg_win"),
-                snapshot.get("avg_loss"),
-                snapshot.get("profit_factor"),
-                snapshot.get("max_drawdown"),
-                snapshot.get("max_drawdown_pct"),
-                snapshot.get("sharpe_ratio"),
-                snapshot.get("starting_balance"),
-                snapshot.get("ending_balance"),
-                snapshot.get("return_pct"),
-            ))
+            """,
+                (
+                    snapshot["timestamp"],
+                    snapshot["timeframe"],
+                    snapshot["total_pnl"],
+                    snapshot["realized_pnl"],
+                    snapshot.get("unrealized_pnl", 0),
+                    snapshot["total_trades"],
+                    snapshot["winning_trades"],
+                    snapshot["losing_trades"],
+                    snapshot["win_rate"],
+                    snapshot.get("avg_win"),
+                    snapshot.get("avg_loss"),
+                    snapshot.get("profit_factor"),
+                    snapshot.get("max_drawdown"),
+                    snapshot.get("max_drawdown_pct"),
+                    snapshot.get("sharpe_ratio"),
+                    snapshot.get("starting_balance"),
+                    snapshot.get("ending_balance"),
+                    snapshot.get("return_pct"),
+                ),
+            )
             conn.commit()
             logger.debug(f"Saved profit snapshot ({snapshot['timeframe']})")
             return cursor.lastrowid
 
     def get_profit_snapshots(
@@ -1617,16 +1737,19 @@
 
         where = " AND ".join(where_parts)
 
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute(f"""
+            cursor.execute(
+                f"""
                 SELECT * FROM profit_snapshots
                 WHERE {where}
                 ORDER BY timestamp DESC
                 LIMIT ?
-            """, params + [limit])
+            """,
+                params + [limit],
+            )
             return [dict(row) for row in cursor.fetchall()]
 
     def delete_old_snapshots(self, timeframe: str, cutoff: datetime) -> int:
         """Delete snapshots older than cutoff.
 
@@ -1637,15 +1760,18 @@
         Returns:
             Number of snapshots deleted.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 DELETE FROM profit_snapshots
                 WHERE timeframe = ?
                 AND timestamp < ?
-            """, (timeframe, cutoff.isoformat()))
+            """,
+                (timeframe, cutoff.isoformat()),
+            )
             deleted = cursor.rowcount
             conn.commit()
             if deleted > 0:
                 logger.debug(f"Deleted {deleted} old {timeframe} snapshots")
             return deleted
@@ -1661,20 +1787,23 @@
         Returns:
             The ID of the inserted point.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT INTO equity_points
                 (timestamp, balance, trade_id, is_high_water_mark)
                 VALUES (?, ?, ?, ?)
-            """, (
-                point["timestamp"],
-                point["balance"],
-                point.get("trade_id"),
-                point.get("is_high_water_mark", False),
-            ))
+            """,
+                (
+                    point["timestamp"],
+                    point["balance"],
+                    point.get("trade_id"),
+                    point.get("is_high_water_mark", False),
+                ),
+            )
             conn.commit()
             return cursor.lastrowid
 
     def get_equity_curve(
         self,
@@ -1705,16 +1834,19 @@
 
         where = " AND ".join(where_parts)
 
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute(f"""
+            cursor.execute(
+                f"""
                 SELECT * FROM equity_points
                 WHERE {where}
                 ORDER BY timestamp ASC
                 LIMIT ?
-            """, params + [limit])
+            """,
+                params + [limit],
+            )
             return [dict(row) for row in cursor.fetchall()]
 
     def get_high_water_marks(self, limit: int = 100) -> List[Dict[str, Any]]:
         """Get all high water mark points.
 
@@ -1724,16 +1856,19 @@
         Returns:
             List of high water mark equity points.
         """
         with self._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT * FROM equity_points
                 WHERE is_high_water_mark = TRUE
                 ORDER BY timestamp DESC
                 LIMIT ?
-            """, (limit,))
+            """,
+                (limit,),
+            )
             return [dict(row) for row in cursor.fetchall()]
 
 
 # Allow running directly to initialize database
 if __name__ == "__main__":
would reformat /mnt/c/documents/crypto-trading-bot/src/database.py
--- /mnt/c/documents/crypto-trading-bot/src/main.py	2026-02-03 23:33:31.692441+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/main.py	2026-02-04 21:34:25.288179+00:00
@@ -42,13 +42,18 @@
 from src.dashboard_v2 import DashboardServer
 
 # Import settings
 try:
     from config.settings import (
-        TRADEABLE_COINS, DEFAULT_EXCHANGE, INITIAL_BALANCE,
-        STALE_DATA_THRESHOLD, STATUS_LOG_INTERVAL, SNIPER_STATE_PATH,
-        STRATEGIST_INTERVAL, STRATEGIST_ENABLED
+        TRADEABLE_COINS,
+        DEFAULT_EXCHANGE,
+        INITIAL_BALANCE,
+        STALE_DATA_THRESHOLD,
+        STATUS_LOG_INTERVAL,
+        SNIPER_STATE_PATH,
+        STRATEGIST_INTERVAL,
+        STRATEGIST_ENABLED,
     )
 except ImportError:
     # Defaults if config not available
     TRADEABLE_COINS = ["BTC", "ETH", "SOL"]
     DEFAULT_EXCHANGE = "bybit"
@@ -60,12 +65,12 @@
     STRATEGIST_ENABLED = True
 
 # Configure logging
 logging.basicConfig(
     level=logging.INFO,
-    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
-    datefmt='%Y-%m-%d %H:%M:%S'
+    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
+    datefmt="%Y-%m-%d %H:%M:%S",
 )
 logger = logging.getLogger("TradingSystem")
 
 
 class HealthMonitor:
@@ -156,17 +161,19 @@
         system.inject_condition(condition)
         system.inject_price("BTC", 50000.0)
         await system.stop()
     """
 
-    def __init__(self,
-                 exchange: str = DEFAULT_EXCHANGE,
-                 coins: list[str] = None,
-                 initial_balance: float = INITIAL_BALANCE,
-                 test_mode: bool = False,
-                 db_path: Optional[str] = None,
-                 state_path: Optional[str] = None):
+    def __init__(
+        self,
+        exchange: str = DEFAULT_EXCHANGE,
+        coins: list[str] = None,
+        initial_balance: float = INITIAL_BALANCE,
+        test_mode: bool = False,
+        db_path: Optional[str] = None,
+        state_path: Optional[str] = None,
+    ):
         """
         Initialize the trading system.
 
         Args:
             exchange: Exchange to connect to (bybit, binance, binance_us)
@@ -205,11 +212,13 @@
         # State
         self._running = False
         self._start_time: Optional[datetime] = None
         self._last_status_log = 0
 
-        logger.info(f"TradingSystem initialized (exchange={exchange}, coins={len(self.coins)}, test_mode={test_mode})")
+        logger.info(
+            f"TradingSystem initialized (exchange={exchange}, coins={len(self.coins)}, test_mode={test_mode})"
+        )
 
     async def start(self) -> None:
         """
         Start the trading system and enter main loop.
 
@@ -261,14 +270,18 @@
         self.knowledge = KnowledgeBrain(self.db)
         self.coin_scorer = CoinScorer(self.knowledge, self.db)
         self.pattern_library = PatternLibrary(self.knowledge)
         kb_stats = self.knowledge.get_stats_summary()
         pl_stats = self.pattern_library.get_stats_summary()
-        logger.info(f"Knowledge Brain: {kb_stats['coins']['total']} coins, "
-                   f"{kb_stats['coins']['blacklisted']} blacklisted")
-        logger.info(f"Pattern Library: {pl_stats['total_patterns']} patterns, "
-                   f"{pl_stats['high_confidence']} high-confidence")
+        logger.info(
+            f"Knowledge Brain: {kb_stats['coins']['total']} coins, "
+            f"{kb_stats['coins']['blacklisted']} blacklisted"
+        )
+        logger.info(
+            f"Pattern Library: {pl_stats['total_patterns']} patterns, "
+            f"{pl_stats['high_confidence']} high-confidence"
+        )
 
         # Initialize QuickUpdate (TASK-130: post-trade knowledge updates)
         logger.info("Initializing QuickUpdate...")
         self.quick_update = QuickUpdate(
             coin_scorer=self.coin_scorer,
@@ -285,15 +298,19 @@
             quick_update=self.quick_update,
         )
 
         # Try to load persisted state
         if self.sniper.load_state():
-            logger.info(f"Restored state: balance=${self.sniper.balance:.2f}, "
-                       f"positions={len(self.sniper.open_positions)}")
+            logger.info(
+                f"Restored state: balance=${self.sniper.balance:.2f}, "
+                f"positions={len(self.sniper.open_positions)}"
+            )
 
         # Initialize MarketFeed
-        logger.info(f"Initializing MarketFeed ({self.exchange}, {len(self.coins)} coins)...")
+        logger.info(
+            f"Initializing MarketFeed ({self.exchange}, {len(self.coins)} coins)..."
+        )
         self.market_feed = MarketFeed(self.coins, exchange=self.exchange)
 
         # Pass market feed to journal for post-trade capture
         self.journal.market_feed = self.market_feed
 
@@ -333,11 +350,13 @@
                 db=self.db,
                 adaptation_engine=self.adaptation_engine,
             )
             # Wire reflection engine to quick update
             self.quick_update.set_reflection_engine(self.reflection_engine)
-            logger.info("ReflectionEngine ready (triggers: 1h or 10 trades, with adaptations)")
+            logger.info(
+                "ReflectionEngine ready (triggers: 1h or 10 trades, with adaptations)"
+            )
         else:
             logger.info("Strategist disabled")
 
         # Initialize ProfitabilityTracker (TASK-141)
         logger.info("Initializing ProfitabilityTracker...")
@@ -410,22 +429,30 @@
             logger.error(f"Feed error: {data.get('error', 'unknown')}")
 
     def _on_execution(self, event) -> None:
         """Handle sniper execution events."""
         if event.event_type == "entry":
-            logger.info(f"TRADE ENTRY: {event.direction} {event.coin} @ ${event.price:,.2f}")
+            logger.info(
+                f"TRADE ENTRY: {event.direction} {event.coin} @ ${event.price:,.2f}"
+            )
         elif event.event_type == "exit":
-            pnl_str = f"+${event.pnl:.2f}" if event.pnl >= 0 else f"-${abs(event.pnl):.2f}"
-            logger.info(f"TRADE EXIT: {event.coin} @ ${event.price:,.2f} [{event.reason}] {pnl_str}")
+            pnl_str = (
+                f"+${event.pnl:.2f}" if event.pnl >= 0 else f"-${abs(event.pnl):.2f}"
+            )
+            logger.info(
+                f"TRADE EXIT: {event.coin} @ ${event.price:,.2f} [{event.reason}] {pnl_str}"
+            )
 
     def _on_new_conditions(self, conditions: list[TradeCondition]) -> None:
         """Handle new conditions from Strategist (handoff to Sniper)."""
         logger.info("=" * 50)
         logger.info("STRATEGIST  SNIPER HANDOFF")
         logger.info(f"Conditions received: {len(conditions)}")
         for c in conditions:
-            logger.info(f"  {c.direction} {c.coin} @ ${c.trigger_price:,.2f} ({c.trigger_condition})")
+            logger.info(
+                f"  {c.direction} {c.coin} @ ${c.trigger_price:,.2f} ({c.trigger_condition})"
+            )
 
         # Pass to Sniper
         active_count = self.sniper.set_conditions(conditions)
         logger.info(f"Sniper now watching {active_count} conditions")
         logger.info("=" * 50)
@@ -554,13 +581,15 @@
             self.journal.stop()
 
         # Final stats
         if self.health:
             stats = self.health.get_stats()
-            logger.info(f"Final stats: {stats['tick_count']} ticks, "
-                       f"{stats['error_count']} errors, "
-                       f"{stats['uptime_seconds']:.1f}s uptime")
+            logger.info(
+                f"Final stats: {stats['tick_count']} ticks, "
+                f"{stats['error_count']} errors, "
+                f"{stats['uptime_seconds']:.1f}s uptime"
+            )
 
         logger.info("Trading system stopped")
 
     # =========================================================================
     # Test Mode Methods
@@ -592,15 +621,11 @@
         if not self.sniper:
             raise RuntimeError("System not started - call start_components() first")
 
         ts = timestamp or int(time.time() * 1000)
         tick = PriceTick(
-            coin=coin.upper(),
-            price=price,
-            timestamp=ts,
-            volume_24h=0,
-            change_24h=0
+            coin=coin.upper(), price=price, timestamp=ts, volume_24h=0, change_24h=0
         )
         self._on_price_tick(tick)
         if self.health:
             self.health.on_tick(tick)
 
@@ -718,11 +743,13 @@
             state["last_reflection_time"] = (
                 self.reflection_engine.last_reflection_time.isoformat()
                 if self.reflection_engine.last_reflection_time
                 else None
             )
-            state["trades_since_reflection"] = self.reflection_engine.trades_since_reflection
+            state["trades_since_reflection"] = (
+                self.reflection_engine.trades_since_reflection
+            )
 
         # Save system stats
         if self.health:
             stats = self.health.get_stats()
             state["uptime_seconds"] = stats.get("uptime_seconds", 0)
@@ -746,12 +773,12 @@
                 return
 
             # Restore reflection state
             if self.reflection_engine and state.get("last_reflection_time"):
                 try:
-                    self.reflection_engine.last_reflection_time = datetime.fromisoformat(
-                        state["last_reflection_time"]
+                    self.reflection_engine.last_reflection_time = (
+                        datetime.fromisoformat(state["last_reflection_time"])
                     )
                     self.reflection_engine.trades_since_reflection = state.get(
                         "trades_since_reflection", 0
                     )
                     logger.info(
@@ -759,11 +786,13 @@
                         f"trades_since={state.get('trades_since_reflection', 0)}"
                     )
                 except (ValueError, TypeError) as e:
                     logger.warning(f"Failed to restore reflection state: {e}")
 
-            logger.info(f"Runtime state restored (shutdown: {state.get('shutdown_time', 'unknown')})")
+            logger.info(
+                f"Runtime state restored (shutdown: {state.get('shutdown_time', 'unknown')})"
+            )
         except Exception as e:
             logger.error(f"Failed to restore runtime state: {e}")
 
     # =========================================================================
     # Operational Commands (TASK-140)
@@ -776,11 +805,12 @@
             Dict with loop statistics.
         """
         stats = {
             "uptime_hours": (
                 (datetime.now() - self._start_time).total_seconds() / 3600
-                if self._start_time else 0
+                if self._start_time
+                else 0
             ),
         }
 
         if self.sniper:
             sniper_status = self.sniper.get_status()
@@ -984,26 +1014,24 @@
 
 # =============================================================================
 # Main Entry Point
 # =============================================================================
 
+
 async def main():
     """Main entry point."""
     import argparse
 
     parser = argparse.ArgumentParser(description="Trading System v2")
     parser.add_argument(
-        "--dashboard", action="store_true",
-        help="Start the dashboard web server"
+        "--dashboard", action="store_true", help="Start the dashboard web server"
     )
     parser.add_argument(
-        "--port", type=int, default=8080,
-        help="Dashboard port (default: 8080)"
+        "--port", type=int, default=8080, help="Dashboard port (default: 8080)"
     )
     parser.add_argument(
-        "--host", type=str, default="0.0.0.0",
-        help="Dashboard host (default: 0.0.0.0)"
+        "--host", type=str, default="0.0.0.0", help="Dashboard host (default: 0.0.0.0)"
     )
     args = parser.parse_args()
 
     system = TradingSystem()
 
--- /mnt/c/documents/crypto-trading-bot/src/risk_manager.py	2026-01-15 00:53:03.864024+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/risk_manager.py	2026-02-04 21:34:25.290241+00:00
@@ -14,29 +14,31 @@
 from src.coin_config import get_tier, get_tier_config, TIERS
 from src.volatility import VolatilityCalculator
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 # Risk parameters - NON-NEGOTIABLE
-MAX_TRADE_PERCENT = 0.10      # 10% max per trade (~$100 for faster learning)
-MAX_EXPOSURE_PERCENT = 0.20   # 20% max total exposure (~$200 for diversity)
-MIN_BALANCE = 750.0           # 25% max drawdown - room for learning failures
-STOP_LOSS_PERCENT = 0.10      # 10% stop loss
-TAKE_PROFIT_USD = 1.0         # $1 take profit per trade
+MAX_TRADE_PERCENT = 0.10  # 10% max per trade (~$100 for faster learning)
+MAX_EXPOSURE_PERCENT = 0.20  # 20% max total exposure (~$200 for diversity)
+MIN_BALANCE = 750.0  # 25% max drawdown - room for learning failures
+STOP_LOSS_PERCENT = 0.10  # 10% stop loss
+TAKE_PROFIT_USD = 1.0  # $1 take profit per trade
 
 # Coin diversity - prevent fixation on single coin
-COIN_COOLDOWN_SECONDS = int(os.environ.get("COIN_COOLDOWN", 1800))  # 30 min default (TASK-020)
+COIN_COOLDOWN_SECONDS = int(
+    os.environ.get("COIN_COOLDOWN", 1800)
+)  # 30 min default (TASK-020)
 
 
 @dataclass
 class TradeValidation:
     """Result of trade validation check."""
+
     valid: bool
     reason: str
     max_allowed_size: float
 
 
@@ -81,16 +83,16 @@
 
         Returns:
             Dictionary with all risk parameters.
         """
         return {
-            'max_trade_percent': self.max_trade_percent,
-            'max_exposure_percent': self.max_exposure_percent,
-            'min_balance': self.min_balance,
-            'stop_loss_percent': self.stop_loss_percent,
-            'take_profit_usd': self.take_profit_usd,
-            'coin_cooldown_seconds': self.cooldown_seconds
+            "max_trade_percent": self.max_trade_percent,
+            "max_exposure_percent": self.max_exposure_percent,
+            "min_balance": self.min_balance,
+            "stop_loss_percent": self.stop_loss_percent,
+            "take_profit_usd": self.take_profit_usd,
+            "coin_cooldown_seconds": self.cooldown_seconds,
         }
 
     # =========================================================================
     # Coin Diversity - Cooldown Management (TASK-020: Persistent Cooldowns)
     # =========================================================================
@@ -119,19 +121,22 @@
                 for row in cursor.fetchall():
                     coin_name = row[0]
                     expires_at_str = row[1]
                     # Convert expires_at to timestamp (SQLite stores UTC)
                     from datetime import datetime, timezone
+
                     expires_at = datetime.strptime(expires_at_str, "%Y-%m-%d %H:%M:%S")
                     expires_at = expires_at.replace(tzinfo=timezone.utc)
                     # Store as start_time (expires_at - cooldown_seconds)
                     start_time = expires_at.timestamp() - self.cooldown_seconds
                     self.coin_cooldowns[coin_name] = start_time
                     loaded_count += 1
 
                 if loaded_count > 0:
-                    logger.info(f"Loaded {loaded_count} cooldowns from database: {list(self.coin_cooldowns.keys())}")
+                    logger.info(
+                        f"Loaded {loaded_count} cooldowns from database: {list(self.coin_cooldowns.keys())}"
+                    )
         except Exception as e:
             logger.warning(f"Failed to load cooldowns from database: {e}")
 
     def _persist_cooldown_to_db(self, coin_name: str):
         """Persist a cooldown to the database.
@@ -140,14 +145,17 @@
             coin_name: Name of the coin to persist cooldown for.
         """
         try:
             with self.db._get_connection() as conn:
                 cursor = conn.cursor()
-                cursor.execute("""
+                cursor.execute(
+                    """
                     INSERT OR REPLACE INTO coin_cooldowns (coin_name, expires_at)
                     VALUES (?, datetime('now', '+' || ? || ' seconds'))
-                """, (coin_name, self.cooldown_seconds))
+                """,
+                    (coin_name, self.cooldown_seconds),
+                )
                 conn.commit()
                 logger.info(f"Cooldown persisted to database for {coin_name}")
         except Exception as e:
             logger.warning(f"Failed to persist cooldown to database: {e}")
 
@@ -208,22 +216,21 @@
             coin_name: Name of the coin that was traded.
         """
         self.coin_cooldowns[coin_name] = time.time()
         # TASK-020: Persist to database
         self._persist_cooldown_to_db(coin_name)
-        logger.info(f"Cooldown started for {coin_name} ({self.cooldown_seconds}s = {self.cooldown_seconds//60} min)")
+        logger.info(
+            f"Cooldown started for {coin_name} ({self.cooldown_seconds}s = {self.cooldown_seconds//60} min)"
+        )
 
     def get_coins_in_cooldown(self) -> List[str]:
         """Get list of coins currently in cooldown.
 
         Returns:
             List of coin names that are in cooldown period.
         """
-        return [
-            coin for coin in self.coin_cooldowns
-            if self.is_coin_in_cooldown(coin)
-        ]
+        return [coin for coin in self.coin_cooldowns if self.is_coin_in_cooldown(coin)]
 
     def get_cooldown_status(self) -> Dict[str, int]:
         """Get cooldown status for all tracked coins.
 
         Returns:
@@ -254,12 +261,12 @@
 
         Returns:
             USD amount available for trading.
         """
         state = self.get_account_state()
-        balance = state.get('balance', 0)
-        in_positions = state.get('in_positions', 0)
+        balance = state.get("balance", 0)
+        in_positions = state.get("in_positions", 0)
 
         # Calculate limits
         max_exposure_usd = balance * self.max_exposure_percent
         exposure_remaining = max_exposure_usd - in_positions
 
@@ -277,21 +284,23 @@
 
         Returns:
             Maximum USD for one trade.
         """
         state = self.get_account_state()
-        balance = state.get('balance', 0)
+        balance = state.get("balance", 0)
 
         # Max per trade is 2% of balance
         max_per_trade = balance * self.max_trade_percent
 
         # But also limited by available for trading
         available = self.get_available_for_trading()
 
         return min(max_per_trade, available)
 
-    def validate_trade(self, coin: str, size_usd: float, action: str = "BUY") -> TradeValidation:
+    def validate_trade(
+        self, coin: str, size_usd: float, action: str = "BUY"
+    ) -> TradeValidation:
         """Validate a proposed trade against all risk rules.
 
         Args:
             coin: Cryptocurrency name (e.g., 'bitcoin').
             size_usd: Size of trade in USD.
@@ -299,68 +308,68 @@
 
         Returns:
             TradeValidation with valid flag, reason, and max allowed size.
         """
         state = self.get_account_state()
-        balance = state.get('balance', 0)
-        in_positions = state.get('in_positions', 0)
-        available_balance = state.get('available_balance', balance)
+        balance = state.get("balance", 0)
+        in_positions = state.get("in_positions", 0)
+        available_balance = state.get("available_balance", balance)
 
         max_allowed = self.calculate_max_trade_size()
 
         # Rule 0: Check coin cooldown (diversity enforcement)
         if action == "BUY" and self.is_coin_in_cooldown(coin):
             remaining = self.get_cooldown_remaining(coin)
             return TradeValidation(
                 valid=False,
                 reason=f"Coin {coin} in cooldown ({remaining}s remaining). Trade different coins for diversity.",
-                max_allowed_size=max_allowed
+                max_allowed_size=max_allowed,
             )
 
         # Rule 1: Check minimum balance would be maintained
         if action == "BUY":
             balance_after = balance - size_usd
             if balance_after < self.min_balance:
                 return TradeValidation(
                     valid=False,
                     reason=f"Trade would put balance (${balance_after:.2f}) below minimum (${self.min_balance})",
-                    max_allowed_size=max_allowed
+                    max_allowed_size=max_allowed,
                 )
 
         # Rule 2: Check max trade size (2% of balance)
         max_trade_usd = balance * self.max_trade_percent
         if size_usd > max_trade_usd:
             return TradeValidation(
                 valid=False,
                 reason=f"Trade size (${size_usd:.2f}) exceeds max per trade (${max_trade_usd:.2f}, {self.max_trade_percent*100}% of balance)",
-                max_allowed_size=max_allowed
+                max_allowed_size=max_allowed,
             )
 
         # Rule 3: Check max total exposure (10% of balance)
         if action == "BUY":
             exposure_after = in_positions + size_usd
             max_exposure_usd = balance * self.max_exposure_percent
             if exposure_after > max_exposure_usd:
                 return TradeValidation(
                     valid=False,
                     reason=f"Total exposure (${exposure_after:.2f}) would exceed max (${max_exposure_usd:.2f}, {self.max_exposure_percent*100}% of balance)",
-                    max_allowed_size=max_allowed
+                    max_allowed_size=max_allowed,
                 )
 
         # Rule 4: Check we have available balance
         if action == "BUY" and size_usd > available_balance:
             return TradeValidation(
                 valid=False,
                 reason=f"Trade size (${size_usd:.2f}) exceeds available balance (${available_balance:.2f})",
-                max_allowed_size=max_allowed
+                max_allowed_size=max_allowed,
             )
 
         # All rules passed
         return TradeValidation(
             valid=True,
             reason="Trade passes all risk checks",
-            max_allowed_size=max_allowed
+            max_allowed_size=max_allowed,
         )
 
     def calculate_stop_loss(self, entry_price: float) -> float:
         """Calculate stop loss price for a trade.
 
@@ -402,11 +411,13 @@
             True if stop loss triggered (should exit).
         """
         stop_loss_price = self.calculate_stop_loss(entry_price)
         return current_price <= stop_loss_price
 
-    def check_take_profit(self, entry_price: float, current_price: float, size_usd: float) -> bool:
+    def check_take_profit(
+        self, entry_price: float, current_price: float, size_usd: float
+    ) -> bool:
         """Check if take profit has been reached.
 
         Args:
             entry_price: Entry price in USD.
             current_price: Current price in USD.
@@ -416,11 +427,13 @@
             True if take profit reached (should exit).
         """
         take_profit_price = self.calculate_take_profit(entry_price, size_usd)
         return current_price >= take_profit_price
 
-    def should_exit_trade(self, entry_price: float, current_price: float, size_usd: float) -> Dict[str, Any]:
+    def should_exit_trade(
+        self, entry_price: float, current_price: float, size_usd: float
+    ) -> Dict[str, Any]:
         """Check if a trade should be exited.
 
         Args:
             entry_price: Entry price in USD.
             current_price: Current price in USD.
@@ -435,34 +448,36 @@
         pnl_pct = price_change_pct * 100
 
         # Check stop loss
         if self.check_stop_loss(entry_price, current_price):
             return {
-                'should_exit': True,
-                'reason': 'stop_loss',
-                'pnl_usd': pnl_usd,
-                'pnl_pct': pnl_pct
+                "should_exit": True,
+                "reason": "stop_loss",
+                "pnl_usd": pnl_usd,
+                "pnl_pct": pnl_pct,
             }
 
         # Check take profit
         if self.check_take_profit(entry_price, current_price, size_usd):
             return {
-                'should_exit': True,
-                'reason': 'take_profit',
-                'pnl_usd': pnl_usd,
-                'pnl_pct': pnl_pct
+                "should_exit": True,
+                "reason": "take_profit",
+                "pnl_usd": pnl_usd,
+                "pnl_pct": pnl_pct,
             }
 
         # No exit triggered
         return {
-            'should_exit': False,
-            'reason': 'none',
-            'pnl_usd': pnl_usd,
-            'pnl_pct': pnl_pct
+            "should_exit": False,
+            "reason": "none",
+            "pnl_usd": pnl_usd,
+            "pnl_pct": pnl_pct,
         }
 
-    def log_risk_check(self, coin: str, size_usd: float, validation: TradeValidation) -> None:
+    def log_risk_check(
+        self, coin: str, size_usd: float, validation: TradeValidation
+    ) -> None:
         """Log a risk check to the activity log.
 
         Args:
             coin: Cryptocurrency name.
             size_usd: Proposed trade size.
@@ -472,11 +487,11 @@
         description = f"Risk check for {coin} ${size_usd:.2f}: {validation.reason}"
 
         self.db.log_activity(
             activity_type=activity_type,
             description=description,
-            details=f"max_allowed: ${validation.max_allowed_size:.2f}"
+            details=f"max_allowed: ${validation.max_allowed_size:.2f}",
         )
 
     # =========================================================================
     # TIER-BASED RISK MANAGEMENT
     # =========================================================================
@@ -498,20 +513,20 @@
             - max_concurrent: Max positions in this tier
         """
         tier = get_tier(coin)
         config = get_tier_config(coin)
         state = self.get_account_state()
-        balance = state.get('balance', 0)
+        balance = state.get("balance", 0)
 
         return {
-            'tier': tier,
-            'tier_name': config.name,
-            'max_position_pct': config.max_position_pct,
-            'max_position_usd': balance * config.max_position_pct,
-            'stop_loss_pct': config.stop_loss_pct,
-            'take_profit_usd': config.take_profit_usd,
-            'max_concurrent': config.max_concurrent
+            "tier": tier,
+            "tier_name": config.name,
+            "max_position_pct": config.max_position_pct,
+            "max_position_usd": balance * config.max_position_pct,
+            "stop_loss_pct": config.stop_loss_pct,
+            "take_profit_usd": config.take_profit_usd,
+            "max_concurrent": config.max_concurrent,
         }
 
     def count_positions_in_tier(self, tier: int) -> int:
         """Count open positions in a specific tier.
 
@@ -526,11 +541,13 @@
             cursor.execute("SELECT coin_name FROM open_trades")
             open_coins = [row[0] for row in cursor.fetchall()]
 
         return sum(1 for coin in open_coins if get_tier(coin) == tier)
 
-    def validate_trade_with_tier(self, coin: str, size_usd: float, action: str = "BUY") -> TradeValidation:
+    def validate_trade_with_tier(
+        self, coin: str, size_usd: float, action: str = "BUY"
+    ) -> TradeValidation:
         """Validate a trade with tier-specific rules.
 
         This extends validate_trade with tier-based limits:
         - Tier-specific position size limits
         - Per-tier concurrent position limits
@@ -548,35 +565,35 @@
         if not base_validation.valid:
             return base_validation
 
         # Get tier-specific limits
         tier_limits = self.get_tier_limits(coin)
-        tier = tier_limits['tier']
+        tier = tier_limits["tier"]
         config = get_tier_config(coin)
 
         # Check tier-specific position size
-        if size_usd > tier_limits['max_position_usd']:
+        if size_usd > tier_limits["max_position_usd"]:
             return TradeValidation(
                 valid=False,
                 reason=f"Trade ${size_usd:.2f} exceeds {tier_limits['tier_name']} max ${tier_limits['max_position_usd']:.2f} ({config.max_position_pct:.0%})",
-                max_allowed_size=tier_limits['max_position_usd']
+                max_allowed_size=tier_limits["max_position_usd"],
             )
 
         # Check tier concurrent position limit
         if action == "BUY":
             current_in_tier = self.count_positions_in_tier(tier)
             if current_in_tier >= config.max_concurrent:
                 return TradeValidation(
                     valid=False,
                     reason=f"Already have {current_in_tier}/{config.max_concurrent} positions in {tier_limits['tier_name']} tier",
-                    max_allowed_size=0
+                    max_allowed_size=0,
                 )
 
         return TradeValidation(
             valid=True,
             reason=f"Trade passes all checks (Tier {tier}: {tier_limits['tier_name']})",
-            max_allowed_size=tier_limits['max_position_usd']
+            max_allowed_size=tier_limits["max_position_usd"],
         )
 
     def calculate_tier_stop_loss(self, coin: str, entry_price: float) -> float:
         """Calculate tier-specific stop loss price.
 
@@ -590,11 +607,13 @@
             Stop loss price in USD.
         """
         config = get_tier_config(coin)
         return entry_price * (1 - config.stop_loss_pct)
 
-    def calculate_tier_take_profit(self, coin: str, entry_price: float, size_usd: float) -> float:
+    def calculate_tier_take_profit(
+        self, coin: str, entry_price: float, size_usd: float
+    ) -> float:
         """Calculate tier-specific take profit price.
 
         Uses consistent $1 take profit across all tiers.
 
         Args:
@@ -632,55 +651,55 @@
 
         # Check tier-specific stop loss
         stop_loss_price = self.calculate_tier_stop_loss(coin, entry_price)
         if current_price <= stop_loss_price:
             return {
-                'should_exit': True,
-                'reason': 'stop_loss',
-                'pnl_usd': pnl_usd,
-                'pnl_pct': pnl_pct,
-                'tier': get_tier(coin)
+                "should_exit": True,
+                "reason": "stop_loss",
+                "pnl_usd": pnl_usd,
+                "pnl_pct": pnl_pct,
+                "tier": get_tier(coin),
             }
 
         # Check take profit ($1)
         take_profit_price = self.calculate_tier_take_profit(coin, entry_price, size_usd)
         if current_price >= take_profit_price:
             return {
-                'should_exit': True,
-                'reason': 'take_profit',
-                'pnl_usd': pnl_usd,
-                'pnl_pct': pnl_pct,
-                'tier': get_tier(coin)
+                "should_exit": True,
+                "reason": "take_profit",
+                "pnl_usd": pnl_usd,
+                "pnl_pct": pnl_pct,
+                "tier": get_tier(coin),
             }
 
         return {
-            'should_exit': False,
-            'reason': 'none',
-            'pnl_usd': pnl_usd,
-            'pnl_pct': pnl_pct,
-            'tier': get_tier(coin)
+            "should_exit": False,
+            "reason": "none",
+            "pnl_usd": pnl_usd,
+            "pnl_pct": pnl_pct,
+            "tier": get_tier(coin),
         }
 
     def get_tier_summary(self) -> Dict[int, Dict[str, Any]]:
         """Get summary of positions and limits by tier.
 
         Returns:
             Dict mapping tier number to summary stats.
         """
         result = {}
         state = self.get_account_state()
-        balance = state.get('balance', 0)
+        balance = state.get("balance", 0)
 
         for tier, config in TIERS.items():
             positions = self.count_positions_in_tier(tier)
             result[tier] = {
-                'name': config.name,
-                'positions': positions,
-                'max_positions': config.max_concurrent,
-                'slots_available': config.max_concurrent - positions,
-                'max_position_usd': balance * config.max_position_pct,
-                'stop_loss_pct': config.stop_loss_pct
+                "name": config.name,
+                "positions": positions,
+                "max_positions": config.max_concurrent,
+                "slots_available": config.max_concurrent - positions,
+                "max_position_usd": balance * config.max_position_pct,
+                "stop_loss_pct": config.stop_loss_pct,
             }
 
         return result
 
     # =========================================================================
@@ -703,33 +722,33 @@
             - volatility_multiplier: Position size multiplier
             - adjusted_max_position: Volatility-adjusted max position
             - position_reduction_pct: How much position is reduced
         """
         tier_limits = self.get_tier_limits(coin)
-        base_position = tier_limits['max_position_usd']
+        base_position = tier_limits["max_position_usd"]
 
         # Get volatility adjustment
         try:
             vc = VolatilityCalculator(db=self.db)
             adjusted, vol_info = vc.get_adjusted_position_size(coin, base_position)
 
             return {
                 **tier_limits,
-                'volatility_score': vol_info['volatility_score'],
-                'volatility_multiplier': vol_info['multiplier'],
-                'adjusted_max_position': adjusted,
-                'position_reduction_pct': vol_info['reduction_pct']
+                "volatility_score": vol_info["volatility_score"],
+                "volatility_multiplier": vol_info["multiplier"],
+                "adjusted_max_position": adjusted,
+                "position_reduction_pct": vol_info["reduction_pct"],
             }
         except Exception as e:
             logger.warning(f"Volatility calculation failed for {coin}: {e}")
             # Fall back to tier limits without adjustment
             return {
                 **tier_limits,
-                'volatility_score': 50,  # Assume normal
-                'volatility_multiplier': 1.0,
-                'adjusted_max_position': base_position,
-                'position_reduction_pct': 0
+                "volatility_score": 50,  # Assume normal
+                "volatility_multiplier": 1.0,
+                "adjusted_max_position": base_position,
+                "position_reduction_pct": 0,
             }
 
     def calculate_volatility_stop_loss(self, coin: str, entry_price: float) -> float:
         """Calculate volatility-adjusted stop-loss price.
 
@@ -782,37 +801,37 @@
 
         # Check volatility-adjusted stop loss
         stop_loss_price = self.calculate_volatility_stop_loss(coin, entry_price)
         if current_price <= stop_loss_price:
             return {
-                'should_exit': True,
-                'reason': 'stop_loss',
-                'pnl_usd': pnl_usd,
-                'pnl_pct': pnl_pct,
-                'tier': get_tier(coin),
-                'volatility_score': vol_score
+                "should_exit": True,
+                "reason": "stop_loss",
+                "pnl_usd": pnl_usd,
+                "pnl_pct": pnl_pct,
+                "tier": get_tier(coin),
+                "volatility_score": vol_score,
             }
 
         # Check take profit ($1 - consistent across tiers)
         take_profit_price = self.calculate_tier_take_profit(coin, entry_price, size_usd)
         if current_price >= take_profit_price:
             return {
-                'should_exit': True,
-                'reason': 'take_profit',
-                'pnl_usd': pnl_usd,
-                'pnl_pct': pnl_pct,
-                'tier': get_tier(coin),
-                'volatility_score': vol_score
+                "should_exit": True,
+                "reason": "take_profit",
+                "pnl_usd": pnl_usd,
+                "pnl_pct": pnl_pct,
+                "tier": get_tier(coin),
+                "volatility_score": vol_score,
             }
 
         return {
-            'should_exit': False,
-            'reason': 'none',
-            'pnl_usd': pnl_usd,
-            'pnl_pct': pnl_pct,
-            'tier': get_tier(coin),
-            'volatility_score': vol_score
+            "should_exit": False,
+            "reason": "none",
+            "pnl_usd": pnl_usd,
+            "pnl_pct": pnl_pct,
+            "tier": get_tier(coin),
+            "volatility_score": vol_score,
         }
 
 
 def get_risk_summary(db: Database = None) -> Dict[str, Any]:
     """Get a summary of current risk status.
@@ -824,17 +843,17 @@
         Dictionary with risk summary.
     """
     rm = RiskManager(db=db)
     state = rm.get_account_state()
 
-    balance = state.get('balance', 0)
-    in_positions = state.get('in_positions', 0)
+    balance = state.get("balance", 0)
+    in_positions = state.get("in_positions", 0)
 
     return {
-        'balance': balance,
-        'in_positions': in_positions,
-        'exposure_percent': (in_positions / balance * 100) if balance > 0 else 0,
-        'available_for_trading': rm.get_available_for_trading(),
-        'max_single_trade': rm.calculate_max_trade_size(),
-        'above_minimum': balance > rm.min_balance,
-        'risk_parameters': rm.get_risk_parameters()
+        "balance": balance,
+        "in_positions": in_positions,
+        "exposure_percent": (in_positions / balance * 100) if balance > 0 else 0,
+        "available_for_trading": rm.get_available_for_trading(),
+        "max_single_trade": rm.calculate_max_trade_size(),
+        "above_minimum": balance > rm.min_balance,
+        "risk_parameters": rm.get_risk_parameters(),
     }
would reformat /mnt/c/documents/crypto-trading-bot/src/main.py
would reformat /mnt/c/documents/crypto-trading-bot/src/risk_manager.py
--- /mnt/c/documents/crypto-trading-bot/src/technical/manager.py	2026-02-04 15:48:31.171324+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/technical/manager.py	2026-02-04 21:34:25.305685+00:00
@@ -1,6 +1,7 @@
 """Technical Manager - Aggregates all technical indicators for Strategist."""
+
 import logging
 from dataclasses import dataclass, field
 from datetime import datetime
 from typing import List, Optional, Dict, Tuple
 
@@ -17,10 +18,11 @@
 
 
 @dataclass
 class TechnicalSnapshot:
     """Complete technical analysis snapshot for a coin."""
+
     coin: str
     rsi: Optional[RSIData] = None
     vwap: Optional[VWAPData] = None
     atr: Optional[ATRData] = None
     funding: Optional[FundingData] = None
@@ -96,11 +98,14 @@
                 signals.append("Extreme shorts (squeeze potential)")
             if self.vwap and self.vwap.is_below_vwap:
                 signals.append("Below VWAP")
             if self.orderbook and self.orderbook.is_bullish:
                 signals.append("Bullish order book")
-            if self.volume_profile and self.volume_profile.position_vs_poc == "below_poc":
+            if (
+                self.volume_profile
+                and self.volume_profile.position_vs_poc == "below_poc"
+            ):
                 signals.append("Below POC")
 
         elif direction == "SHORT":
             if self.is_overbought:
                 signals.append("RSI overbought")
@@ -110,11 +115,14 @@
                 signals.append("Extreme longs (dump potential)")
             if self.vwap and self.vwap.is_above_vwap:
                 signals.append("Above VWAP")
             if self.orderbook and self.orderbook.is_bearish:
                 signals.append("Bearish order book")
-            if self.volume_profile and self.volume_profile.position_vs_poc == "above_poc":
+            if (
+                self.volume_profile
+                and self.volume_profile.position_vs_poc == "above_poc"
+            ):
                 signals.append("Above POC")
 
         return signals
 
     def to_prompt(self) -> str:
@@ -125,26 +133,34 @@
             condition = self.rsi.condition
             lines.append(f"RSI: {self.rsi.value:.1f} ({condition})")
 
         if self.vwap:
             pos = self.vwap.position
-            lines.append(f"VWAP: ${self.vwap.vwap:.2f} ({self.vwap.deviation_pct:+.1f}%, {pos})")
+            lines.append(
+                f"VWAP: ${self.vwap.vwap:.2f} ({self.vwap.deviation_pct:+.1f}%, {pos})"
+            )
 
         if self.atr:
-            lines.append(f"ATR: ${self.atr.atr:.2f} ({self.atr.volatility_pct:.1f}% volatility)")
+            lines.append(
+                f"ATR: ${self.atr.atr:.2f} ({self.atr.volatility_pct:.1f}% volatility)"
+            )
 
         if self.funding:
             bias = self.funding_bias
             lines.append(f"Funding: {self.funding.current_rate:.4%} ({bias})")
 
         if self.sr_levels:
             if self.sr_levels.nearest_support:
                 dist = self.sr_levels.support_distance_pct
-                lines.append(f"Support: ${self.sr_levels.nearest_support.price:.2f} ({dist:.1f}% below)")
+                lines.append(
+                    f"Support: ${self.sr_levels.nearest_support.price:.2f} ({dist:.1f}% below)"
+                )
             if self.sr_levels.nearest_resistance:
                 dist = self.sr_levels.resistance_distance_pct
-                lines.append(f"Resistance: ${self.sr_levels.nearest_resistance.price:.2f} ({dist:.1f}% above)")
+                lines.append(
+                    f"Resistance: ${self.sr_levels.nearest_resistance.price:.2f} ({dist:.1f}% above)"
+                )
 
         if self.volume_profile:
             vp = self.volume_profile
             lines.append(f"POC: ${vp.poc:.2f} ({vp.position_vs_poc})")
 
@@ -186,11 +202,11 @@
         vwap_calculator: Optional[VWAPCalculator] = None,
         atr_calculator: Optional[ATRCalculator] = None,
         funding_fetcher: Optional[FundingRateFetcher] = None,
         sr_detector: Optional[SRLevelDetector] = None,
         volume_profile: Optional[VolumeProfileCalculator] = None,
-        orderbook_analyzer: Optional[OrderBookAnalyzer] = None
+        orderbook_analyzer: Optional[OrderBookAnalyzer] = None,
     ):
         """Initialize with technical indicator sources.
 
         Args:
             candle_fetcher: CandleFetcher instance (required)
@@ -227,18 +243,14 @@
             atr=self._get_atr(coin),
             funding=self._get_funding(coin),
             sr_levels=self._get_sr_levels(coin),
             volume_profile=self._get_volume_profile(coin),
             orderbook=self._get_orderbook(coin),
-            timestamp=datetime.now()
+            timestamp=datetime.now(),
         )
 
-    def get_trade_setup_quality(
-        self,
-        coin: str,
-        direction: str
-    ) -> Tuple[float, str]:
+    def get_trade_setup_quality(self, coin: str, direction: str) -> Tuple[float, str]:
         """Calculate trade setup quality score.
 
         Args:
             coin: Coin symbol
             direction: "LONG" or "SHORT"
@@ -306,14 +318,11 @@
         score = max(0, min(100, score))
 
         return score, "; ".join(reasons) if reasons else "neutral setup"
 
     def get_dynamic_stops(
-        self,
-        coin: str,
-        direction: str,
-        entry_price: float
+        self, coin: str, direction: str, entry_price: float
     ) -> Tuple[float, float]:
         """Calculate dynamic stop loss and take profit.
 
         Uses ATR and S/R levels for intelligent stop placement.
 
@@ -342,11 +351,13 @@
             # Stop below entry
             stop_loss = entry_price - (atr_value * stop_atr_mult)
 
             # If we have support, use it if closer
             if sr_data and sr_data.nearest_support:
-                support_stop = sr_data.nearest_support.zone_low * 0.995  # Just below zone
+                support_stop = (
+                    sr_data.nearest_support.zone_low * 0.995
+                )  # Just below zone
                 if support_stop > stop_loss and support_stop < entry_price:
                     stop_loss = support_stop
 
             # Take profit above entry
             take_profit = entry_price + (atr_value * tp_atr_mult)
@@ -376,16 +387,11 @@
                 if support_tp > take_profit and support_tp < entry_price:
                     take_profit = support_tp
 
         return stop_loss, take_profit
 
-    def get_position_size(
-        self,
-        coin: str,
-        base_size: float,
-        direction: str
-    ) -> float:
+    def get_position_size(self, coin: str, base_size: float, direction: str) -> float:
         """Calculate position size based on volatility and setup quality.
 
         Args:
             coin: Coin symbol
             base_size: Base position size
would reformat /mnt/c/documents/crypto-trading-bot/src/technical/manager.py
--- /mnt/c/documents/crypto-trading-bot/src/volatility.py	2026-01-14 18:42:59.063065+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/volatility.py	2026-02-04 21:34:25.311769+00:00
@@ -20,22 +20,21 @@
 from src.database import Database
 from src.coin_config import get_tier, get_tier_config
 
 # Configure logging
 logging.basicConfig(
-    level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
+    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
 )
 logger = logging.getLogger(__name__)
 
 
 # Volatility multiplier thresholds (score -> multiplier)
 VOLATILITY_MULTIPLIERS = [
-    (20, 1.2),   # Very low volatility: +20% position
-    (40, 1.0),   # Low volatility: no change
-    (60, 0.9),   # Normal volatility: -10% position
-    (80, 0.7),   # High volatility: -30% position
+    (20, 1.2),  # Very low volatility: +20% position
+    (40, 1.0),  # Low volatility: no change
+    (60, 0.9),  # Normal volatility: -10% position
+    (80, 0.7),  # High volatility: -30% position
     (100, 0.5),  # Extreme volatility: -50% position
 ]
 
 # ATR multipliers by tier (for stop-loss calculation)
 ATR_MULTIPLIERS = {
@@ -110,14 +109,17 @@
         if price <= 0:
             return
 
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 INSERT INTO price_history (coin, price_usd)
                 VALUES (?, ?)
-            """, (coin, price))
+            """,
+                (coin, price),
+            )
             conn.commit()
 
     def record_all_prices(self, prices: Dict[str, float]) -> int:
         """Record prices for all coins in one transaction.
 
@@ -130,23 +132,24 @@
         count = 0
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
             for coin, price in prices.items():
                 if price and price > 0:
-                    cursor.execute("""
+                    cursor.execute(
+                        """
                         INSERT INTO price_history (coin, price_usd)
                         VALUES (?, ?)
-                    """, (coin, price))
+                    """,
+                        (coin, price),
+                    )
                     count += 1
             conn.commit()
 
         logger.debug(f"Recorded {count} price snapshots")
         return count
 
-    def get_price_history(
-        self, coin: str, hours: int = 24
-    ) -> List[Tuple[float, str]]:
+    def get_price_history(self, coin: str, hours: int = 24) -> List[Tuple[float, str]]:
         """Get price history for a coin.
 
         Args:
             coin: Coin ID.
             hours: How many hours of history to retrieve.
@@ -154,27 +157,27 @@
         Returns:
             List of (price, timestamp) tuples, oldest first.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 SELECT price_usd, timestamp
                 FROM price_history
                 WHERE coin = ?
                 AND timestamp > datetime('now', ?)
                 ORDER BY timestamp ASC
-            """, (coin, f'-{hours} hours'))
+            """,
+                (coin, f"-{hours} hours"),
+            )
             return [(row[0], row[1]) for row in cursor.fetchall()]
 
     def get_history_count(self, coin: str) -> int:
         """Get number of price history records for a coin."""
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute(
-                "SELECT COUNT(*) FROM price_history WHERE coin = ?",
-                (coin,)
-            )
+            cursor.execute("SELECT COUNT(*) FROM price_history WHERE coin = ?", (coin,))
             return cursor.fetchone()[0]
 
     def calculate_volatility(self, coin: str, hours: int = 24) -> float:
         """Calculate volatility as standard deviation of returns.
 
@@ -201,12 +204,12 @@
 
         # Calculate returns
         prices = [h[0] for h in history]
         returns = []
         for i in range(1, len(prices)):
-            if prices[i-1] > 0:
-                ret = (prices[i] - prices[i-1]) / prices[i-1]
+            if prices[i - 1] > 0:
+                ret = (prices[i] - prices[i - 1]) / prices[i - 1]
                 returns.append(ret)
 
         if len(returns) < 2:
             config = get_tier_config(coin)
             return config.stop_loss_pct
@@ -247,14 +250,11 @@
 
         # Get 24h change as additional signal
         change_24h = 0
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute(
-                "SELECT change_24h FROM market_data WHERE coin = ?",
-                (coin,)
-            )
+            cursor.execute("SELECT change_24h FROM market_data WHERE coin = ?", (coin,))
             row = cursor.fetchone()
             if row and row[0]:
                 change_24h = abs(row[0])
 
         # Combine volatility and 24h change
@@ -332,15 +332,15 @@
         vol_score = self.calculate_volatility_score(coin)
         multiplier = self.get_volatility_multiplier(vol_score)
         adjusted = base_position * multiplier
 
         return adjusted, {
-            'volatility_score': vol_score,
-            'multiplier': multiplier,
-            'base_position': base_position,
-            'adjusted_position': adjusted,
-            'reduction_pct': (1 - multiplier) * 100
+            "volatility_score": vol_score,
+            "multiplier": multiplier,
+            "base_position": base_position,
+            "adjusted_position": adjusted,
+            "reduction_pct": (1 - multiplier) * 100,
         }
 
     def cleanup_old_history(self, days: int = 7) -> int:
         """Remove price history older than specified days.
 
@@ -352,14 +352,17 @@
         Returns:
             Number of records deleted.
         """
         with self.db._get_connection() as conn:
             cursor = conn.cursor()
-            cursor.execute("""
+            cursor.execute(
+                """
                 DELETE FROM price_history
                 WHERE timestamp < datetime('now', ?)
-            """, (f'-{days} days',))
+            """,
+                (f"-{days} days",),
+            )
             deleted = cursor.rowcount
             conn.commit()
 
         if deleted > 0:
             logger.info(f"Cleaned up {deleted} old price history records")
@@ -382,15 +385,15 @@
             vol_score = self.calculate_volatility_score(coin)
             multiplier = self.get_volatility_multiplier(vol_score)
             history_count = self.get_history_count(coin)
 
             summary[coin] = {
-                'volatility_score': vol_score,
-                'multiplier': multiplier,
-                'tier': get_tier(coin),
-                'history_records': history_count,
-                'has_enough_data': history_count >= 3
+                "volatility_score": vol_score,
+                "multiplier": multiplier,
+                "tier": get_tier(coin),
+                "history_records": history_count,
+                "has_enough_data": history_count >= 3,
             }
 
         return summary
 
     def get_database_stats(self) -> Dict[str, Any]:
@@ -416,15 +419,15 @@
 
             # Records per coin (average)
             avg_per_coin = total_records / unique_coins if unique_coins > 0 else 0
 
         return {
-            'total_records': total_records,
-            'unique_coins': unique_coins,
-            'avg_records_per_coin': avg_per_coin,
-            'oldest_record': oldest,
-            'estimated_size_kb': total_records * 50 / 1024  # ~50 bytes per record
+            "total_records": total_records,
+            "unique_coins": unique_coins,
+            "avg_records_per_coin": avg_per_coin,
+            "oldest_record": oldest,
+            "estimated_size_kb": total_records * 50 / 1024,  # ~50 bytes per record
         }
 
 
 # Convenience functions for external use
 def get_volatility_score(coin: str, db: Database = None) -> int:
@@ -455,11 +458,11 @@
     print(f"  Unique coins: {stats['unique_coins']}")
     print(f"  Estimated size: {stats['estimated_size_kb']:.1f} KB")
 
     # Show volatility for sample coins
     print(f"\nVolatility Scores (cached for 5 min):")
-    for coin in ['bitcoin', 'ethereum', 'pepe']:
+    for coin in ["bitcoin", "ethereum", "pepe"]:
         score = vc.calculate_volatility_score(coin)
         mult = vc.get_volatility_multiplier(score)
         tier = get_tier(coin)
         print(f"  {coin}: Score={score}, Multiplier={mult}x, Tier={tier}")
 
would reformat /mnt/c/documents/crypto-trading-bot/src/volatility.py
--- /mnt/c/documents/crypto-trading-bot/src/reflection.py	2026-02-03 18:12:48.912959+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/reflection.py	2026-02-04 21:34:25.348583+00:00
@@ -30,10 +30,11 @@
     TimeAnalysis,
 )
 
 # Import for type hint only - avoid circular import
 from typing import TYPE_CHECKING
+
 if TYPE_CHECKING:
     from src.adaptation import AdaptationEngine
 
 logger = logging.getLogger(__name__)
 
@@ -181,24 +182,30 @@
 
     def should_reflect(self) -> bool:
         """Check if reflection should run now."""
         # Time-based trigger
         if self.last_reflection_time:
-            hours_since = (datetime.now() - self.last_reflection_time).total_seconds() / 3600
+            hours_since = (
+                datetime.now() - self.last_reflection_time
+            ).total_seconds() / 3600
             if hours_since >= self.REFLECTION_INTERVAL_HOURS:
                 logger.info(f"Time trigger: {hours_since:.1f}h since last reflection")
                 return True
 
         # Trade count trigger
         if self.trades_since_reflection >= self.REFLECTION_TRADE_COUNT:
-            logger.info(f"Trade trigger: {self.trades_since_reflection} trades since last reflection")
+            logger.info(
+                f"Trade trigger: {self.trades_since_reflection} trades since last reflection"
+            )
             return True
 
         # First reflection (no history) - need minimum trades
         if self.last_reflection_time is None:
             if self.trades_since_reflection >= self.MIN_TRADES_FOR_REFLECTION:
-                logger.info(f"Initial reflection: {self.trades_since_reflection} trades available")
+                logger.info(
+                    f"Initial reflection: {self.trades_since_reflection} trades available"
+                )
                 return True
 
         return False
 
     # =========================================================================
@@ -355,24 +362,26 @@
                 else:
                     trend = "stable"
             else:
                 trend = "insufficient_data"
 
-            analyses.append(CoinAnalysis(
-                coin=coin,
-                total_trades=len(coin_list),
-                wins=len(winners),
-                losses=len(losers),
-                win_rate=len(winners) / len(coin_list) if coin_list else 0,
-                total_pnl=sum(pnls),
-                avg_pnl=sum(pnls) / len(pnls) if pnls else 0,
-                avg_winner=sum(winners) / len(winners) if winners else 0,
-                avg_loser=sum(losers) / len(losers) if losers else 0,
-                best_trade=max(pnls) if pnls else 0,
-                worst_trade=min(pnls) if pnls else 0,
-                trend=trend,
-            ))
+            analyses.append(
+                CoinAnalysis(
+                    coin=coin,
+                    total_trades=len(coin_list),
+                    wins=len(winners),
+                    losses=len(losers),
+                    win_rate=len(winners) / len(coin_list) if coin_list else 0,
+                    total_pnl=sum(pnls),
+                    avg_pnl=sum(pnls) / len(pnls) if pnls else 0,
+                    avg_winner=sum(winners) / len(winners) if winners else 0,
+                    avg_loser=sum(losers) / len(losers) if losers else 0,
+                    best_trade=max(pnls) if pnls else 0,
+                    worst_trade=min(pnls) if pnls else 0,
+                    trend=trend,
+                )
+            )
 
         # Sort by total P&L
         analyses.sort(key=lambda x: x.total_pnl, reverse=True)
         return analyses
 
@@ -398,21 +407,23 @@
                     if p.pattern_id == pattern_id:
                         description = p.description
                         confidence = p.confidence
                         break
 
-            analyses.append(PatternAnalysis(
-                pattern_id=pattern_id,
-                description=description,
-                total_trades=len(pattern_list),
-                wins=wins,
-                losses=len(pattern_list) - wins,
-                win_rate=wins / len(pattern_list) if pattern_list else 0,
-                total_pnl=sum(pnls),
-                avg_pnl=sum(pnls) / len(pnls) if pnls else 0,
-                confidence=confidence,
-            ))
+            analyses.append(
+                PatternAnalysis(
+                    pattern_id=pattern_id,
+                    description=description,
+                    total_trades=len(pattern_list),
+                    wins=wins,
+                    losses=len(pattern_list) - wins,
+                    win_rate=wins / len(pattern_list) if pattern_list else 0,
+                    total_pnl=sum(pnls),
+                    avg_pnl=sum(pnls) / len(pnls) if pnls else 0,
+                    confidence=confidence,
+                )
+            )
 
         analyses.sort(key=lambda x: x.total_pnl, reverse=True)
         return analyses
 
     def _analyze_by_time(self, trades: List[JournalEntry]) -> TimeAnalysis:
@@ -439,17 +450,25 @@
             wins = sum(1 for t in day_list if t.pnl_usd and t.pnl_usd > 0)
             day_win_rates[day] = wins / len(day_list) if day_list else 0
             day_trade_counts[day] = len(day_list)
 
         # Find best/worst hours (with minimum 2 trades)
-        valid_hours = {h: r for h, r in hour_win_rates.items() if hour_trade_counts.get(h, 0) >= 2}
-        best_hours = sorted(valid_hours.keys(), key=lambda h: valid_hours[h], reverse=True)[:3]
+        valid_hours = {
+            h: r for h, r in hour_win_rates.items() if hour_trade_counts.get(h, 0) >= 2
+        }
+        best_hours = sorted(
+            valid_hours.keys(), key=lambda h: valid_hours[h], reverse=True
+        )[:3]
         worst_hours = sorted(valid_hours.keys(), key=lambda h: valid_hours[h])[:3]
 
         # Find best/worst days (with minimum 2 trades)
-        valid_days = {d: r for d, r in day_win_rates.items() if day_trade_counts.get(d, 0) >= 2}
-        best_days = sorted(valid_days.keys(), key=lambda d: valid_days[d], reverse=True)[:2]
+        valid_days = {
+            d: r for d, r in day_win_rates.items() if day_trade_counts.get(d, 0) >= 2
+        }
+        best_days = sorted(
+            valid_days.keys(), key=lambda d: valid_days[d], reverse=True
+        )[:2]
         worst_days = sorted(valid_days.keys(), key=lambda d: valid_days[d])[:2]
 
         # Weekend vs weekday
         weekend_trades = [t for t in trades if t.day_of_week >= 5]
         weekday_trades = [t for t in trades if t.day_of_week < 5]
@@ -465,12 +484,16 @@
             best_days=best_days,
             worst_days=worst_days,
             day_win_rates=day_win_rates,
             day_trade_counts=day_trade_counts,
             weekend_trades=len(weekend_trades),
-            weekend_win_rate=weekend_wins / len(weekend_trades) if weekend_trades else 0,
-            weekday_win_rate=weekday_wins / len(weekday_trades) if weekday_trades else 0,
+            weekend_win_rate=(
+                weekend_wins / len(weekend_trades) if weekend_trades else 0
+            ),
+            weekday_win_rate=(
+                weekday_wins / len(weekday_trades) if weekday_trades else 0
+            ),
         )
 
     def _analyze_by_regime(self, trades: List[JournalEntry]) -> RegimeAnalysis:
         """Analyze performance by market regime."""
         btc_up = [t for t in trades if t.btc_trend == "up"]
@@ -528,11 +551,13 @@
         # Average P&L by exit type
         sl_pnls = [t.pnl_usd or 0 for t in stop_losses]
         tp_pnls = [t.pnl_usd or 0 for t in take_profits]
 
         # Early exits (trades with missed_profit > 0)
-        early_exits = [t for t in trades if t.missed_profit_usd and t.missed_profit_usd > 1.0]
+        early_exits = [
+            t for t in trades if t.missed_profit_usd and t.missed_profit_usd > 1.0
+        ]
         missed_profits = [t.missed_profit_usd or 0 for t in early_exits]
 
         return ExitAnalysis(
             stop_loss_count=len(stop_losses),
             take_profit_count=len(take_profits),
@@ -541,11 +566,13 @@
             stop_loss_rate=len(stop_losses) / total if total else 0,
             take_profit_rate=len(take_profits) / total if total else 0,
             avg_stop_loss_pnl=sum(sl_pnls) / len(sl_pnls) if sl_pnls else 0,
             avg_take_profit_pnl=sum(tp_pnls) / len(tp_pnls) if tp_pnls else 0,
             early_exits=len(early_exits),
-            avg_missed_profit=sum(missed_profits) / len(missed_profits) if missed_profits else 0,
+            avg_missed_profit=(
+                sum(missed_profits) / len(missed_profits) if missed_profits else 0
+            ),
         )
 
     # =========================================================================
     # LLM Insight Generation
     # =========================================================================
@@ -626,18 +653,36 @@
         for p in pattern_analyses[:5]:
             pattern_lines.append(
                 f"  {p.pattern_id}: {p.total_trades} trades, {p.win_rate:.0%} win rate, "
                 f"${p.total_pnl:+.2f} P&L"
             )
-        pattern_text = "\n".join(pattern_lines) if pattern_lines else "  No pattern data"
+        pattern_text = (
+            "\n".join(pattern_lines) if pattern_lines else "  No pattern data"
+        )
 
         # Format time analysis
         day_names = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]
-        best_hours_str = ", ".join(f"{h}:00" for h in time_analysis.best_hours) if time_analysis.best_hours else "N/A"
-        worst_hours_str = ", ".join(f"{h}:00" for h in time_analysis.worst_hours) if time_analysis.worst_hours else "N/A"
-        best_days_str = ", ".join(day_names[d] for d in time_analysis.best_days) if time_analysis.best_days else "N/A"
-        worst_days_str = ", ".join(day_names[d] for d in time_analysis.worst_days) if time_analysis.worst_days else "N/A"
+        best_hours_str = (
+            ", ".join(f"{h}:00" for h in time_analysis.best_hours)
+            if time_analysis.best_hours
+            else "N/A"
+        )
+        worst_hours_str = (
+            ", ".join(f"{h}:00" for h in time_analysis.worst_hours)
+            if time_analysis.worst_hours
+            else "N/A"
+        )
+        best_days_str = (
+            ", ".join(day_names[d] for d in time_analysis.best_days)
+            if time_analysis.best_days
+            else "N/A"
+        )
+        worst_days_str = (
+            ", ".join(day_names[d] for d in time_analysis.worst_days)
+            if time_analysis.worst_days
+            else "N/A"
+        )
 
         return f"""Analyze this trading performance and generate actionable insights:
 
 PERIOD: {period_hours:.1f} hours
 OVERALL: {len(trades)} trades, {wins} wins ({win_rate:.0%}), ${total_pnl:+.2f} P&L
@@ -730,11 +775,15 @@
         """Get ReflectionEngine statistics."""
         return {
             "reflections_completed": self.reflections_completed,
             "insights_generated": self.insights_generated,
             "adaptations_applied": self.adaptations_applied,
-            "last_reflection": self.last_reflection_time.isoformat() if self.last_reflection_time else None,
+            "last_reflection": (
+                self.last_reflection_time.isoformat()
+                if self.last_reflection_time
+                else None
+            ),
             "trades_since_reflection": self.trades_since_reflection,
             "is_running": self._running,
         }
 
     def get_health(self) -> Dict[str, Any]:
@@ -754,38 +803,46 @@
         # Determine health status
         if not self._running:
             status = "stopped"
         elif time_since is None:
             # Never ran, but might be waiting for enough trades
-            status = "healthy" if self.trades_since_reflection < self.MIN_TRADES_FOR_REFLECTION else "degraded"
+            status = (
+                "healthy"
+                if self.trades_since_reflection < self.MIN_TRADES_FOR_REFLECTION
+                else "degraded"
+            )
         elif time_since > self.REFLECTION_INTERVAL_HOURS * 2:
             status = "degraded"  # Should have run by now
         else:
             status = "healthy"
 
         return {
             "status": status,
-            "last_activity": self.last_reflection_time.isoformat() if self.last_reflection_time else None,
+            "last_activity": (
+                self.last_reflection_time.isoformat()
+                if self.last_reflection_time
+                else None
+            ),
             "error_count": 0,
             "metrics": {
                 "reflections_completed": self.reflections_completed,
                 "insights_generated": self.insights_generated,
                 "adaptations_applied": self.adaptations_applied,
                 "trades_since_reflection": self.trades_since_reflection,
                 "hours_since_reflection": round(time_since, 2) if time_since else None,
                 "is_running": self._running,
-            }
+            },
         }
 
 
 # Allow running directly for testing
 if __name__ == "__main__":
     import sys
 
     logging.basicConfig(
         level=logging.INFO,
-        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
     )
 
     print("=" * 60)
     print("ReflectionEngine Test")
     print("=" * 60)
--- /mnt/c/documents/crypto-trading-bot/src/sniper.py	2026-02-03 20:46:42.619709+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/sniper.py	2026-02-04 21:34:25.347802+00:00
@@ -28,49 +28,51 @@
     """
     An open position being managed by the Sniper.
 
     Tracks entry, current state, and exit targets (stop-loss, take-profit).
     """
+
     id: str
     coin: str
     direction: Literal["LONG", "SHORT"]
     entry_price: float
     entry_time: datetime
     size_usd: float
-    stop_loss_price: float                          # Absolute price for stop
-    take_profit_price: float                        # Absolute price for TP
-    condition_id: str                               # Which condition triggered this
+    stop_loss_price: float  # Absolute price for stop
+    take_profit_price: float  # Absolute price for TP
+    condition_id: str  # Which condition triggered this
     strategy_id: str
     reasoning: str
-    current_price: float = 0.0                      # Updated on each tick
-    unrealized_pnl: float = 0.0                     # Updated on each tick
+    current_price: float = 0.0  # Updated on each tick
+    unrealized_pnl: float = 0.0  # Updated on each tick
 
     def to_dict(self) -> dict:
         """Convert to dictionary for serialization."""
         d = asdict(self)
-        d['entry_time'] = self.entry_time.isoformat()
+        d["entry_time"] = self.entry_time.isoformat()
         return d
 
     @classmethod
-    def from_dict(cls, d: dict) -> 'Position':
+    def from_dict(cls, d: dict) -> "Position":
         """Create from dictionary."""
-        d['entry_time'] = datetime.fromisoformat(d['entry_time'])
+        d["entry_time"] = datetime.fromisoformat(d["entry_time"])
         return cls(**d)
 
 
 @dataclass
 class ExecutionEvent:
     """Event emitted when a trade is executed."""
+
     event_type: Literal["entry", "exit"]
     position_id: str
     coin: str
     direction: str
     price: float
     size_usd: float
     timestamp: int
-    reason: Optional[str] = None                    # For exits: stop_loss, take_profit, manual
-    pnl: Optional[float] = None                     # For exits
+    reason: Optional[str] = None  # For exits: stop_loss, take_profit, manual
+    pnl: Optional[float] = None  # For exits
 
 
 class Sniper:
     """
     Fast execution engine for paper trading.
@@ -97,13 +99,13 @@
 
         # Sniper automatically executes when conditions trigger
     """
 
     # Risk Limits
-    MAX_POSITIONS = 5           # Maximum concurrent positions
-    MAX_PER_COIN = 1            # Maximum positions per coin
-    MAX_EXPOSURE_PCT = 0.10     # Maximum % of balance at risk
+    MAX_POSITIONS = 5  # Maximum concurrent positions
+    MAX_PER_COIN = 1  # Maximum positions per coin
+    MAX_EXPOSURE_PCT = 0.10  # Maximum % of balance at risk
 
     # State persistence
     DEFAULT_STATE_PATH = "data/sniper_state.json"
 
     def __init__(
@@ -125,11 +127,13 @@
             quick_update: Optional QuickUpdate for post-trade knowledge updates
         """
         self.journal = journal
         self.balance = initial_balance
         self.initial_balance = initial_balance
-        self.state_path = Path(state_path) if state_path else Path(self.DEFAULT_STATE_PATH)
+        self.state_path = (
+            Path(state_path) if state_path else Path(self.DEFAULT_STATE_PATH)
+        )
         self.coin_scorer = coin_scorer  # Deprecated: use quick_update instead
         self.quick_update = quick_update  # TASK-130: for post-trade updates
 
         # Core state
         self.active_conditions: dict[str, TradeCondition] = {}
@@ -163,14 +167,11 @@
 
         Returns:
             Number of active conditions after setting
         """
         now = datetime.now()
-        self.active_conditions = {
-            c.id: c for c in conditions
-            if c.valid_until > now
-        }
+        self.active_conditions = {c.id: c for c in conditions if c.valid_until > now}
 
         logger.info(f"Set {len(self.active_conditions)} active conditions")
         return len(self.active_conditions)
 
     def add_condition(self, condition: TradeCondition) -> bool:
@@ -288,12 +289,11 @@
 
     def _cleanup_expired_conditions(self) -> None:
         """Remove expired conditions. Called on each tick."""
         now = datetime.now()
         expired = [
-            cid for cid, c in self.active_conditions.items()
-            if c.valid_until <= now
+            cid for cid, c in self.active_conditions.items() if c.valid_until <= now
         ]
         for cid in expired:
             logger.debug(f"Condition {cid} expired")
             del self.active_conditions[cid]
 
@@ -344,17 +344,23 @@
         Returns:
             True if allowed, False if risk limit hit
         """
         # Check max positions
         if len(self.open_positions) >= self.MAX_POSITIONS:
-            logger.warning(f"Max positions ({self.MAX_POSITIONS}) reached, skipping entry")
+            logger.warning(
+                f"Max positions ({self.MAX_POSITIONS}) reached, skipping entry"
+            )
             return False
 
         # Check max per coin
-        coin_positions = [p for p in self.open_positions.values() if p.coin == condition.coin]
+        coin_positions = [
+            p for p in self.open_positions.values() if p.coin == condition.coin
+        ]
         if len(coin_positions) >= self.MAX_PER_COIN:
-            logger.warning(f"Max positions for {condition.coin} reached, skipping entry")
+            logger.warning(
+                f"Max positions for {condition.coin} reached, skipping entry"
+            )
             return False
 
         # Check max exposure
         current_exposure = sum(p.size_usd for p in self.open_positions.values())
         new_exposure = current_exposure + condition.position_size_usd
@@ -373,11 +379,13 @@
             )
             return False
 
         return True
 
-    def _execute_entry(self, condition: TradeCondition, price: float, timestamp: int) -> None:
+    def _execute_entry(
+        self, condition: TradeCondition, price: float, timestamp: int
+    ) -> None:
         """
         Execute an entry (open a position).
 
         Args:
             condition: The triggered condition
@@ -419,36 +427,42 @@
 
         # Log to journal
         self.journal.record_entry(position, timestamp)
 
         # Emit event
-        self._emit_event(ExecutionEvent(
-            event_type="entry",
-            position_id=position.id,
-            coin=position.coin,
-            direction=position.direction,
-            price=price,
-            size_usd=position.size_usd,
-            timestamp=timestamp,
-        ))
+        self._emit_event(
+            ExecutionEvent(
+                event_type="entry",
+                position_id=position.id,
+                coin=position.coin,
+                direction=position.direction,
+                price=price,
+                size_usd=position.size_usd,
+                timestamp=timestamp,
+            )
+        )
 
         logger.info(
             f"ENTRY: {position.direction} {position.coin} @ ${price:.2f} "
             f"(SL: ${stop_loss_price:.2f}, TP: ${take_profit_price:.2f})"
         )
 
-    def _calc_stop_loss_price(self, entry_price: float, condition: TradeCondition) -> float:
+    def _calc_stop_loss_price(
+        self, entry_price: float, condition: TradeCondition
+    ) -> float:
         """Calculate absolute stop-loss price.
 
         Note: stop_loss_pct is in percentage form (e.g., 2.0 = 2%), not decimal.
         """
         if condition.direction == "LONG":
             return entry_price * (1 - condition.stop_loss_pct / 100)
         else:  # SHORT
             return entry_price * (1 + condition.stop_loss_pct / 100)
 
-    def _calc_take_profit_price(self, entry_price: float, condition: TradeCondition) -> float:
+    def _calc_take_profit_price(
+        self, entry_price: float, condition: TradeCondition
+    ) -> float:
         """Calculate absolute take-profit price.
 
         Note: take_profit_pct is in percentage form (e.g., 1.5 = 1.5%), not decimal.
         """
         if condition.direction == "LONG":
@@ -514,15 +528,11 @@
             price_change_pct = -price_change_pct
 
         return position.size_usd * price_change_pct
 
     def _execute_exit(
-        self,
-        position: Position,
-        price: float,
-        timestamp: int,
-        reason: str
+        self, position: Position, price: float, timestamp: int, reason: str
     ) -> None:
         """
         Execute an exit (close a position).
 
         Args:
@@ -584,24 +594,28 @@
                 "direction": position.direction,
                 "exit_reason": reason,
             }
             adaptation = self.coin_scorer.process_trade_result(trade_data)
             if adaptation:
-                logger.info(f"ADAPTATION: {adaptation.coin} -> {adaptation.new_status.value}")
+                logger.info(
+                    f"ADAPTATION: {adaptation.coin} -> {adaptation.new_status.value}"
+                )
 
         # Emit event
-        self._emit_event(ExecutionEvent(
-            event_type="exit",
-            position_id=position.id,
-            coin=position.coin,
-            direction=position.direction,
-            price=price,
-            size_usd=position.size_usd,
-            timestamp=timestamp,
-            reason=reason,
-            pnl=pnl,
-        ))
+        self._emit_event(
+            ExecutionEvent(
+                event_type="exit",
+                position_id=position.id,
+                coin=position.coin,
+                direction=position.direction,
+                price=price,
+                size_usd=position.size_usd,
+                timestamp=timestamp,
+                reason=reason,
+                pnl=pnl,
+            )
+        )
 
         pnl_str = f"+${pnl:.2f}" if pnl >= 0 else f"-${abs(pnl):.2f}"
         logger.info(f"EXIT: {position.coin} @ ${price:.2f} [{reason}] {pnl_str}")
 
     # =========================================================================
@@ -626,11 +640,13 @@
         for position in self.open_positions.values():
             if position.coin == coin:
                 return position
         return None
 
-    def close_position(self, position_id: str, price: float, timestamp: Optional[int] = None) -> bool:
+    def close_position(
+        self, position_id: str, price: float, timestamp: Optional[int] = None
+    ) -> bool:
         """
         Manually close a position.
 
         Args:
             position_id: ID of position to close
@@ -676,11 +692,12 @@
 
     def get_status(self) -> dict:
         """Get current Sniper status."""
         avg_tick_time = (
             self._total_tick_time / self._tick_count * 1000
-            if self._tick_count > 0 else 0
+            if self._tick_count > 0
+            else 0
         )
 
         return {
             "balance": self.balance,
             "initial_balance": self.initial_balance,
@@ -700,11 +717,13 @@
         max_exposure = self.balance * self.MAX_EXPOSURE_PCT
 
         return {
             "current_exposure_usd": position_exposure,
             "max_exposure_usd": max_exposure,
-            "exposure_pct": (position_exposure / self.balance) * 100 if self.balance > 0 else 0,
+            "exposure_pct": (
+                (position_exposure / self.balance) * 100 if self.balance > 0 else 0
+            ),
             "available_usd": max_exposure - position_exposure,
         }
 
     def get_health(self) -> dict:
         """Get component health status for monitoring.
@@ -725,37 +744,41 @@
         else:
             status = "healthy"
 
         # Check for stuck positions (positions with extreme unrealized loss)
         stuck_positions = [
-            p for p in self.open_positions.values()
+            p
+            for p in self.open_positions.values()
             if p.unrealized_pnl < -p.size_usd * 0.1  # >10% loss
         ]
         if stuck_positions:
             status = "degraded"
 
         avg_tick_time = (
             self._total_tick_time / self._tick_count * 1000
-            if self._tick_count > 0 else 0
+            if self._tick_count > 0
+            else 0
         )
 
         return {
             "status": status,
-            "last_activity": datetime.fromtimestamp(
-                self.last_tick_time / 1000
-            ).isoformat() if self.last_tick_time else None,
+            "last_activity": (
+                datetime.fromtimestamp(self.last_tick_time / 1000).isoformat()
+                if self.last_tick_time
+                else None
+            ),
             "error_count": 0,  # No explicit error tracking yet
             "metrics": {
                 "balance": self.balance,
                 "total_pnl": self.total_pnl,
                 "trades_executed": self.trades_executed,
                 "open_positions": len(self.open_positions),
                 "active_conditions": len(self.active_conditions),
                 "tick_count": self._tick_count,
                 "avg_tick_time_ms": round(avg_tick_time, 4),
                 "tick_age_seconds": round(tick_age, 2) if tick_age else None,
-            }
+            },
         }
 
     # =========================================================================
     # Persistence
     # =========================================================================
would reformat /mnt/c/documents/crypto-trading-bot/src/reflection.py
would reformat /mnt/c/documents/crypto-trading-bot/src/sniper.py
--- /mnt/c/documents/crypto-trading-bot/src/profitability.py	2026-02-03 18:23:33.852839+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/profitability.py	2026-02-04 21:34:25.364245+00:00
@@ -22,20 +22,22 @@
 logger = logging.getLogger(__name__)
 
 
 class TimeFrame(Enum):
     """Time frames for snapshot aggregation."""
+
     HOUR = "hour"
     DAY = "day"
     WEEK = "week"
     MONTH = "month"
     ALL_TIME = "all_time"
 
 
 @dataclass
 class ProfitSnapshot:
     """Point-in-time profitability snapshot."""
+
     timestamp: datetime
     timeframe: TimeFrame
 
     # Core metrics
     total_pnl: float = 0.0
@@ -92,12 +94,20 @@
 
     @classmethod
     def from_dict(cls, d: Dict[str, Any]) -> "ProfitSnapshot":
         """Create from dictionary."""
         return cls(
-            timestamp=datetime.fromisoformat(d["timestamp"]) if isinstance(d["timestamp"], str) else d["timestamp"],
-            timeframe=TimeFrame(d["timeframe"]) if isinstance(d["timeframe"], str) else d["timeframe"],
+            timestamp=(
+                datetime.fromisoformat(d["timestamp"])
+                if isinstance(d["timestamp"], str)
+                else d["timestamp"]
+            ),
+            timeframe=(
+                TimeFrame(d["timeframe"])
+                if isinstance(d["timeframe"], str)
+                else d["timeframe"]
+            ),
             total_pnl=d.get("total_pnl", 0.0),
             realized_pnl=d.get("realized_pnl", 0.0),
             unrealized_pnl=d.get("unrealized_pnl", 0.0),
             total_trades=d.get("total_trades", 0),
             winning_trades=d.get("winning_trades", 0),
@@ -116,10 +126,11 @@
 
 
 @dataclass
 class DimensionPerformance:
     """Performance breakdown by dimension (coin, pattern, hour, etc.)."""
+
     dimension: str  # "coin", "pattern", "hour_of_day", "day_of_week"
     key: str  # "BTC", "momentum_breakout", "14", "Monday"
 
     total_pnl: float = 0.0
     trade_count: int = 0
@@ -184,11 +195,13 @@
 
         # High-water mark for drawdown calculation
         self._high_water_mark = initial_balance
         self._current_balance = initial_balance
 
-        logger.info(f"ProfitabilityTracker initialized (initial_balance=${initial_balance:,.2f})")
+        logger.info(
+            f"ProfitabilityTracker initialized (initial_balance=${initial_balance:,.2f})"
+        )
 
     # =========================================================================
     # Core Snapshot Methods
     # =========================================================================
 
@@ -209,14 +222,18 @@
         now = datetime.now()
         start_time = self._get_start_time(timeframe, now)
 
         # Get trades from journal
         if timeframe == TimeFrame.ALL_TIME:
-            trades = self.journal.get_recent(hours=24 * 365, status="closed", limit=10000)
+            trades = self.journal.get_recent(
+                hours=24 * 365, status="closed", limit=10000
+            )
         else:
             hours = int((now - start_time).total_seconds() / 3600)
-            trades = self.journal.get_recent(hours=max(hours, 1), status="closed", limit=10000)
+            trades = self.journal.get_recent(
+                hours=max(hours, 1), status="closed", limit=10000
+            )
 
         # Calculate metrics
         metrics = self.calculate_metrics(trades)
 
         # Build snapshot
@@ -278,14 +295,20 @@
         avg_win = gross_profit / winning_trades if winning_trades > 0 else 0
         avg_loss = gross_loss / losing_trades if losing_trades > 0 else 0
 
         # Rates
         win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
-        profit_factor = (gross_profit / gross_loss) if gross_loss > 0 else float('inf') if gross_profit > 0 else 0
+        profit_factor = (
+            (gross_profit / gross_loss)
+            if gross_loss > 0
+            else float("inf") if gross_profit > 0 else 0
+        )
 
         # Win/Loss ratio
-        avg_win_loss_ratio = (avg_win / avg_loss) if avg_loss > 0 else float('inf') if avg_win > 0 else 0
+        avg_win_loss_ratio = (
+            (avg_win / avg_loss) if avg_loss > 0 else float("inf") if avg_win > 0 else 0
+        )
 
         # Expectancy: (win_rate * avg_win) - (loss_rate * avg_loss)
         loss_rate = (losing_trades / total_trades) if total_trades > 0 else 0
         expectancy = ((win_rate / 100) * avg_win) - (loss_rate * avg_loss)
 
@@ -294,11 +317,13 @@
 
         # Sharpe ratio (simplified: assume risk-free rate = 0)
         sharpe_ratio = self._calculate_sharpe_ratio(trades)
 
         # Return percentage
-        return_pct = (total_pnl / self.initial_balance * 100) if self.initial_balance > 0 else 0
+        return_pct = (
+            (total_pnl / self.initial_balance * 100) if self.initial_balance > 0 else 0
+        )
 
         return {
             "total_trades": total_trades,
             "winning_trades": winning_trades,
             "losing_trades": losing_trades,
@@ -306,12 +331,14 @@
             "gross_profit": gross_profit,
             "gross_loss": gross_loss,
             "avg_win": avg_win,
             "avg_loss": avg_loss,
             "win_rate": win_rate,
-            "profit_factor": profit_factor if profit_factor != float('inf') else 999.99,
-            "avg_win_loss_ratio": avg_win_loss_ratio if avg_win_loss_ratio != float('inf') else 999.99,
+            "profit_factor": profit_factor if profit_factor != float("inf") else 999.99,
+            "avg_win_loss_ratio": (
+                avg_win_loss_ratio if avg_win_loss_ratio != float("inf") else 999.99
+            ),
             "expectancy": expectancy,
             "max_drawdown": max_drawdown,
             "max_drawdown_pct": max_drawdown_pct,
             "sharpe_ratio": sharpe_ratio,
             "return_pct": return_pct,
@@ -348,12 +375,11 @@
         if not trades:
             return 0.0, 0.0
 
         # Sort trades by exit time
         sorted_trades = sorted(
-            [t for t in trades if t.exit_time],
-            key=lambda t: t.exit_time
+            [t for t in trades if t.exit_time], key=lambda t: t.exit_time
         )
 
         if not sorted_trades:
             return 0.0, 0.0
 
@@ -369,11 +395,13 @@
 
                 if balance > high_water_mark:
                     high_water_mark = balance
 
                 drawdown = high_water_mark - balance
-                drawdown_pct = (drawdown / high_water_mark * 100) if high_water_mark > 0 else 0
+                drawdown_pct = (
+                    (drawdown / high_water_mark * 100) if high_water_mark > 0 else 0
+                )
 
                 if drawdown > max_drawdown:
                     max_drawdown = drawdown
                     max_drawdown_pct = drawdown_pct
 
@@ -432,12 +460,11 @@
         """Estimate trading days in sample."""
         if not trades:
             return 1
 
         sorted_trades = sorted(
-            [t for t in trades if t.exit_time],
-            key=lambda t: t.exit_time
+            [t for t in trades if t.exit_time], key=lambda t: t.exit_time
         )
 
         if len(sorted_trades) < 2:
             return 1
 
@@ -567,11 +594,13 @@
         if timeframe == TimeFrame.ALL_TIME:
             hours = 24 * 365
         else:
             hours = int((now - start_time).total_seconds() / 3600)
 
-        trades = self.journal.get_recent(hours=max(hours, 1), status="closed", limit=10000)
+        trades = self.journal.get_recent(
+            hours=max(hours, 1), status="closed", limit=10000
+        )
 
         if not trades:
             return []
 
         # Calculate total P&L for contribution %
@@ -592,19 +621,21 @@
         for key, group_trades in groups.items():
             pnl = sum(t.pnl_usd or 0 for t in group_trades)
             wins = sum(1 for t in group_trades if t.pnl_usd and t.pnl_usd > 0)
             count = len(group_trades)
 
-            results.append(DimensionPerformance(
-                dimension=dimension,
-                key=str(key),
-                total_pnl=pnl,
-                trade_count=count,
-                win_rate=(wins / count * 100) if count > 0 else 0,
-                avg_pnl=(pnl / count) if count > 0 else 0,
-                contribution_pct=(pnl / total_pnl * 100) if total_pnl != 0 else 0,
-            ))
+            results.append(
+                DimensionPerformance(
+                    dimension=dimension,
+                    key=str(key),
+                    total_pnl=pnl,
+                    trade_count=count,
+                    win_rate=(wins / count * 100) if count > 0 else 0,
+                    avg_pnl=(pnl / count) if count > 0 else 0,
+                    contribution_pct=(pnl / total_pnl * 100) if total_pnl != 0 else 0,
+                )
+            )
 
         # Sort by P&L descending
         results.sort(key=lambda x: x.total_pnl, reverse=True)
 
         return results
@@ -619,11 +650,15 @@
             return trade.strategy_id or "none"
         elif dimension == "hour_of_day":
             return str(trade.hour_of_day)
         elif dimension == "day_of_week":
             days = ["Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]
-            return days[trade.day_of_week] if 0 <= trade.day_of_week < 7 else str(trade.day_of_week)
+            return (
+                days[trade.day_of_week]
+                if 0 <= trade.day_of_week < 7
+                else str(trade.day_of_week)
+            )
         elif dimension == "exit_reason":
             return trade.exit_reason or "unknown"
         elif dimension == "position_size":
             # Bucket into size categories
             size = trade.position_size_usd or 0
@@ -674,44 +709,55 @@
         if start is None:
             hours = 24 * 365
         else:
             hours = int((datetime.now() - start).total_seconds() / 3600)
 
-        trades = self.journal.get_recent(hours=max(hours, 1), status="closed", limit=10000)
+        trades = self.journal.get_recent(
+            hours=max(hours, 1), status="closed", limit=10000
+        )
 
         # Sort by exit time
         sorted_trades = sorted(
-            [t for t in trades if t.exit_time],
-            key=lambda t: t.exit_time
+            [t for t in trades if t.exit_time], key=lambda t: t.exit_time
         )
 
         # Filter by end time if specified
         if end:
             sorted_trades = [t for t in sorted_trades if t.exit_time <= end]
 
         # Build equity curve
-        curve = [{
-            "timestamp": self._get_start_time(TimeFrame.ALL_TIME, datetime.now()).isoformat(),
-            "balance": self.initial_balance,
-            "trade_id": None,
-            "pnl": 0,
-        }]
+        curve = [
+            {
+                "timestamp": self._get_start_time(
+                    TimeFrame.ALL_TIME, datetime.now()
+                ).isoformat(),
+                "balance": self.initial_balance,
+                "trade_id": None,
+                "pnl": 0,
+            }
+        ]
 
         balance = self.initial_balance
         for trade in sorted_trades:
             if trade.pnl_usd is not None:
                 balance += trade.pnl_usd
-                curve.append({
-                    "timestamp": trade.exit_time.isoformat() if trade.exit_time else None,
-                    "balance": balance,
-                    "trade_id": trade.id,
-                    "pnl": trade.pnl_usd,
-                })
+                curve.append(
+                    {
+                        "timestamp": (
+                            trade.exit_time.isoformat() if trade.exit_time else None
+                        ),
+                        "balance": balance,
+                        "trade_id": trade.id,
+                        "pnl": trade.pnl_usd,
+                    }
+                )
 
         return curve
 
-    def record_equity_point(self, balance: float, trade_id: Optional[str] = None) -> None:
+    def record_equity_point(
+        self, balance: float, trade_id: Optional[str] = None
+    ) -> None:
         """
         Record an equity point after a trade.
 
         Args:
             balance: Current balance
@@ -723,16 +769,18 @@
             self._high_water_mark = balance
 
         self._current_balance = balance
 
         # Save to database
-        self.db.save_equity_point({
-            "timestamp": datetime.now().isoformat(),
-            "balance": balance,
-            "trade_id": trade_id,
-            "is_high_water_mark": is_hwm,
-        })
+        self.db.save_equity_point(
+            {
+                "timestamp": datetime.now().isoformat(),
+                "balance": balance,
+                "trade_id": trade_id,
+                "is_high_water_mark": is_hwm,
+            }
+        )
 
     # =========================================================================
     # Learning Loop Integration
     # =========================================================================
 
@@ -748,35 +796,41 @@
         """
         now = datetime.now()
         cutoff = now - timedelta(days=lookback_days)
 
         # Get current period metrics
-        current_trades = self.journal.get_recent(hours=lookback_days * 24, status="closed", limit=10000)
+        current_trades = self.journal.get_recent(
+            hours=lookback_days * 24, status="closed", limit=10000
+        )
         current_metrics = self.calculate_metrics(current_trades)
 
         # Get previous period metrics
         prev_start = cutoff - timedelta(days=lookback_days)
         prev_hours = lookback_days * 24
-        all_trades = self.journal.get_recent(hours=lookback_days * 24 * 2, status="closed", limit=10000)
+        all_trades = self.journal.get_recent(
+            hours=lookback_days * 24 * 2, status="closed", limit=10000
+        )
 
         # Filter to previous period
         prev_trades = [
-            t for t in all_trades
-            if t.exit_time and prev_start <= t.exit_time < cutoff
+            t for t in all_trades if t.exit_time and prev_start <= t.exit_time < cutoff
         ]
         prev_metrics = self.calculate_metrics(prev_trades)
 
         # Calculate changes
         win_rate_change = current_metrics["win_rate"] - prev_metrics["win_rate"]
         pnl_change = current_metrics["total_pnl"] - prev_metrics["total_pnl"]
-        profit_factor_change = current_metrics["profit_factor"] - prev_metrics["profit_factor"]
+        profit_factor_change = (
+            current_metrics["profit_factor"] - prev_metrics["profit_factor"]
+        )
         expectancy_change = current_metrics["expectancy"] - prev_metrics["expectancy"]
 
         # Determine if improving
         is_improving = (
-            current_metrics["total_pnl"] > prev_metrics["total_pnl"] and
-            current_metrics["win_rate"] >= prev_metrics["win_rate"] - 5  # Allow 5% variance
+            current_metrics["total_pnl"] > prev_metrics["total_pnl"]
+            and current_metrics["win_rate"]
+            >= prev_metrics["win_rate"] - 5  # Allow 5% variance
         )
 
         return {
             "lookback_days": lookback_days,
             "current_period": {
@@ -848,10 +902,11 @@
 
 # =============================================================================
 # Snapshot Scheduler
 # =============================================================================
 
+
 class SnapshotScheduler:
     """
     Schedules periodic snapshot creation.
 
     Manages hourly, daily, weekly, and monthly snapshots according to schedule.
@@ -889,11 +944,13 @@
             self._last_snapshots[TimeFrame.WEEK] = now
             taken.append(TimeFrame.WEEK)
 
         # Monthly: last day of month
         tomorrow = now + timedelta(days=1)
-        if tomorrow.month != now.month and self._should_take(TimeFrame.MONTH, now, hours=24 * 28):
+        if tomorrow.month != now.month and self._should_take(
+            TimeFrame.MONTH, now, hours=24 * 28
+        ):
             self.tracker.take_snapshot(TimeFrame.MONTH)
             self._last_snapshots[TimeFrame.MONTH] = now
             taken.append(TimeFrame.MONTH)
 
         return taken
would reformat /mnt/c/documents/crypto-trading-bot/src/profitability.py
--- /mnt/c/documents/crypto-trading-bot/src/strategist.py	2026-02-03 21:57:44.498479+00:00
+++ /mnt/c/documents/crypto-trading-bot/src/strategist.py	2026-02-04 21:34:25.383872+00:00
@@ -114,11 +114,13 @@
 
         Args:
             callback: Function to call with new conditions list.
         """
         self._condition_callbacks.append(callback)
-        logger.debug(f"Added condition callback, total: {len(self._condition_callbacks)}")
+        logger.debug(
+            f"Added condition callback, total: {len(self._condition_callbacks)}"
+        )
 
     def unsubscribe_conditions(
         self, callback: Callable[[List[TradeCondition]], None]
     ) -> None:
         """Remove a condition callback.
@@ -189,11 +191,11 @@
         if "NO_TRADE" in self._active_rule_actions:
             logger.info("NO_TRADE regime rule triggered - skipping generation")
             self.db.log_activity(
                 activity_type="strategist",
                 description="Skipped generation due to NO_TRADE regime rule",
-                details=json.dumps({"triggered_actions": self._active_rule_actions})
+                details=json.dumps({"triggered_actions": self._active_rule_actions}),
             )
             return []
 
         # Build context for LLM
         context = self._build_context()
@@ -234,27 +236,33 @@
 
             # Log activity
             self.db.log_activity(
                 activity_type="strategist",
                 description=f"Generated {len(valid_conditions)} conditions",
-                details=json.dumps({
-                    "conditions": [c.to_dict() for c in valid_conditions],
-                    "context_summary": {
-                        "coins_analyzed": len(context.get("market_state", {}).get("prices", {})),
-                        "knowledge_rules": len(context.get("knowledge", {}).get("active_rules", [])),
+                details=json.dumps(
+                    {
+                        "conditions": [c.to_dict() for c in valid_conditions],
+                        "context_summary": {
+                            "coins_analyzed": len(
+                                context.get("market_state", {}).get("prices", {})
+                            ),
+                            "knowledge_rules": len(
+                                context.get("knowledge", {}).get("active_rules", [])
+                            ),
+                        },
                     }
-                })
+                ),
             )
 
             return valid_conditions
 
         except Exception as e:
             logger.error(f"Error generating conditions: {e}")
             self.db.log_activity(
                 activity_type="error",
                 description="Strategist generation failed",
-                details=str(e)
+                details=str(e),
             )
             return []
 
     def get_active_conditions(self) -> List[TradeCondition]:
         """Get currently active (non-expired) conditions.
@@ -325,26 +333,30 @@
                 coin_summaries.append(summary)
 
             # Get active regime rules with descriptions
             active_rules = []
             for rule in self.knowledge.get_active_rules():
-                active_rules.append({
-                    "description": rule.description,
-                    "action": rule.action,
-                    "times_triggered": rule.times_triggered,
-                })
+                active_rules.append(
+                    {
+                        "description": rule.description,
+                        "action": rule.action,
+                        "times_triggered": rule.times_triggered,
+                    }
+                )
 
             # Get bad coins (poor performers not yet blacklisted)
             bad_coins = self.knowledge.get_bad_coins()
 
             return {
                 "good_coins": self.knowledge.get_good_coins(),
                 "avoid_coins": self.knowledge.get_blacklisted_coins() + bad_coins,
                 "blacklisted": self.knowledge.get_blacklisted_coins(),
                 "coin_summaries": coin_summaries,
                 "active_rules": active_rules,
-                "winning_patterns": [p.description for p in self.knowledge.get_winning_patterns()],
+                "winning_patterns": [
+                    p.description for p in self.knowledge.get_winning_patterns()
+                ],
                 "blacklist_count": len(self.knowledge.get_blacklisted_coins()),
             }
 
         # Simplified fallback when no knowledge brain
         return {
@@ -424,14 +436,11 @@
             logger.info(f"Regime rules triggered: {actions}")
 
         return actions
 
     def _calculate_final_position_size(
-        self,
-        base_size: float,
-        coin: str,
-        pattern_id: Optional[str] = None
+        self, base_size: float, coin: str, pattern_id: Optional[str] = None
     ) -> float:
         """Calculate final position size with all modifiers.
 
         Combines:
         - Coin score modifier (0.0 - 1.5)
@@ -463,11 +472,11 @@
             size *= pattern_modifier
             if pattern_modifier != 1.0:
                 logger.debug(f"Pattern modifier for {pattern_id}: {pattern_modifier}")
 
         # 3. Regime rule modifier
-        if hasattr(self, '_active_rule_actions') and self._active_rule_actions:
+        if hasattr(self, "_active_rule_actions") and self._active_rule_actions:
             if "REDUCE_SIZE" in self._active_rule_actions:
                 size *= 0.5
                 logger.debug("Regime REDUCE_SIZE modifier: 0.5")
 
         # Enforce limits
@@ -703,10 +712,11 @@
             True if condition is valid.
         """
         # TASK-121: Check if coin is blacklisted
         if self.coin_scorer:
             from src.coin_scorer import CoinStatus
+
             status = self.coin_scorer.get_coin_status(condition.coin)
             if status == CoinStatus.BLACKLISTED:
                 logger.info(f"Skipping {condition.coin}: BLACKLISTED")
                 return False
 
@@ -755,11 +765,15 @@
         if current_price is None:
             logger.warning(f"No price data for {condition.coin}")
             return False
 
         # Check trigger price is reasonable (within 2% of current - conditions expire in 5 min)
-        price_diff_pct = abs(condition.trigger_price - current_price.price) / current_price.price * 100
+        price_diff_pct = (
+            abs(condition.trigger_price - current_price.price)
+            / current_price.price
+            * 100
+        )
         if price_diff_pct > 2:
             logger.warning(
                 f"Trigger price ${condition.trigger_price} is {price_diff_pct:.1f}% "
                 f"away from current ${current_price.price} - too far for 5-min TTL"
             )
@@ -797,13 +811,15 @@
         """
         return {
             "generation_count": self.generation_count,
             "conditions_generated": self.conditions_generated,
             "active_conditions": len(self.active_conditions),
-            "last_generation": self.last_generation_time.isoformat()
-            if self.last_generation_time
-            else None,
+            "last_generation": (
+                self.last_generation_time.isoformat()
+                if self.last_generation_time
+                else None
+            ),
             "interval_seconds": self.interval,
             "is_running": self._running,
         }
 
     def get_health(self) -> Dict[str, Any]:
@@ -830,32 +846,36 @@
         else:
             status = "healthy"
 
         return {
             "status": status,
-            "last_activity": self.last_generation_time.isoformat()
-            if self.last_generation_time
-            else None,
+            "last_activity": (
+                self.last_generation_time.isoformat()
+                if self.last_generation_time
+                else None
+            ),
             "error_count": 0,  # Could add error tracking in future
             "metrics": {
                 "generation_count": self.generation_count,
                 "conditions_generated": self.conditions_generated,
                 "active_conditions": len(self.active_conditions),
                 "interval_seconds": self.interval,
-                "time_since_last_generation": round(time_since_gen, 1) if time_since_gen else None,
+                "time_since_last_generation": (
+                    round(time_since_gen, 1) if time_since_gen else None
+                ),
                 "is_running": self._running,
-            }
+            },
         }
 
 
 # Allow running directly for testing
 if __name__ == "__main__":
     import sys
 
     logging.basicConfig(
         level=logging.INFO,
-        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
+        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
     )
 
     async def test_strategist():
         print("=" * 60)
         print("Strategist Test - Generating Trade Conditions")
would reformat /mnt/c/documents/crypto-trading-bot/src/strategist.py

Oh no!   
54 files would be reformatted, 6 files would be left unchanged.
