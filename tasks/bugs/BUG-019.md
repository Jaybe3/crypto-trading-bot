# BUG-019: Synchronous LLM calls block dashboard event loop

**Severity:** HIGH
**Found:** 2026-02-06
**Found By:** User report (slow dashboard) + investigation
**Status:** FIXED

## Evidence

llm_interface.py line 109 uses `requests.post()` (synchronous blocking call):
```
109:            response = requests.post(
```

strategist.py line 218 calls `self.llm.query()` every ~180 seconds:
```
218:            response = self.llm.query(prompt, system_prompt)
```

FastAPI event loop blocked during LLM response wait (~10+ seconds).
All dashboard endpoints unresponsive during this window.

## Root Cause

Synchronous HTTP call (`requests.post`) inside an async method blocks the
entire event loop. When the strategist generates conditions every 3 minutes,
the LLM call can take 10+ seconds, during which the dashboard is frozen.

## Fix

1. Added `asyncio` import to llm_interface.py
2. Added `async_query()` method using `asyncio.to_thread()` wrapper
3. Added `async_query_json()` method using `asyncio.to_thread()` wrapper
4. Changed strategist.py to wrap the sync `llm.query()` call with `asyncio.to_thread()`

The original synchronous methods are preserved for backwards compatibility.
The strategist uses `asyncio.to_thread(self.llm.query, ...)` directly to maintain
compatibility with existing test mocks that patch `llm.query`.

## Verification

```bash
# Confirm async methods exist in llm_interface
grep -n "async def async_query" src/llm_interface.py

# Confirm strategist uses asyncio.to_thread
grep -n "to_thread" src/strategist.py

# Confirm imports work
python3 -c "from src.llm_interface import LLMInterface; print('OK')"
python3 -c "from src.strategist import Strategist; print('OK')"
```

## Fixed In
[Commit hash to be added after commit]
